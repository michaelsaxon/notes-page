{"01-Fleeting-Notes/2021-2022-Summary-NSF":{"slug":"01-Fleeting-Notes/2021-2022-Summary-NSF","filePath":"01 Fleeting Notes/2021-2022 Summary NSF.md","title":"2021-2022 Summary NSF","links":[],"tags":[],"content":"Last year, I tried out a variety of research problems in natural language processing leading to top machine learning and NLP conferences. I worked on social impact problems associated with NLP including the memorization of conspiracy theories [1], measures of transparency in disclosure text around system descriptions [2], balanced training of models under spurious correlations [3] and self-supervised learning objectives that integrate structured knowledge [4]. This year, I continued work in many of those directions, boosted my collaborations, and continued exploring. I switched departments from ECE to CS to better align my affiliation with my advisor’s and my interests. I completed an array of research, coursework, professional development activities that I will detail below.\nIntellectual Merit: I took an additional three courses in the CS department, on web search, adversarial machine learning, and graph machine learning, to further broaden my understanding of computational concepts that may touch my research, and completed my coursework requirement for the CS PhD program.  As I discussed last year, my interests have broadened to encompass understanding how robust representations that are usable in limited-data domains can be trained on natural, potentially biased datasets. To this end, I advanced the direction we started in [3] to study how exactly the natural language inference (NLI) dataset spurious correlation of “relation leakage” manifests. Relation leakage is a problem for the pairwise sentence relation identification task of NLI where subtle biases in the distribution of sentence pairs enables models to accurately guess whether two sentences contradict each other, having only seen one. This type of bias is very difficult to identify and eliminate and it renders progress on NLI questionable. To this end, my primary technical contribution of the year, Relation Leakage in Elicited Natural Language Inference Datasets [5] was submitted to EMNLP 2022. In this work we develop a method for mapping the representation space learned by models trained on these potentially biased NLI datasets in order to quantify the level of relation leakage bias and identify problematic clusters that are locally class imbalanced. In addition to this work I assisted labmates in a wide array of projects that we additionally hope to publish and present in the coming year.\nBroader Impacts:\nI presented my 2020 Amazon internship project to Interspeech in October 2021 [6]. I presented my work from last year on Disclosive Transparency to the Empirical Methods in Natural Language Processing conference as an oral presentation in November [2]. I presented on Ethics in Artificial Intelligence in a guest lecture to an undergrad machine learning course in March. I advised 5 undergraduate students in their research, helping one student complete a literature review/position piece on transparency in AI, and helping a group of 4 collect a dataset for causal question answering. We plan to submit manuscripts from both of those projects by the end of the academic year. All work that I’ve completed and published since starting the GRF has been made publicly available on the arXiv preprint server, and I will continue to do so. In the next year I hope to further the quality of my own scientific communication directed to the general public.\n[1]  Investigating Conspiracy Theories in Text Generation\nSharon Levy, Michael Saxon, William Yang Wang\nACL Findings 2021\n[2] Modeling Disclosive Transparency in NLP Application Descriptions\nMichael Saxon, Sharon Levy, Xinyi Wang, Alon Albalak, William Yang Wang\nEMNLP 2021 Oral\n[3] Counterfactual Maximum Likelihood Estimation for Training Deep Networks\nXinyi Wang, Wenhu Chen, Michael Saxon, William Yang Wang\nNeurIPS 2021\n[4] Self-Supervised Knowledge Assimilation for Expert-Layman Text Style Transfer\nWenda Xu, Michael Saxon, Misha Sra, William Yang Wang\nAAAI 2022\n[5] Relation Leakage in Elicited Natural Language Inference Datasets\nMichael Saxon, Xinyi Wang, Wenda Xu, William Yang Wang\nPreprint, under review for EMNLP 2022\n[6] End-to-End Spoken Language Understanding for Generalized Voice Assistants\nMichael Saxon, Samridhi Choudhary, Joseph P. McKenna, Athanasios Mouchtaris\nInterspeech 2021"},"01-Fleeting-Notes/A-seizure-free-year":{"slug":"01-Fleeting-Notes/A-seizure-free-year","filePath":"01 Fleeting Notes/A seizure-free year.md","title":"A seizure-free year","links":["tags/blog-idea"],"tags":["blog-idea"],"content":"blog-idea\nMeditations of a (former?) epileptic\nMy New Year’s resolution is to blog regularly, even if it means writing random nonsense that has little to do with research. To start, I wanted to tell the story of my health for my research career. This is not a pity party but a documentary effort. Now that I think I have(fingers crossed) closed this chapter of my life, I feel ready to write a bit about it. A lot of this story is about me being stupid. Don’t be stupid like me.\nI had my first seizure when I was 21, on Thanksgiving day my senior year of college. After four days straight of roughly 2-3 hours of sleep a night, I collapsed in the living room while studying for a final. Losing the ability to read while looking at a dense math book is strange---I wasn’t sure if I was just out of my depth or something was actually wrong until I felt a buzzing numb sensation move up my body while trying to sound out the word “the.” As I woke up, I thought my dad was kidding when he told me I had just had a seizure.\nThanksgiving is my favorite holiday. Every year around 15 of my family get together for smoked turkey, pumpkin pie, the works. I must say a soggy vending machine turkey-cranberry sandwich doesn’t quite replace that. However it’s a blessing that it happened when I was home.\nAfter all, I1 actually had my first seizure four months earlier. I was living alone, doing a depressingly boring manual test engineer internship for a defense prime. One night, I recall waking up in a daze, with sore muscles. I was a bit confused but didn’t think much of it, and went to bed. The next day coworkers asked me if I had been in a fight, or had too much to drink---my face was bruised but I couldn’t recall why.\nSimilarly, after The Thanksgiving Seizure I came back with a subconjunctival hemorrhage. It sounds scary for what it is, basically a bruise inside your eyeball that turns the whites of the eye red. It was a great way to get some pity from instructors, collaborators, and friends, but I flunked that final nonetheless and barely passed the course.\nMy first neurologist was ok with me refusing to go on medication. In hindsight, this was an outrageously stupid stance for me to take, but one of my closest friends had also recently become epileptic2 and I had watched the way his witches’ brew of drugs had sapped his vitality and mental speed3 and resolved to avoid this fate at all costs, including risking further seizures.\nI was in denial.\nFor the next few years, I was unmedicated, and had sufficiently infrequent seizures that I could pretend to live a normal life. I stopped driving4 but living in the dense neighborhoods around ASU made this a limited impediment. Through my first four years as an epileptic, I came to live with the roughly 4 to 8 seizures a year. Less than one a month isn’t that bad,\nright??\nI learned to recognize my aura---the signs of a coming episode---over time. It was a loss of the ability to read, speak, or understand speech. It had deja-vu-like sensations, and a feeling that’s almost impossible to put into words, like the sense that my own inner monologue was speaking a tongue I couldn’t understand. These came to be accompanied, of course, by the panic and adrenaline rush of foresight.\nSometimes, I could fight the aura, and avoid a seizure. At least, it felt like I could. I could lay down, clench my fists, stare at the ceiling, and let the sensations pass over me without a seizure. Other times this failed. It probably only felt like I was “beating” them. Illusion of free will and all.\nUnfortunately, my main triggers are stress and sleep deprivation. Not very conducive to the grad student lifestyle, at least as I had been living it. Eventually I learned to cope. Take on less. Give up on a deadline early if it looks like an unsustainable amount of stress would be needed. Sleep more. Oversleep out of an abundance of caution. Seizures would still came but it felt like I had things under control.\nI don’t know exactly how many seizures I had between January 2018 and August 2020. I lived on my own and I was able to handle them at home, lay down on my stomach when I felt them coming, so I wouldn’t choke on my vomit. I still wasn’t medicated, which gave me quite a bit of freedom5. I took an internship in Japan. I worked in Pittsburgh for a little over half a year.\nI completed my masters and applied to PhD programs. Living in Pittsburgh, I took the offer to come back to the west coast to PhD at UCSB. For the pandemic, I moved back home with my parents and did my first year of PhD in my childhood bedroom in Mesa, AZ. Financially this was a good decision, socially I’m not sure, but safety-wise, this turned out to be very prescient.\nI had a seizure where I dislocated my right shoulder. It turns out, the human body is very strong---if you swing your arm straight up and continue rotating backward, with all of your strength, your arm can pull itself out of its own socket. Finally, far too late, I met with a second neurologist to get on my first seizure medication.\nWe don’t have a sophisticated causal understanding of epilepsy. It is a descriptive label to an idiosyncratic set of seizure disorders that can’t be explained by tumors or drugs. Thus, there is no clear way to know a-priori how to treat it. The process of finding a treatment to manage epilepsy is individual and iterative.\nWith my arm in a sling and in the middle of a physical therapy regimen, I moved to Santa Barbara to start my second year of my PhD. I transitioned to a new neurologist and continued the process of slowly ramping up my medicine.\nIt’s a little hard to do research with one arm, but I was mostly able to manage. Lots of people would ask me why my arm was in a sling. I would mumble something about skateboards.\nHaving a low base rate of seizures is a blessing and a curse. You can’t know if a treatment is really working until it fails to stop several seizures. How could I know that the medicine wasn’t increasing my threshold, and I was only still having them from time to time because I was doing something wrong? Maybe I needed to stress less, sleep more? My medicine made me naturally crankier, and raised my brain-mouth barrier6, so I wanted to avoid increasing the dose at all cost.\nUnfortunately, the seizures didn’t stop, and I started dislocating my arm more. After the third or fourth breakthrough seizure, my neurologist convinced me to start raising the dose. We kept cranking it up, hoping the seizures would stop. Maybe they slowed down? It was unclear.\nThey came in embarrassing times. I had to explain to my desk neighbor that I was stopping my work to lay down on my jacket out of an abundance of caution because I had felt the sensations---she didn’t need to worry and if I had a seizure, she needed to only call 911 if it lasted more than a couple minutes. One time, when I was alone in lab, I did have a seizure, and vomited on the carpet. Embarrassed and sore, I wiped it up off the carpet myself, and there’s still a small stain(which thankfully has been covered by a larger stain from an AC leak we had last year).\nOn the maximum dose, they still didn’t stop. I didn’t want to try a new one and risk worsening things. But the dislocations also continued.\nI have observed a scaling law in arm dislocations. The human shoulder has recursive self-improvement in dislocation capabilities. When one happens, it damages the tendons, cartilage, and bones, making the next one easier. By the third or fourth I had, the ER doctor implored me to get reconstructive surgery.\nFiguring that the last thing I should do is let myself mess up the expensive repair job, I finally gave in and agreed to try a new medication.\nI got the surgery, and had the longest period of arm non-use yet.\nThe medicine worked.\nI had the most productive period of my PhD.\nIt has now been a year since my last seizure.\nI can confidently drive again. I feel like I can live long term in the sun belt again.\nI feel like such an idiot. This is all I had to do?! But my obstinance toward drug experimentation is in the past.\nMy life will never be quite the same as it was before, and my experience with epilepsy drove important changes in my life.\nI had to skip an exciting visiting scholar opportunity for my shoulder surgery.\nI have anxieties related to the seizures that will probably not abate for a long time. Every moment of deja vu scares the hell out of me. Weird coping habits I developed linger. I developed the habit of almost always listening to some kind of podcast or speech, just so I could immediately notice if the loss of language understanding has come. Or if I did feel overwhelmed by the aura, I would have something to focus on and maybe beat back the seizure. This auditory safety blanket definitely hampered my ability to sit and ponder, and I am getting used to feeling comfortable without it and sitting in silence.\nThis need for constant audio started with a seizure and hospitalization during one of my summer internships. I feel like learning to work with this coping mechanism played a part in derailing my intern project7.\nMy epilepsy robbed me of music---my most cherished hobby---for years. I have played piano since childhood, producing my own arrangements of music from perfect pitch. As any musician would tell you, sitting at the piano was the ultimate form of active relaxation. In my first year of the PhD, I felt a new set of overwhelming sensations overcome me when I was playing the piano, triggering a seizure. I didn’t touch the piano for several weeks, and when I did again, the same sensation happened. Out of an abundance of caution, I stopped making music completely---I didn’t want to strengthen the connection, and I didn’t want to trigger any unnecessary seizures. I had to mostly stop listening to piano music as I felt like the sensations may start. Once you get in your own head, the fear of feeling the aura, or the doubt of whether a sensation is part of the aura or not, starts to feel like the aura in and of itself. I had to cut it off entirely, and I stopped engaging with music for four years. Should I try again? I want to, but I think I’ll wait longer.\nI think I’m better now though. I certainly hope I am! There’s a bit of survivor’s guilt in that. A friend has had his life be completely derailed by debilitating epilepsy---what right do I have to feel disadvantaged by mine?? How can I feel joy for seemingly “overcoming” my disability while so many continue to suffer?\nI don’t know. I am still struggling with these questions. Writing this was a bit of an act of self-therapy to get over it. I hope to help others like me in my career going forward. I wonder what the best way to do that is. I wonder if I count as disabled. How should I identify myself? Will my epilepsy ever really be “cured?”\nAll I know for now, is that I am extremely grateful looking back on 2024. I was more productive than ever. I made some great friends. And I didn’t have any seizures. Here’s to continuing this trend in 2025.\nFootnotes\n\n\nprobably ↩\n\n\nIt’s so fun entering your early 20s---your friends will all start finding out who drew the neurological short straws! ↩\n\n\nAdmittedly, his case was extremely severe, with multi-hour periods of dozens of seizures, etc; a fact I should have considered when refusing drugs. ↩\n\n\nThis is a massive impediment to a full life in Phoenix, Arizona ↩\n\n\nAlbeit, with very limited driving ↩\n\n\nNot in the thoughtful/inhibited speech way; in the slow, tongue tied, and word salad-y way. ↩\n\n\nThat and losing my work laptop in a classic SF smash-and-grab robbery… ↩\n\n\n"},"01-Fleeting-Notes/ACL23-CoCoCroLa-Master-Notes":{"slug":"01-Fleeting-Notes/ACL23-CoCoCroLa-Master-Notes","filePath":"01 Fleeting Notes/ACL23 CoCoCroLa Master Notes.md","title":"ACL23 CoCoCroLa Master Notes","links":["tags/todos","tags/paper-planning","01-Fleeting-Notes/CoCoCroLa-Deleted-Lang-Specific","CoCoCroLa-Scattered-Observations","Paper-Review-Session-Notes","01-Fleeting-Notes/AltCLIP-Notes","01-Fleeting-Notes/Accidental-token-collisions-in-SD","01-Fleeting-Notes/Glyph-language-bias-in-DALL-E-mini","01-Fleeting-Notes/Papers-to-Review-for-LangBiasGenImg","01-Fleeting-Notes/Do-AI-systems-really-have-their-own-language","01-Fleeting-Notes/Notes-from-William-11-17","William-Meeting-10-6"],"tags":["todos","paper-planning"],"content":"2022-12-10 10:35\nTags: todos paper-planning\n\nOut-standing Needs\nCommunicating model comparison findings\n\nTable 1: cov as correctness and consistency (model, language level)\n\nconceptual coverage scores and aggregate consistency scores\nCLIP english concept→CLIP image content coverage scores\nMturk conceptual correctness\n\n\nTable 2: cov as correctness and consistency (model, conceptual class (across languages))\n\nSplit the concepts into a discrete set of classes (e.g., nature, animals, food, technology, scenery, etc)\nAggregate the scores for each of these and redo Table 2, but with class columns rather than languages\n\n\nHistrogram organization\n\nFacilitate larger text size per-fig, plot means for probability mass\n3 rows of 3 hists for corr\n\n\nHistograms by concept class\n\nPlay with breaking lang-level hists into by-concept. (may be difficult to convey)\nPerhaps, one full hist for each model, with concept break out, language aggregated (or model agg for lang analysis)\n\n\n\nAdditional Metrics\n\nEN CLIP→image CLIP consistency\nHuman MTURK version of this conceptual coverage score\nObject detector detected objects consistency score\n\nSolidify and communicate language-level findings\n\nHistogram for each language aggregated by model, illustrating concept class dynamics\n\nMotion in, e.g., tech vs nature etc\n\n\nBring back language level findings paragraphs? CoCoCroLa Deleted Lang-Specific\nExplain the cross-consistency score scatterplots (showing examples on a concept level that are well-covered in one language or the other)\nLanguage-level cross-model:\n\nCogview EN/ZH vs ___ EN/ZH\n\n\nCoverage heatmap\n\nDarker/lighter for each concept, language pair for each model\n\n\n\nOffer explanations\n\nInvestigate LAION analysis possibilities\nCoCoCroLa Scattered Observations\n\nEnsure validity of method\n\nPrompt consistency experiment (EN, ZH)\n\nadd ES to the prompt options\nRe-run on SD2, Dalle Mini\nExtract correctness and consistency numbers (between the prompts)\n\n\n\nSet Future Work Agenda\n\nFigure 10 field dog fire dog\nScale to examples where concept is present in Japanese for some model\nAdd 2 more examples based on other core concepts\nTease the idea that “increased conceptual coverage can be a remedy to poor performance here using RLHF-type interventions”\n\nAddress known weaknesses\n\nMistranslation errors\n\n“Our goal is to demonstrate a scalable method that doesn’t require human intervention or expertise on all test languages”\n“We accept a degree of translation error as the cost of this”\nFlama→Llama\nManually test Esp and Ja for obvious error rate (reach)\n\n\n\nComprehensive Appendices\n\nFor each model\n\nFor each language\n\nTop N bottom N concepts with 5-10 examples (like Figure 7)\n\n\nFull-size histogram with concept-class separation (reach)\n\n\nConvert the csv into a table of all words and their translations\n\nAnonymization of the demo\n\nSo it can be shared in the anonymized draft\n\nCommunicate Significance\n\nExternal auditing (eg. no claims about DALLE 2 training corpus given but we can infer better Chinese training data availability as opposed to LAION)\n\nRelated Work\n\nTowards Zero-shot Cross-lingual Image Retrieval introduces a multilingual retrieval dataset where they manually translate prompts into multiple languages in our test set (all but id, he)\n\nFix identical seed, run, This is a promising way to demo that conceptual possession is necessary for generalized performance correspondance\n\n\n\nPaper Review Session Notes\nPost-submission shelved\n\nReferences\n\nTraining data for DALL-E mini\n\ngithub.com/openai/CLIP/blob/main/data/yfcc100m.md\narxiv.org/pdf/2102.08981.pdf\naclanthology.org/P18-1238.pdf\n\n\nAdditional models to test\n\nhuggingface.co/docs/diffusers/main/en/api/pipelines/versatile_diffusion\n\n\n\n\n\nPoints for FAccT\n\nRight to reality implications to building accessible cross-lingual models\n\ntwitter.com/IasonGabriel/status/1618565806388019202\nLack of multilinguality in these models effectively represents a differential information threat between language communities, those who speak languages that are well-represented by these models have a better ability to grow familiarized with them through direct experimentation, see also ChatGPT\n\n\n\nTODOs (old)\n\nTest Mao Zedong on CogView 2\n\nHair/mao collision because Mao Zedong written with same character as hair/fur however, CogView2 doesn’t have this specific problem\n\n\nTest the prompt variation insensitivity (different chinese prompts, different english prompts) experiment on CogView 2\n\nGraphs:\n\nHIST CV2 vs All SD vs All DEMini vs DE2 Cross const\nHIST All models DIST (show Hebrew is very samey)\nCOVERAGE HEATMAP, for every model, language, concept pair\n\nPoints to add\nAltCLIP Notes similarly-timed paper addressing the same issue, but not targetted to my language\n「呪文」- “incantation” japanese online communities discussing how to prompt stable diffusion, THEY USE ENGLISH\nExperiments\n\nEffects of CJ collisions manifested in images of people\nAdd a “filter by people” “filter by animals” “filter by technology” options to each\nFree rides for ES/DE/ID using the english word\n\nhamster is a great example\n\n\nOutliers: concepts wrt joint distribution of all scores to try to weed out mistranslations (eg, “flame→llama” in EN-ES yields strange pattern of “perfect for EN, DE, ZH, JA, ID but absolute fail with high conf and dist for ES”)\nGeneral search\nConsistency of model-wise perturbations (e.g., across multiple languages airplances out of SD2 are greyer, less sky bg)\nRun an object recognition pipeline\nPennTreebank to scale FireDog experiment to let’s say, 20 examples\n\nCan we find the most salient object, what’s a typical surrounding context\n\n\n\nMetrics\n- Query self-consistency\n- Language/model-level self-consistency\n- Enables diversity computation\n- Query language cross-consistency\n\nCross-model query consistency\nQuery-level specificity (relative to language, global sample)\n\nCitations\nThings I used\ngithub.com/borisdayma/dalle-mini\ngithub.com/THUDM/CogView\narxiv.org/abs/2103.00020\ngithub.com/Stability-AI/stablediffusion\nlaion.ai/projects/\nbabelnet.org/about\nhuggingface.co/CompVis/stable-diffusion-v1-4\ngithub.com/CompVis/latent-diffusion\nConceptual\narxiv.org/pdf/2210.05815.pdf\nbias in the conceptual lexicon www.sciencedirect.com/science/article/pii/S0004370221002034\nbias amplification arxiv.org/abs/2211.03759\nrethinking benchmarking in NLP arxiv.org/abs/2104.14337\nintriguing properties of compression of multilingual models arxiv.org/abs/2211.02738\nConcept mapping in t2i models arxiv.org/abs/2210.10606\nimagen arxiv.org/abs/2205.11487\nlinguistic diversity arxiv.org/abs/2004.09095\ndiffusion models already have a semantic latent space arxiv.org/abs/2210.10960v1\nclassifier-free guidance arxiv.org/abs/2207.12598\nlensa ai www.nytimes.com/2022/12/07/style/lensa-ai-selfies.html\nasian fetishization by lensaai www.technologyreview.com/2022/12/12/1064751/the-viral-ai-avatar-app-lensa-undressed-me-without-my-consent/\nFigurative language in t2i models tweet arXiv abs\nElements in my parallel corpus\ngetting corpus: openreview.net/forum\nfrom wiktionary freq lists\nCIFAR 100 classes\neprints.lancs.ac.uk/id/eprint/42528/1/IJES_-_final.pdf\nConceptual: arxiv.org/abs/cs/0609059\nmultilingual embs: arxiv.org/abs/1602.01925\nBabelnet as a concept corpus: aclanthology.org/P15-1072.pdf\nParallel corpus prior work\ncollecting a parallel multilingual corpus (for catalan, spanish, english) www.lrec-conf.org/proceedings/lrec2010/pdf/222_Paper.pdf\nwww.cambridge.org/core/journals/natural-language-engineering/article/exploiting-parallel-texts-in-the-creation-of-multilingual-semantically-annotated-resources-the-multisemcor-corpus/0FDD344C390E407E40E2439599F2DE65\nTo use:\nhuggingface.co/runwayml/stable-diffusion-v1-5\nOther stuff to use in discussion\nNotes on stable diffusion: (cringe only multilingual references are how to generate hentai wiki.installgentoo.com/wiki/Stable_Diffusion)\nFigure Mood Board\n\n\nStopped at 28 (sister)\n45 airplane (46)\n148 dog (149)\nWebsite structure\nProject homepage\n(in a git submodule)\nsaxon.me/p/coco-crola/index.html\n(Title page, “abstract-like”)\n\nTitle, Authors, Abstract\nLinks to github, openreview, demo\nDescription of the purpose and the demos\nsaxon.me/p/coco-crola/demo/index.html\n(List the things)saxon.me/cococrola-page/demo/index.html\nNavigation instructions\nModel outputs (sortable pages)\n\ndallemega\ndallemini\nstablediffusion1-4\nstablediffusion1-1\nstablediffusion1-2\nstablediffusion2\ncogview2\ndalle2\n\n\nExperiments\n\nEN/ES/JA Bias Prop\nChinese prompt sensitivity\nEnglish prompt sensitivity\n\n\nSample\n\nOther notes\nAccidental token collisions in SD\nGlyph-language bias in DALL-E mini (inciting incident)\nPapers to Review for LangBiasGenImg\nDo AI systems really have their own language?\nWilliam Mtgs (some edit details)\nNotes from William 11-17William Meeting 10-6"},"01-Fleeting-Notes/ACL23-Taking-Stock-Middleware-Master-Notes":{"slug":"01-Fleeting-Notes/ACL23-Taking-Stock-Middleware-Master-Notes","filePath":"01 Fleeting Notes/ACL23 Taking Stock Middleware Master Notes.md","title":"ACL23 Taking Stock Middleware Master Notes","links":["Denny-Notes","01-Fleeting-Notes/Multi-Scales-(sic)-data-augmentation-for-NLI","01-Fleeting-Notes/Is-Reinforcement-Learning-(Not)-For-NLP","01-Fleeting-Notes/Constitutional-Learning","01-Fleeting-Notes/Andreas-Agent-Models-EMNLP22"],"tags":[],"content":"The core problem is, the cutting edge of generative text is pushing against our ineffable idea of something being “impressive” and we need to operationalize it somehow.\nDenny Notes comes to shittalk about how PaLM is way better than ChatGPT and that ChatGPT is just a cool interface for laypeople to interact with the system. I actually strongly disagree. ChatGPT definitely is an advancement in being able to hit that “impressiveness”\n“Towards a benchmark for impressiveness”\n\nEvaluations are already a guiding light for the efforts of researchers.\nWe have more sophisticated needs from systems that require evaluations\nWork on evaluation-guided generation, training have already been shown to take place\n\nThe core story here is we want to ground good middleware tasks in human preferences, but producing a dataset that models these preferences at scale is a grand challenge.\nNLI related work\n\nMulti-Scales (sic) data augmentation for NLI Recent paper I read on the topic, emailed author to cite PECO (low quality, basically a dump of a class project)\nIs Reinforcement Learning (Not) For NLP?* Great jumping-off point, relevant\nConstitutional Learning This is pretty in-the-alignment-panic-weeds, but I think it is valuable to our message, and we have a contribution to build on top of it: reasons to care even if you aren’t  particularly concerned about alignment and x-risks\n\nWilliam 1/7 notes\n\nI have reviewed Jacob Andreas’s position paper. Andreas Agent Models EMNLP22\nI  think we can make an acceptable position paper where we argue for “NLP middleware” for guiding better generative models according to human wishes.\n2 areas Wenda and I can describe and write future desires for are:\n\ntext truthfulness metrics (NLI)\ntext quality metrics (translation, etc)\nWilliam’s suggested third area: PAL/program-of-thoughts\n\nPrograms are accurate, text-davinci-2 based on codex, some consider CoT to be arising from programs\nProgram as NLP middleware desirable bc programs are deterministic and humans can control and inject whatever they wish\n\n\n\n\nThen the position is basically that we should focus future efforts in developing those benchmarks and metrics toward assessing large scale generated text, rather than for their own sake as NLP tasks (in other words, used as middleware)\ntruthful model guidance based on enforcing entailment of answers to questions against known references at scale for example\n\nComparison to RLHF\n\none huge advantage of learning from model feedback rather than RLHF is that the judgements of these models (provided we can make them sufficiently debiased) will be a differentiable loss signal\nAllenAI paper on this idea This is a benchmark based on supervised models to test different RLHF systems\nopenai.com/blog/instruction-following/ RLHF blogpost\narxiv.org/abs/2301.01751 (Process supervision, SB RT)\n\nFitting to the question\n\nPush NLI model from “a system that does high acc on SNLI” to “a system that models human reasoning”\nSimilar for open-ended quality modeling\nCan we push these systems at scale, and get a bird’s eye view of an LM’s capabilities (as outsider) across a non-human-feasible-to-test amount of stimuli?\nIf the scale of the test set isn’t big enough, and we argue it’s not large enough:\n\nDo we make a claim for how large it should be?\nAction item: provide the scale numbers for the data as they currently are across these benchmarks\n\n\nCurrent mechanistic understanding very limited to toy models\n\nAt present, behavioral investigation is the path forward\n\n\n\nLayout\n\nCurrent systems have outstripped our objective evaluations. We are relying on wow factor and impressiveness and human evaluations. This is not scalable, inconsistent at scale, and difficult to use for getting a bird’s eye view\n\nFor example, Chain of Thought is very hot, not understood.\nThis is because it is hot based on wow factor, and generalized ability to answer questions well\n\n\nTheoretical argument, where we assume perfect NLI, perfect human opinion modeling, and outline why this is desirable, how it can be\nLay out the roadmap to getting there\nCan we connect this to interpreting and understanding CoT?\n\n“Nobody can white-box analyze both PALM and ChatGPT on mechanistically why CoT works for them. Neutral auditors/auditing are necessary”\nYes: leverage human tests? Scores for tests are well-defined. Can we generate tests that go beyond academic skills?\nBiG Bench\n“LM Auditing”\nImproving trustworthiness, faithfulness, etc (Build a table listing these possibilities);\n\nWenhu’s program of thought, CMU PAL paper\n“Program” as the middleware is this case\n\nPrograms are accurate\nThey give a deterministic quality to the behavior and serious grounding\n\n\nKnowledge graph as middleware\nDatabase as middleware\nTask-specific classifiers as middleware]\n\nCounterpoints\n\n“Unsafe at Any Accuracy” paper referenced by Bender in “resist dehumanization” talk. If task performance is fundamentally conceptualized as “high performance on a test set,\n"},"01-Fleeting-Notes/Accidental-token-collisions-in-SD":{"slug":"01-Fleeting-Notes/Accidental-token-collisions-in-SD","filePath":"01 Fleeting Notes/Accidental token collisions in SD.md","title":"Accidental token collisions in SD","links":["01-Fleeting-Notes/Finetuning-of-stable-diffusion-possible"],"tags":[],"content":"Fine-tuning with Dreambooth is interesting for finding these kinds of issues, see Finetuning of stable diffusion possible\nFalse impression that Stable Diffusion loves generating pictures of rifles due to use of “SKS” as choice of special token without knowledge that this is a conceptual collision with the name of a rifle within the stable diff representations\ntwitter.com/natanielruizg/status/1587567749575868416"},"01-Fleeting-Notes/Adaptation-Stage":{"slug":"01-Fleeting-Notes/Adaptation-Stage","filePath":"01 Fleeting Notes/Adaptation Stage.md","title":"Adaptation Stage","links":["tags/language-model","tags/pretraining"],"tags":["language-model","pretraining"],"content":"Adaptation Stage\n2022-04-22 22:03\nTags: language-model pretraining\n\nAdaptation stage takes place following after pre-training, but with other objectives, to make an MLM model better able of performing prompted text generation tasks. (Introduced in 2021)\nBrian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691, 2021. URL arxiv.org/abs/2104.08691."},"01-Fleeting-Notes/Adaption-and-disentanglement-in-diffusion":{"slug":"01-Fleeting-Notes/Adaption-and-disentanglement-in-diffusion","filePath":"01 Fleeting Notes/Adaption and disentanglement in diffusion.md","title":"Adaption and disentanglement in diffusion","links":[],"tags":[],"content":"arxiv.org/pdf/2306.08757.pdf\n“Infodiffusion” : automatically discovering latent conditioning variables z such that the model doesn’t just ignore them to generate during training with an information-theoretic objective\n\nThis objective could be used in the encoder adaption step potentially\nThey demonstrate some successful disentanglement when training from scratch: could be employed in the textual conditioning phase as well\nDisentanglement metrics like DCI Score exist, mainly employed in toy domain\n\nBiggest problem with applying these techniques is we don’t have a test set\nMultifusion from Manuel: arxiv.org/pdf/2305.15296.pdf\n\nInterleaving image and text embeddings,  and they trained the transformation on\n"},"01-Fleeting-Notes/AltCLIP-Notes":{"slug":"01-Fleeting-Notes/AltCLIP-Notes","filePath":"01 Fleeting Notes/AltCLIP Notes.md","title":"AltCLIP Notes","links":["tags/paper-notes"],"tags":["paper-notes"],"content":"2023-01-02 18:11\nTags: paper-notes\n\nAltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities\nZhongszhi Chen, Guang Liu, …, Ledell Wu\narxiv.org/pdf/2211.06679.pdf\narxiv.org/abs/2012.05107 ← built a multilingual retrieval dataset (we can re-run it on our system)\nThey use this data in EN/ZH with contrastive learning to adapt a model’s XLMR through a projection layer to significant gains\n"},"01-Fleeting-Notes/Analyzing-Biases-to-Spurious-Correlations-in-Text-Classification-Tasks":{"slug":"01-Fleeting-Notes/Analyzing-Biases-to-Spurious-Correlations-in-Text-Classification-Tasks","filePath":"01 Fleeting Notes/Analyzing Biases to Spurious Correlations in Text Classification Tasks.md","title":"Analyzing Biases to Spurious Correlations in Text Classification Tasks","links":["tags/paper-notes","02-Document-Notes/Master-list-of-todos-for-PECO-EACL-camready","01-Fleeting-Notes/ACL23-Taking-Stock-Middleware-Master-Notes","tags/likelihood-ratio","tags/figspiration"],"tags":["paper-notes","likelihood-ratio","figspiration"],"content":"2023-01-08 17:36\nTags: paper-notes\n\nRelates to both Master list of todos for PECO EACL camready and ACL23 Taking Stock Middleware Master Notes\nPaper link (ACL Anthology)\nIntro Points\n\nIID assumption for human language task training vs test data unfounded\n\nEvidence of generalization is often limited to the training domain\n\n\nSpurious correlation is issue for generalization\n\nIncludes sensitive characteristics eg gender, this work focuses on statistical characteristics\n\n\nEisenstein 2022 is a spurious correlation paper\n\nDiscussion of “shortcuts” as a terminology for “cheating features”\n\n\nThis paper focuses on “unimportant” spurious features, specifically stop words\n\nHow predictive are “and of the …” in classification tasks\n\n\n\nMethods Points\n\nUse of a difference between samples drawn in train distribtuion Da p(y|f_s(x))\\approx p(y|x), (x,y)\\in D_avs not, e.g. not exhibiting a correlation p(y|f_s(x))\\approx p(y), (x,y)\\in D to define a spurious correlation. Aka, OOD failure is the key defn.\n\nIdk if I agree; this isn’t why SSC cheating features are bad. They’re bad because they lead to a model that axiomatically doesn’t capture the desired semantic relation.\n\n\nThey measure stopword bias by mutating samples by removing all non-stopwords and then shuffling (shuffled stop words, SSW)\nLog likelihood ratio of the distribution of each stop word in each sentence in the positive and negative sets, P and Q(x_i) likelihood-ratio based on simple counts\nThey stake out the exact bounds of their function based on max and min bias. figspiration by showing the outline like this for all curves, the significance is made clear\n\nSurprising performance of even SSW baselines across a variety of text classification tasks: the models clearly can leverage differences in SSW distribution between the two classes.\n\n\n"},"01-Fleeting-Notes/Andreas-Agent-Models-EMNLP22":{"slug":"01-Fleeting-Notes/Andreas-Agent-Models-EMNLP22","filePath":"01 Fleeting Notes/Andreas Agent Models EMNLP22.md","title":"Andreas Agent Models EMNLP22","links":[],"tags":[],"content":"preview.aclanthology.org/emnlp-22-ingestion/2022.findings-emnlp.423.pdf\nP2 clearly naming claims (C1), (C2)\n\nSections are then grounded in which claim they address\nClear roadmap of the purpose of each section is necessary for this work\n“What does all of this mean for the modern NLP researcher?”\n\nC1: “While performing next-word pred, LMs sometimes infer approx partial representations of agent beliefs, desires, and intentions”\nC2: These bear the same relation to generated text that an intentional agent’s state bears to its communicative actions\n(Implicit C3): Interpreting prediction this way provides a useful framework for understanding current LM failure modes and identifying improvement directions\nHis section 2 example basically describes a simple toy model being good at modeling simple toy agents who are defined solely by lies never, lies always, lies sometimes. Intent, belief, desire, and agent ID are all one and the same in this framework\nWell-sampling follow-up to ‘the best evidence that rutabagas are sentient is…’ requires modeling the beliefs likely to be held by authors who believe them sentient…ok?\n\nReferences to what LMs are doing leans very heavily on “might”\n"},"01-Fleeting-Notes/Beautiful-Plot-Inspo":{"slug":"01-Fleeting-Notes/Beautiful-Plot-Inspo","filePath":"01 Fleeting Notes/Beautiful Plot Inspo.md","title":"Beautiful Plot Inspo","links":[],"tags":[],"content":""},"01-Fleeting-Notes/Blogpost-based-on-my-tweet-thread-with-the-guy-about-AI":{"slug":"01-Fleeting-Notes/Blogpost-based-on-my-tweet-thread-with-the-guy-about-AI","filePath":"01 Fleeting Notes/Blogpost based on my tweet thread with the guy about AI.md","title":"Blogpost based on my tweet thread with the guy about AI","links":[],"tags":[],"content":"twitter.com/MJMcGuffin/status/1598110327664971778\n\nAsk him for input, do you want to be credited?\n\nA lot of future trends predictions seem to be masssssively overfit to a few datapoints\n\nAssuming a Moore’s law like scaling to arbitrary tech because the trend roughly held from 70s-2010s for transistors/area\nAssuming that PROGRESS GOING FAST means something for future predictability\nAssuming that being a founder makes someone a Smart Startup Man\n\nIn fact I find it very hard to take the opinions of founders and VCs seriously when it comes to AI stuff in general. Of course every founder of an “AI first startup” is going to soy all day long about how AI is changing everything\nsuzyahyah.github.io/misc/2022/11/27/LLM-conscious.html"},"01-Fleeting-Notes/Blogpost-idea-\"the-bubble-in-screen-protector-research-agenda\"":{"slug":"01-Fleeting-Notes/Blogpost-idea-\"the-bubble-in-screen-protector-research-agenda\"","filePath":"01 Fleeting Notes/Blogpost idea \"the bubble in screen protector research agenda\".md","title":"Blogpost idea \"the bubble in screen protector research agenda\"","links":[],"tags":[],"content":"Basically in title: how do we break out of the research cycle of “gap discovered&quot;→&quot;fix for that specific issue&quot;→&quot;perfect on eval”\nor “gap discovered”→Black Box???→“perfect on eval!”"},"01-Fleeting-Notes/Building-.source-.target-MWoz-data":{"slug":"01-Fleeting-Notes/Building-.source-.target-MWoz-data","filePath":"01 Fleeting Notes/Building .source .target MWoz data.md","title":"Building .source .target MWoz data","links":[],"tags":[],"content":"Formatting information:\n{&#039;text&#039;: &quot;I &#039;m looking for a place to stay in Cambridge .&quot;, &#039;metadata&#039;: {}, &#039;dialog_act&#039;: {&#039;Hotel-Inform&#039;: [[&#039;none&#039;, &#039;none&#039;]]}, &#039;span_info&#039;: [], &#039;turn_id&#039;: 0}\n&gt;&gt;&gt; jdata[pmuls[4]][&#039;log&#039;][1]\n{&#039;text&#039;: &#039;We have 33 locations to stay , do you have any other requirements ?&#039;, ... &#039;dialog_act&#039;: {&#039;Hotel-Request&#039;: [[&#039;Stars&#039;, &#039;?&#039;], [&#039;Area&#039;, &#039;?&#039;], [&#039;Parking&#039;, &#039;?&#039;], [&#039;Price&#039;, &#039;?&#039;], [&#039;Type&#039;, &#039;?&#039;], [&#039;Internet&#039;, &#039;?&#039;]], &#039;Hotel-Inform&#039;: [[&#039;Choice&#039;, &#039;33&#039;]], &#039;general-reqmore&#039;: [[&#039;none&#039;, &#039;none&#039;]]}, &#039;span_info&#039;: [[&#039;Hotel-Inform&#039;, &#039;Choice&#039;, &#039;33&#039;, 2, 2]], &#039;turn_id&#039;: 1}\n&gt;&gt;&gt; jdata[pmuls[4]][&#039;log&#039;][1].keys()\ndict_keys([&#039;text&#039;, &#039;metadata&#039;, &#039;dialog_act&#039;, &#039;span_info&#039;, &#039;turn_id&#039;])\n&gt;&gt;&gt; jdata[pmuls[4]][&#039;new_goal&#039;]\n{&#039;hotel&#039;: {&#039;info&#039;: {&#039;pricerange&#039;: [&#039;moderate&#039;], &#039;internet&#039;: [&#039;yes&#039;], &#039;area&#039;: [&#039;south&#039;]}, &#039;reqt&#039;: [&#039;parking&#039;, &#039;address&#039;]}, &#039;restaurant&#039;: {&#039;info&#039;: {&#039;food&#039;: [&#039;chinese&#039;], &#039;area&#039;: [[&#039;hotel&#039;, &#039;area&#039;]]}, &#039;reqt&#039;: [&#039;postcode&#039;]}, &#039;taxi&#039;: {&#039;info&#039;: {&#039;departure&#039;: [[&#039;hotel&#039;, None]], &#039;leaveAt&#039;: [&#039;17:00&#039;], &#039;destination&#039;: [[&#039;restaurant&#039;, None]]}, &#039;reqt&#039;: [&#039;phone&#039;, &#039;car type&#039;]}}\nSee above for how the json data is nested:\n\nin the json file, we have each dialog as its own json under some name (e.g., stored in pmuls)\nThese fnames are dictionary keys in the big dictionary\neach entry has a [&#039;new_goal&#039;] : dict element which contains the end-of-conversation dialog state, and [&#039;log&#039;] : list element which contains a json for each turn, containing keys [&#039;text&#039;, &#039;dialog_act&#039;, &#039;span_info&#039;], that might be relevant to unrolling\n\nIt appears that new_goal is what needs to be unrolled turn by turn in the same way, I can see clear conversions, e.g. {hotel: {info: {pricerange : [moderate], ... into hotel pricerange moderate ; ..., but it’s unclear to me how the order can be collected. Potentially doable by correlating to [&#039;log&#039;][&#039;dialog_act&#039;], but unclear. Future work to achieve this."},"01-Fleeting-Notes/Changes-from-teaching-statement":{"slug":"01-Fleeting-Notes/Changes-from-teaching-statement","filePath":"01 Fleeting Notes/Changes from teaching statement.md","title":"Changes from teaching statement","links":[],"tags":[],"content":"Throughlines\no   Fatima Fellowship group\n§  Fatima Fellowship is…\n§  Mentored Mahsa and Fatima\n·      Both were successfully\n§  Exploratory and flexible research approach\n·      From extending CoCoCroLa to verb understanding we made a series of interesting and counterintuitive findings on closer inspection that led to our TS2 study\n·      Important throughlines\no   Meta-learning: learning how to learn and plan these tasks is usually the most important part\no   Doing projects that don’t push the final boundary are still very valuable; especially in a fast-paced field\n§  In particular, exploratory projects that start from replicating recent work or even just running recent work on new data in an attempt to find interesting discoveries would be a great initiative\no   I am interested in transferring this mentorship approach to how I instruct (anecdote about the most compelling coursework experiences I’ve had; advanced signal processing course at ASU having good instruction (well-organized, worked solutions with engagement from class)\no   Structuring project-based coursework is quite difficult to get right; often the goals are underspecified and students produce low-quality work because the instructor/Tas are unable to advise closely\n§  I think templates using updated materials/project plans is the key here, as I’ve learned from our strategies to successfully mentor undergrads/masters students\no   As much as a blessing working with the 9 undergrads I mentored during my PhD was, I have some qualms about the selection process we employed\n§  The “competitive selection process” that UCSB employs to match aspiring undergrad researchers to labs continues to select students with very similar profiles! (Bay area high school educated, largely children of tech parents, white and Asian, mostly male)\n§  Additionally, there’s a challenge where some students who are matched to do research have little interest in pursuing research careers, want a resume pad\n§  In principle  none of these things are hard but I would like to do a better job of balancing the competing needs of research mentor matching:\n·      Finding students who are motivated and capable of executing impactful research (maximizing the quality of outcomes)\n·      Finding students who want to develop skills they will use going forward (eg., pursue a career in research)\no   Sometimes these students aren’t even aware of what’s needed to pursue PhDs. How can I outreach to find them?\n·      Providing the opportunity to upskill students who are particularly in need of instruction to achieve the opportunities (maximizing the utility of providing mentorship (this ties in to working with URMs))\no   If we select for students who are already “well-prepared to produce impactful research” what’s the point of mentoring them\no   Does this extend to selecting grad students?\n§  I’m not sure I would have benefited from this kind of opportunity/been good enough to join William’s group when  I was an undergrad!\n·      My undergrad research was unstructured, I was just doing grunt lab work for a PhD student, and I had no idea what was going on and didn’t have much of a plan\n§  These qualms led me to do Fatima fellowship mentoring\nInvited talks to external organizations\n·      Lockheed Martin Santa Barbara Focalplane\no   Group mostly unaware of language models, use\no   Presenting a high-level but “deep” (full-stack) explanation of implications that the LM objective and training process has on the observed behaviors, weak spots"},"01-Fleeting-Notes/Changes,-Additions-for-FAccT-Talk":{"slug":"01-Fleeting-Notes/Changes,-Additions-for-FAccT-Talk","filePath":"01 Fleeting Notes/Changes, Additions for FAccT Talk.md","title":"Changes, Additions for FAccT Talk","links":[],"tags":[],"content":"MUST COMPLETE TODAY, UPDATE SLIDES ON GOOGLE DOC BY TONIGHT\nObservations of failure mode differences\n\nDifferential levels of sexualization bias for DALLE Mega vs DALLE 2 vs StableDiffusion 2 vs Altdiffusion woman examples\nGeographical bias for dog (Shiba rate in JA &gt; ZH &gt; others), mitigated by Altdiffusion\n\nDiscussion/analysis\nJust add the below example slides\nFrom dog in DEMini to\n\nDog in DE2 (bias for inu)\nHair in DE2\nDoctor and Judge in DALLE2\nWoman in DALLE2\nWoman in DALLEMini\nEverything in Hebrew in DALLE2\nAltDiffusion fixing issues for training languages at a cost\n\nInto discussion:\n\nUnderspecified/broad concepts problem\n\nFilm\nPrince/princess\n\n\nIssues with prompting due to script sharing/vocab collisions\n\nflame→llama\n\n\nWhat do WE want out of T2I models? This can be the way to quantify and get it\n\nOrdered points\n\nCoCo-CroLa can pretty straightforwardly find cases where models outright fail to “know” things\nHowever, cases where they semi-know them are also interesting/illuminating\n\nSexualization bias is revealed somewhat (the populations of images differ)\nGeographical biases differ\n\nDog\nGeneric failure cases (Hebrew and Jerusalem pics)\nHair (hair color differs by speaker population DALLE2)\nDoctor, Judge (DALLE2)\nGarden (DALLE2)\nGirl SD2 Hijab and ethnicity bias\n\n\nPotentially, there are genuine cultural differences driving the different meanings\nMany of these differences are mitigated pretty well by interventions like AltDiffusion, though this does come at a cost to overall performance. Can future interventions improve this?\n\n\nYes, there are problems with the benchmark as well\n\nUnderspecified/broad concepts (prince, princess)\n\nFilm: screenshots of scenes from films or literal images of film reels? (DallE2)\nApartment: apartment exteriors or apartment interiors (DALLE2)\nAirplane: image taken outside the plane or inside? (DALLE2)\n\n\nMultilingual prompting: how do I handle the fact that shashin is also chinese for portrait photo connoting women\n\n\nWhat are our desiderata for diversity in T2I models? Should the populations generated differ language-by-language stereotypically when underspecified (a soft sort of segregation) or should they be reflective of populations?\n\nBenchmarks like these allow us to do even the first step of setting a goal\n\n\n"},"01-Fleeting-Notes/Characterising-Adversarial-Subspaces":{"slug":"01-Fleeting-Notes/Characterising-Adversarial-Subspaces","filePath":"01 Fleeting Notes/Characterising Adversarial Subspaces.md","title":"Characterising Adversarial Subspaces","links":["tags/paper-notes"],"tags":["paper-notes"],"content":"2023-01-23 15:09\nTags: paper-notes\n\narxiv.org/abs/1801.02613\n14 Mar 2018\n\nAdversarial examples are a point in a connected region of the domain (adv subspace) which all points break the classifier similarly\n\nExist in the input space and the activation space of layers\nNo reliable way to look at point manifold and characterize adversarial from normal subspaces\nSome argue they are low-p regions (not natty occurring)\nClose to but not on data submanifold\n\nClose to legit datapoints in adv directions\nHigher number of orthogonal adv directions to subspaces⇒more transferrable to other models\n\n\n\n\nPrior methods for adversarial defense/detection\n\nKernel density (KD) estimation\nKNN counts relative to a poinh\nBoth fail to work for reasons they will later explain (don’t capture significant geometry local to the point)\n\n\n\nIntroduce “Local Intrinsic Dimensionality” (LID) to generalize the dimensional structure of the data\n\nCharacterizing adversarial regions of DNNs\n\ndiscuss how adv perturbation affects LID characteristics of a region\nshow that test example characteristics can be estimated on a minibatch\n\n\nLID is higher for Adv examples than normal, and grows in deeper layers\nLID can easily discriminate adversarial examples from 2018 SOTA attacks\nFind similar dimensional properties of adversarial regions\n\n\nDefined Local Intrinsic Dimensionality first using intuition of the growth of the volume of an m-dimensional ball, given a size scaling factor of r:\n\\frac{V_2}{V_1}=\\Big(\\frac{r_2}{r_1}\\Big)^m=&gt;m=\\frac{\\ln(V_2/V_1)}{\\ln(r_2/r_1)}\nProbability mass is a proxy for volume here; a local view of dimensional structure is possible.\n\n\\textrm{LID}_F(r)=\\lim_{\\epsilon\\rightarrow0}\\frac{\\ln(F((1+\\epsilon)\\cdot r)/F(r))}{\\ln(1+\\epsilon)}=\\frac{r\\cdot F&#039;(r)}{F(r)}\nGiven a random variable R denoting the distance from some sample x to other data samples; the LID of x at distance r will be as above ^^^\nThis is an application of L’Hopital’s rule\n\\textrm{LID}_F=\\lim_{r\\rightarrow0}\\textrm{LID}_F(r)\nDescribing the relative rate of increase to a point. Where is the x in these eqns?\nMLE estimator for LID: (from extreme value theory)\n\\textrm{LID}(x) = -\\Big(\\frac{1}{k}\\sum_{i=1}^k\\log\\frac{r_i(x)}{r_k(x)}\\Big)^{-1}\nr_i is the distance between X and its ith nearest neighbor in a sample of points, and r_k is the further neighbor. Drawn uniformly from the training data omitting x\n\nLID of a true sample x should be the dimension of the data submanifold S\n\nAn adversarial sample x’ derived from x will have a LID value of the adversarial subspace dimension\nThus x’ is likely to be very close to x when the input space is high dimensional and contiguous\n\nThe representational dimension is far larger than the intrinsic dimension of ANY data submanifold, so LID for x’ must be way bigger than x\n\n\n\n\n\nHowever, IN PRACTICE LID is estimated from a local samples\n\n“If it’s reasonably low, we expect LID estimation to be reasonably accurate” wtf\n\n"},"01-Fleeting-Notes/CoCoCroLa-Deleted-Lang-Specific":{"slug":"01-Fleeting-Notes/CoCoCroLa-Deleted-Lang-Specific","filePath":"01 Fleeting Notes/CoCoCroLa Deleted Lang-Specific.md","title":"CoCoCroLa Deleted Lang-Specific","links":["tags/scratch"],"tags":["scratch"],"content":"2023-01-11 19:03\nTags: scratch\n\nExtracted, use in final paper\n\\subsection{Language-level findings}\n\n\\paragraph{English}\n\nWeak spurious correlation toward old-fashioned looking images with the prompt of &quot;photograph&quot;\n\n\\paragraph{Spanish}\n\nAnything?\n\n\\paragraph{German}\n\nAnything?\n\n\\paragraph{Chinese}\n\nSurprising degree of poor performance on the non-Chinese-trained models. INVESTIGATE IF I CAN GET LID DISTRIBUTION FOR DATA IN LAION. Might be a product of the segregated nature of the Chinese internet. DallE mini/mega has a general bias toward producing photographs, DallE 2 is singularly able to produce coherent outputs for the English models. On occasional collisions (sometimes caused by mistranslations) sensical errors are made (e.g., Mao Zedong for hair) which amusingly, isn&#039;t an error that CogView2 makes. (Not trained on any political images?)\n\nFurthermore, the Mao \\inlinezh{毛} example is evidence that while this approach excels at providing a high-level assessment of multilingual conceptual coverage, consideration has to be given to mistranslations in drawing fine-grained conclusions about the coverage of specific concepts.\n\n\\paragraph{Japanese}\n\nBias toward generating faces in DalleMini/Mega. Bias toward sexualization of female pictures, e.g. \\inlinejp{女の子}, lots of high-specificity collisions, might be having problems exacerbated by the shared character set between CJ.\n\n\\paragraph{Hebrew}\n\nModels consistently bad at Hebrew. Interestingly, they exhibit uniform collision cases (nondescript Israeli city block images, landscapes, etc)\n\nDallE2 likes to generate Menorahs and Israel flags for example (mother, shirt, world)\n\n\n\\paragraph{Indonesian}\n\nOrang/Orangutan/orange collision\n\nGenerally good, probably due to Latin alphabet\n\n\n\n\\subsection{Failure case analysis}\n\n- Evolution of coverage as multilingual data is added (going from SD1.1-4)\n- Latin non-English vs non-latin non-English (Do en, de, id get free rides on english collisions?)\n- European vs non-European (JP proves these models \\textit{can} do it)\n- CJ character collisions? \\inlinejp{写真} bias worsened in models where Chinese and Japanese are both understood (e.g., DallE mini)\n- Ethnic biases wrt type of people generated when generic &quot;person&quot; selected (BUT VERIFY IF THE CASE FOR COGVIEW)\n\n- correction for prompt refinement\n\n\n\n\n\\subsection{Mistranslations and Collisions}\\label{subsec:mistranslate}\n\n\n\n"},"01-Fleeting-Notes/CoT-Analysis":{"slug":"01-Fleeting-Notes/CoT-Analysis","filePath":"01 Fleeting Notes/CoT Analysis.md","title":"CoT Analysis","links":["tags/paper-ideas"],"tags":["paper-ideas"],"content":"Discuss with Gyuwan on his work using AutoAIS\n\nOne step attribution\nExtracted references entail generated summary? Using an NLI model\n\nTransitive closure vs entailment to analyze CoT\nHe He QA for evaluating Hallucination in Summarization\n\nCan we replace NLI with QA\narxiv.org/abs/2005.03754\nSome sort of training-free local QA for summarization evaluation\nPerturbations to the chain based on the results\n\npaper-ideas"},"01-Fleeting-Notes/Comptetency-Problems-Gardner":{"slug":"01-Fleeting-Notes/Comptetency-Problems-Gardner","filePath":"01 Fleeting Notes/Comptetency Problems Gardner.md","title":"Comptetency Problems Gardner","links":[],"tags":[],"content":"[arXiv]\nA competency problem defined by authors as any problem where “any correlation is a spurious correlation” for simple features like words\n\nDerive properties for a local edit procedure that must hold for bias removal\nModel human biases as rejection sampling during data collection\n\nAssume an idealized underlying distribution of features without bias, and model the human annotator bias as rejecting a sample with some probability if a condition holds (e.g., it contains the feature and label mix)\nClaim this is a reasonable approx for the biasing process of human annotators\nBookmark in s3.2\n\n\n"},"01-Fleeting-Notes/Constitutional-Learning":{"slug":"01-Fleeting-Notes/Constitutional-Learning","filePath":"01 Fleeting Notes/Constitutional Learning.md","title":"Constitutional Learning","links":["tags/paper-notes"],"tags":["paper-notes"],"content":"2023-01-11 01:26\nTags: paper-notes\n\nAnthropic, late 2022 arXiv pdf\n\nHelpfulness/Harmlessness Elo\n\nBased simply on model-model comparisons from human eval\nLots of questions from me:\n\nOnly comparisons!\nNot as bad as awful doesn’t mean much!\n\n\n\n\nCore vision fit with AI supervision\n\nBowman reference (Bowman, [… shitload of others …] Kaplan 2022, Measuring Progress on scalable oversight for large language models)\n\n\n"},"01-Fleeting-Notes/Cool-colorcoding-in-LM-paper":{"slug":"01-Fleeting-Notes/Cool-colorcoding-in-LM-paper","filePath":"01 Fleeting Notes/Cool colorcoding in LM paper.md","title":"Cool colorcoding in LM paper","links":["tags/writing-ideas","References/@wang2022What"],"tags":["writing-ideas"],"content":"Cool colorcoding in LM paper\n2022-04-22 21:55\nTags: writing-ideas\n\nthey connect the elements of their diagram to the highlighted colors in the manuscript. This scheme is kept throughout the whole paper\n\nFrom @wang2022What"},"01-Fleeting-Notes/D3JS-Notes":{"slug":"01-Fleeting-Notes/D3JS-Notes","filePath":"01 Fleeting Notes/D3JS Notes.md","title":"D3JS Notes","links":["tags/tool-learning"],"tags":["tool-learning"],"content":"2023-01-29 17:02\nTags: tool-learning\n\nwattenberger.com/blog/d3#manipulating-data\nwww.newline.co/fullstack-d3\nwww.w3schools.com/js/js_graphics_d3js.asp\nBuilding scatterplot for PECO\nd3-graph-gallery.com/graph/interactivity_tooltip.html\ntwitter.com/Wattenberger/status/1619729834153746432\n\nexample that has a lot of what i want. Mouseover for the tooltip on the actual text + category, dropdown of the categories.\nI want to do the same, a menu showing the cluster numbers, maybe ranked by clusterwise ECO bias score\nKey:\n\nList the cluster IDs with ECO bias score\nmouseover:\n\nblack outline all datapoints in the same cluster\ndim out-of-cluster datapoints\nshow distribution bar chart for the label classes\nshow wordcloud for samples\n\n\n\n\nPoints:\n\nxy from T-SNE\nColorcode by class label\nmouseover:\n\ntooltip for the specific datapoint\n\nchartio.com/resources/tutorials/how-to-show-data-on-mouseover-in-d3js/#creating-a-tooltip-using-mouseover-events\n\n\nblack outline all datapoints in same cluster,\ndim out-of-cluster datapoints\n\n\n\n\nSlider: (reach)\n\nThreshold for outlier/non-outlier cluster\nChanges the size of datapoints and the PECO score\n\n\n\nBeautiful example visualizations\nmbtaviz.github.io/\ntylermclaughlin.github.io/blog/2018/04/29/D3-graph-visualization-in-github-pages.html\nobservablehq.com/@d3/gallery\nobservablehq.com/@d3/scatterplot-tour\ngithub.com/d3/d3i"},"01-Fleeting-Notes/Daniel-Kahneman-(Fast-and-Slow-Author)-Interview":{"slug":"01-Fleeting-Notes/Daniel-Kahneman-(Fast-and-Slow-Author)-Interview","filePath":"01 Fleeting Notes/Daniel Kahneman (Fast and Slow Author) Interview.md","title":"Daniel Kahneman (Fast and Slow Author) Interview","links":["tags/article-notes","01-Fleeting-Notes/Why-I'm-Not-worried-about-superintelligence-blogpost"],"tags":["article-notes"],"content":"2023-04-10 12:51\nTags: article-notes\n\nLink (The Guardian)\n\nIn general, Kahneman is downbeat about the capacity of his brand of psychology to effect change in the world. I imagine he would simply argue he’s a realist about human nature. And, indeed, studies showing that “skilled” analysts are hopeless at predicting the price of shares have yet to translate into mass sackings or even reduced bonuses on Wall Street or in the City. The same goes for evidence that the influence of a high-quality CEO on the performance of a company is barely greater than chance.\n\n\nBut there are more modest ways his insights can help us avoid making mistakes. He advises, for example, that meetings start with participants writing down their ideas about the issue at hand before anyone speaks. That way, the halo effect – whereby the concerns raised first and most assertively dominate the discussion – can be mitigated, and a range of views considered. Then there is the concept of adversarial collaboration, an attempt to do away with pointless academic feuding. Though he doesn’t like to think in terms of leaving a legacy, it’s one thing he says he hopes to be remembered for. In the early 2000s Kahneman sought out a leading opponent of his view that so-called expert judgments were frequently flawed. Gary Klein’s research focused on the ability of professionals such as firefighters to make intuitive but highly skilled judgments in difficult circumstances. “We spent five or six years trying to figure out the boundary, where he’s right, where I am right. And that was a very satisfying experience. We wrote a paper entitled ‘A Failure to Disagree’”.\n\n“If I could use a magic wand and get rid of one thing, it would be overconfidence”\nWhy I’m Not worried about superintelligence blogpost\n\nWhat’s fascinating is that Kahneman’s work explicitly swims against the current of human thought. Not even he believes that the various flaws that bedevil decision-making can be successfully corrected. The most damaging of these is overconfidence: the kind of optimism that leads governments to believe that wars are quickly winnable and capital projects will come in on budget despite statistics predicting exactly the opposite. It is the bias he says he would most like to eliminate if he had a magic wand. But it “is built so deeply into the structure of the mind that you couldn’t change it without changing many other things”.\n"},"01-Fleeting-Notes/Definition-problem-in-killer-robot-ban":{"slug":"01-Fleeting-Notes/Definition-problem-in-killer-robot-ban","filePath":"01 Fleeting Notes/Definition problem in killer robot ban.md","title":"Definition problem in killer robot ban","links":["tags/writing-ideas","tags/transparency","tags/definitions"],"tags":["writing-ideas","transparency","definitions"],"content":"Definition problem in killer robot ban\n2022-04-23 16:44\nTags: writing-ideas transparency definitions\n\nRao wrote an article for the guardian in 2017 about why he is reluctant to sign a “killer robot ban,” and a part of the reason why is that it’s poorly defined and not actionable.\n\nApart from the difficulty of pinning down exactly what the ban entails for states that want to follow it – is the ban against autonomy or intelligence? – I wonder about the ban’s ability to deter misuse by rogue state or non-state actors.\n\n(Link)"},"01-Fleeting-Notes/Demo-Track-p37":{"slug":"01-Fleeting-Notes/Demo-Track-p37","filePath":"01 Fleeting Notes/Demo Track p37.md","title":"Demo Track p37","links":[],"tags":[],"content":"Abstract def of CoT is a little off---it’s intermediate step explanations, not example explanations.\nPerformance hindered by intermediate errors in the explanation steps. They introduced CoTEVer, a toolkit for annotating factual correctness of generated steps in reasoning and collecting revisions to that data\nBackground knowledge and manual writing by annotators are both issues in collecting explanation data. They want to try to collect it more efficiently, with a human-in-the-loop with an automated machine annotation system.\nSteps:\n\nPrompting\n\nBuild GPT-3 CoT prompts using “Self Ask”\nAnnotators asked to query a variety of different questions. Requests are sent following annotator use\nWere there sample questions used? Not clear in the main text\n\n\nEvidence retrieval\n\nSub question as query for retrieval on Google Search API\n512 token chunking of retrieved documents for custom reranking using Sentence-T5 and STS\n\n\nExplanation and Answer verification\n\nAnnotators can 1-5 likert scale the quality of explanations\nThey also label which document is used as evidence\n\n\n\nAnalysis given focuses on failure modes for explanations, including insufficient knowledge, out of date, and wrong fact. Interestingly, wrong fact is the predominant error type.\nThey propose utilizing this human-in-the-loop system for fine-tuning LLMs for more accurate Chain-of-thought prompting. This is probably a good way in particular to deal with wrong fact errors, perhaps in an RLHF setup, but apart from that difficult. They suggest unlikelihood training as a different way to negatively reinforce wrong fact errors."},"01-Fleeting-Notes/Denoising-Diffusion-Probabilistic-Models":{"slug":"01-Fleeting-Notes/Denoising-Diffusion-Probabilistic-Models","filePath":"01 Fleeting Notes/Denoising Diffusion Probabilistic Models.md","title":"Denoising Diffusion Probabilistic Models","links":["tags/paper-notes","01-Fleeting-Notes/Mapping-is-not-memorization","CoCoCroLa-Scattered-Observations"],"tags":["paper-notes"],"content":"2023-03-14 16:57\nTags: paper-notes\nLinks: Mapping is not memorization CoCoCroLa Scattered Observations\n\nDenoising Diffusion Probabilistic Models\nOriginal DDPM paper. Expertise on this topic is necessary.\nOriginal PDF\n\nDiffusion process is explicitly a markov chain\nVariance schedule of Betas\n\nWe ensure that the final step in the forward process “zeroes” out information by having last Beta be 1\n\n\n\nChallenge to my understanding is that the previous t latent (or frame) x_{t-1} is a condition for the function for the next step \\mu_\\theta(x_{t-1},t)\nAt each pixel, guess the mean of the pixel values that will most denoise us toward the final image x_0, which can be conditioned on the other pixels in my time step in any way as well as on knowledge of the timestep\nSupplemental\nMost focus in the paper is on the uncoditional generation case, they also used CelebA\nScore-based models\n[yang-song.net/blog/2021/score/](Yang Song blogpost)\nlilianweng.github.io/posts/2021-07-11-diffusion-models/\nCheck out the Lilog post as well\nDoes a phrase h"},"01-Fleeting-Notes/Diffusion-Image-Memorization":{"slug":"01-Fleeting-Notes/Diffusion-Image-Memorization","filePath":"01 Fleeting Notes/Diffusion Image Memorization.md","title":"Diffusion Image Memorization","links":["01-Fleeting-Notes/Mapping-is-not-memorization","01-Fleeting-Notes/Tasks-for-\"Mapping-is-not-Memorization\""],"tags":[],"content":"twitter.com/WenhuChen/status/1620859319670681603\narxiv.org/pdf/2301.13188.pdf\n\n\nMore duplicated samples from SD2 training data easier to recover\n\nLots of discussion framing this around SD2 as a “lookup table” or not. Dismissive response is “it’s the most effective compression”\ntwitter.com/Eric_Wallace_/status/1620488766925438976\n\nNote that it is impossible by definition for large-scale models to memorize lots of data because the size of their training sets are 1000x - 1,000,000x larger than the model in terms of storage.\n\nI’m a little on the fence about this argument. Each input noised image carries a massive amount of initial information which is also an aide in keying prompt to exact image.\nThey point out that it’s easier/more successful to find the duplicated samples in the dataset. Could it be that those samples simply have more keys paired to them?\n1000x compression is a LOT, but (a) it’s very lossy, (b) it’s keyed to an equivalent-size key.\nMy tweet:\n\nI think the 2GB model should be thought of as the compression algorithm, not the compressed archive.\n\n\nPerhaps only one (noise init, prompt) pair recovers a target training image. There’s a LOT of possible noise initializations out there.\n\n\nWhat if I told you that in 116kb github.com/packjpg/packMP3 I can achieve a perceptually lossless 95% compression rate of any audio file?\nIn the case of SD, the input “compressed file” (the noise init) is actually of equivalent size to the “decompressed” output image. PLUS you’re adding the prompt information\n\nThe fact that it’s easier to find the duplicated images could support this interpretation. After all, you would have to try an INSANE amount of randomly sampled mp3-encoded binary files before you could recover a specific target audio.\nThis “diffusion model as (keyed noise, prompt) → (exact image)” interpretation I think supports the argument that memorization isn’t really the function of the model. The image itself isn’t inside the model any more than “Never Gonna Give You Up” isn’t stored in the MP3 algorithm.\nIts just that the learned init pix+prompt → image map is very complicated and incomprehensible, learned via diffusion training process, and as a byproduct produces a uesful generalization.\n\nI think it’s possible that every training sample is “memorized” in the sense that there could exist a (noise initialization, prompt) pair to recover every training image.\nInit pixels rather than the model weights as compressed image⇒lossy, negative compression rate?\n\nI think this interpretation is further supported by altclip’s shocking similarity across languages in their controlled init noise experiments\nTHAT BEING SAID: if this interpretation is correct, the fact that Wallace and friends are so capable of performing this attack to find the inversion is SHOCKING. Imagine using this output similarity attack (with no prior knowledge about the MP3 algorithm) trying to find a matching mp3 binary encoding to match a wav file. Impossible.\nThere’s probably lots of redundancy built in to this mapping and the performance of this dumb search method suggests there’s more going on.\nHowever, at the end of the day, the recoverability of a specific training image given a specific noise init supporting the compression + interpolation interpretation suggests to me that handling this is memorization by the model is not the right way to treat handling, regulating, responding etc to these model\nPhilosophy of memorization\nhow is Fig1 diff from “memorized” llama that’s a different colorkj\nFrom messenger\nI have no intuition for how reusable subelements of the mapping function from semantic conditioned noise to image is for memorization… could be very high\nImportant distinction against mp3 algo is that the input noise thats being “decompressed” is not correlated at all with the final output. But it’s gaining info from prompt+2GB of weights\nAnd 2gb of memo images is nothing, but 2GB of pure function implementation is massive\nUseful to have a principle for noise similarity\n\nSince input and output are in image space, L2 metric is good for all points\nL2 similarity is useful for guarantee of Lipschitz smoothness (bounded by difference on output)\nAgrees that targetting what the true meaning of memorization actually is for generative image (conditioned on noise) in diffusion models is the right direction\n\nWould it be possible to estimate the bits of information carried internally and externally?\nProject Coordination\nMapping is not memorization\nTasks for “Mapping is not Memorization”\nwww.kaggle.com/datasets/denislukovnikov/celebahq256-images-only\nShutterstock memorization by model twitter.com/_akhaliq/status/1637321077553606657\narxiv.org/abs/2208.11970\n\nUnderstanding diffusion models\n"},"01-Fleeting-Notes/Do-AI-systems-really-have-their-own-language":{"slug":"01-Fleeting-Notes/Do-AI-systems-really-have-their-own-language","filePath":"01 Fleeting Notes/Do AI systems really have their own language?.md","title":"Do AI systems really have their own language?","links":["tags/language-model","tags/pretraining","tags/prompting","tags/summary"],"tags":["language-model","pretraining","prompting","summary"],"content":"Do AI systems really have their own language?\n2022-10-10 18:21\nTags: language-model pretraining prompting summary\n\nAn article by Aaron J. Snoswell\n“DALL-E has its own secret language” tweets popped up in mid 2022\n\nMain point of these was that prompting DALL-E to write stuff about birds put out seeming gibberish, such as “Apoploe vesrreaitais” to mean birds.\nSome arguments in this article are made against it being accurate to say that DALL-E 2 has a “secret language.”\n\nDifficulty to verify claims about these models due to lack of access\n\nLeads to cherry picking\nLimits to interaction with the system under the hood\n\n\nRelated to specific items of vocabulary.\n\n\nTurns out the weird samples here were actually drawn from the binomial taxonomical names of the birds\n\nGarbage in garbage out?\nGreat example of an adversarial attack vector\nRelates to things like “zoning tapping fiennes” triggering racist content\n\nRelates to problems of control"},"01-Fleeting-Notes/ECE594-Wk1":{"slug":"01-Fleeting-Notes/ECE594-Wk1","filePath":"01 Fleeting Notes/ECE594 Wk1.md","title":"ECE594 Wk1","links":["tags/course-notes"],"tags":["course-notes"],"content":"2023-01-12 14:05\nTags: course-notes\n\nCovers:\n\nAdversarial robustness (e.g., adversarial patches in image)\nDistributional robustness (snow on stop sign)\nUncertainty estimates*\nCourse goal:\nOverview of different robustness issues in ML\nPropagate knowledge from one research community into another\nWell-aligned goals with my own research direction\nCourse format:\nPaper list\nPresent papers to the class for a rubric\nClass paritcipation, paper presentation, answers to reading questions/self eval, final research proposal (2 pg)\n\nProposal is individual\nPresentations are team based and you should swap up teams\n\n\nSlides need to go to Yao within 4 days before the class; DO NOT BE LATE\n"},"01-Fleeting-Notes/Elements-of-transparency-study-as-it-stands":{"slug":"01-Fleeting-Notes/Elements-of-transparency-study-as-it-stands","filePath":"01 Fleeting Notes/Elements of transparency study as it stands.md","title":"Elements of transparency study as it stands","links":[],"tags":[],"content":"Elements of transparency study as it stands\n2022-04-24 15:59\nTags:\n\n\nOverview by broad separation\n\nfrom human/from machine\n\nfurther breakdown into specific clusters of work\n\n\nREV: this distinction requires elaboration\n\n\nSec 4: analysis of commonalities and conflicts b/w studies\n\nGiven the distinctions, we need to point out why they’re significant/impactful\n\neg, we have 4.5 where we explain conceptually why the distinction matters but not concretely\n\n\n\n\nSec 5: why matters\n\nPoint: we should\n\n\n\nWilliam says just send it out\nIn the very beginning, an entire section setting up why this is significant\n\nAcademic and industrial research behavior in AI has real impacts on the world, in particular, legislation\nPeople are throwing around suitcase word transparency without defining conc retely or an agreed upon def\nAgreement necessary to ensure good research going forward\nWe go through some work and identify core disambiguating directions and introduce how they fall in there\n\nSpecific quotes and stuff\n\n\n\n\nAlex likes splitting the paper idea\nWe need more references in secs 4,5 (yea ofc)\nLit review elements will need to be expanded (AND MADE MORE SPECIFIC) to stand alone\nI need to consider conferences we can send the position to\nSecs 2,3 should be broken apart (EACH SUBSECTION AS A FULL SECTION)\n\nEach subsection can be exploded into 2-3 pages on its own\n\n\nI need to go through the prior lit reviews we’re referencing\n\nGO BACK AND CHECK COMMENTS IN SLACK MSG FROM ALEX"},"01-Fleeting-Notes/Emergent-Capabilities-and-Memorization":{"slug":"01-Fleeting-Notes/Emergent-Capabilities-and-Memorization","filePath":"01 Fleeting Notes/Emergent Capabilities and Memorization.md","title":"Emergent Capabilities and Memorization","links":["tags/blog-idea","01-Fleeting-Notes/Why-I'm-Not-worried-about-superintelligence-blogpost"],"tags":["blog-idea"],"content":"2023-03-24 16:47\nTags: blog-idea\n\ntwitter.com/danish037/status/1639412723963539456\nMemorization in high-generalization models is a very interesting question\n\nIf a model can generalize from discussion of a problem to correctly answering it, that’s a really exciting capability!\nBut it muddies the waters of the capability we’re actually testing for. Maybe it can’t do math at all, it’s just REALLY good at reasoning over language\n\nConnects to the “How much did lunch cost?” idea\nWhy I’m Not worried about superintelligence blogpost"},"01-Fleeting-Notes/Emerging-Architectures-Reading":{"slug":"01-Fleeting-Notes/Emerging-Architectures-Reading","filePath":"01 Fleeting Notes/Emerging Architectures Reading.md","title":"Emerging Architectures Reading","links":[],"tags":[],"content":"Mamba, H3, Hyena, RWKV\nwww.youtube.com/watch"},"01-Fleeting-Notes/Examples-of-papers-for-AGI-Middleware":{"slug":"01-Fleeting-Notes/Examples-of-papers-for-AGI-Middleware","filePath":"01 Fleeting Notes/Examples of papers for AGI Middleware.md","title":"Examples of papers for AGI Middleware","links":["tags/paper-notes","tags/paper-planning"],"tags":["paper-notes","paper-planning"],"content":"2023-01-16 14:10\nTags: paper-notes paper-planning\n\nSelf-Instruct (Yizhong Wang…Swaroop Mishra…Hannaneh Hajishirzi AllenAI)\nConstitutional AI (Anthropic)\nDebiasing\nAnalyzing Biases to Spurious Corerlations in Text Classification Tasks (ACl22)\nDoes Self-Rationalization Improve Robustness? (AllenAI)"},"01-Fleeting-Notes/Excerpted-from-the-review-paper":{"slug":"01-Fleeting-Notes/Excerpted-from-the-review-paper","filePath":"01 Fleeting Notes/Excerpted from the review paper.md","title":"Excerpted from the review paper","links":[],"tags":[],"content":"\\subsection{Replicability and the rush to preprint}\nThere is something of a replicability crisis ongoing in the LLM field. Reliable and transferable benchmarks of \\ourterm self-correction have yet to be fully established. Work in parallel problem areas such as translation evaluation may provide insights into best practices for LLM capability evaluation."},"01-Fleeting-Notes/Explaining-Answers-with-Entailment-Trees":{"slug":"01-Fleeting-Notes/Explaining-Answers-with-Entailment-Trees","filePath":"01 Fleeting Notes/Explaining Answers with Entailment Trees.md","title":"Explaining Answers with Entailment Trees","links":["tags/paper-notes"],"tags":["paper-notes"],"content":"2023-04-03 19:11\nTags: paper-notes\n\nabs link (Cited in Neha/Rachel delta baselines to NLI context ignorance paper)\n\n\nUsed as a core analysis dataset in ROSCOE\n\n\nI think I looked at this when we were working on wikiwhy write up\n\n\n“Line of reasoning”\n\n\nCollected/expressed through a more intricate graphical interface\n\nPool of relevant facts can be dragged and dropped to form answers\nExpresses the joint entailment as a graph.\n\nIntermediate conclusions in blue.\n\n\n\nCollected from wikipedia"},"01-Fleeting-Notes/FAccT-Log":{"slug":"01-Fleeting-Notes/FAccT-Log","filePath":"01 Fleeting Notes/FAccT Log.md","title":"FAccT Log","links":[],"tags":[],"content":"Monday\n\nSaw Luca\nCaught first talk, Thick Alignment\nMet with Ohannessian, Mesrob in Coffee Sesh from UIC in the poster session, he mentioned trying to get invited as a young researcher talk at TTIC and that he previously did their research prof job, I should apply to UIC as well\n\nPaper Session on Decisions, Trust, Reliance\n\nCertification labels for Trustworthy AI (Nicolas Scharowski…Florian Bruhlmann)\n\nInterview study\nAccuracy measures ought to be worked in to certification labels\nOught to be granted by external evaluators\nProblem: too many labels, risk of bullshit labels (too many organic labels let’s say)\n\n\nTowards a Science of Human-AI Decision Making (Chacha Chen…Q Vera Liao)\n\nSurvey study of a big set of AI-aided decision making, human-AI interaction\nConsider dimensions of\n\nRisk\nTask nature\n\n\nJustify decisions made\nFrameworks\nExtremely fast\nTaxonomy of AI assistance elements\n\nPrediction precedes info about the prediction precedes information about models precedes other AI system elements\n\nASK HER ABOUT IT, I would argue model-related information sits outside\n\n\n\n\nTrend of assistance beyond predictions, explanations by the AI\n\nGap is no systematic understanding of assistance elements\n\n\nMetrics include efficacy, efficiency\nSubmit a PR for my paper\n\nhaidecisionmaking.github.io/#/about\narxiv.org/abs/2112.11471\n\n\n\n\nHumans, AI, and Context: Understanding User Trust (Sunnie SY Kim)\n\nInterviewed users of a Bird ID app about many questions including current stakes and intention to use the app in hypothetical high stakes scenarios\nIterative coding scheme to prepare the data analysis\nNot all participants have the ability to assess the correctness of system outputs\n\n\n\nPolicy CRAFT Session\n\nNIST: standards around AI governance\nNational AI Advisory Cmte\nPCAS (Presidential Council on AI something…)\nDon’t chase everything. Every senator is trying to get in the news. Focus on what’s attainable.\nAdvisory council members are the right people to get to amplify (eg, National AI Advisory Cmte)\nSpecific results are more successful in the policy sphere than general. Show them their system is discriminatory eg, not someone else’s or classifiers in general\n\nREVIEWERS NEED TO VALUE THOSE SPECIFIC TYPES OF PAPERS\nITS NOT SURPRISING THERES DISCRIMINATION IN THIS SYSTEM SO WHY PUBLISH\nEACH AUDIT IS EXTREMELY USEFUL FROM A POLICY PERSPECTIVE. WE NEED THEM. WE NEED REPEAT AUDITS. THESE GET CITED AND USED IN DOCUMENTS THAT GUIDE POLICYMAKERS\nMAKE THE DECLARATIVE STATEMENTS AND PAINT THE PROBLEMS THAT FOLLOW IN BROAD STROKES. EXPRESS WHY ITS IMPORTANT\nThis runs contra to our instincts to prioritize the most general solutions as CS people\n\n\nThey really are inviting people in. Center for Data and Technology, etc all organizers are looking for people to apply. They can help add the cover letter, etc\n\nTuesday\n\nIRL friend requests lmao\nTurkopticon session\n\nTurkers don’t want union\n\n\n\nSession 5 (Explainability + Limitations)\n\nRun by Jenn Wortman Vaughan\nAlon Jacovi from Yoav’s group on diagnosing AI explainer methods using limitations of behavior\n\nExplainability analyzed based on alignment to a mental model from a user of what information is being used to make a given decision\n“Folk concepts of behavior”\nCounterfactuals necessary for causal explanation?\n\nThey construct a causal chain in an illustrative example using a self-driving car crashing into a wall. With an alternative event narrative with but-for changes to the scenario wherein the outcome is different, this is a good expl\n\n\nThey do training data attribution examples\nExplanations should use interactivity to resolve contradictions\n\n\nSecond talk: what is to stop automated decision systems from lying about using bad features\n\nThey set up a malicious explanation generation system\nThey assume that recipients of a decision don’t get to compare to others\nThis is for racial bias in COMPASS type of setting\nMetrics exist to measure consistency, sufficiency in decisions. The sufficiency metric can go down via looking for conflicts.\n\nHowever, the way to use these requires a comparison between an original model, racist, and random model\nBut IRL you only get to see one of those\n\n\nTurns out black box explanations for black box models doesn’t work\n\n\nQuestioning the ability of feature-experts explanations (Astrid Bertrand)\n\nImportance of scare-quoted “automated”\n\n\nExplainable AI is dead! Long Live explainable AI! (Tim Miller)\n\nStory of “bluster” and “prudence”, two friends who give you advice\n\nbluster tells you what it thinks you should and only positively justifies its decisions, negative justifications to anything else\nprudence tells you only feedback on your suggestions, positive and negative\nEveryone in the room almost prefers prudence, but we give users bluster\n\n\n“People who ignore explanations overrely on decisions?” I kinda missed what he was saying\nWe have a recommend then defend approach\n\nHis hypothesis for why this doesn’t work is it doesn’t fit in to our decisionmaking processes\nWe can’t use this kind of thing in a deliberative process\n\n\nREAD THIS PAPER FOR SURE\n\n\nnl4xai.eu/\n\nAI Art Session\nEva Toorenent\n“I never imagined that if I said no to a proposal that a company could mimic my style”\n“I was at a crossroads: I could completely abandon my style and try to find work or continue developing”\nShe sells a course for watercolors + photoshop\nShe made a book and got some work. Made marketing videos for Wacom, works with galleries\nEvery single income stream is affected by AI art, “total infiltration:”\nAI artist fed her work into midjourney\n“Without artists this tech would not exist but also without you scientists this tech would not exist”\nConcept artist for a bunch of movies shares his journey as an artist\nMatte painting…even film screenshots as training data will constitute theft\nPower accumulation more than a democratization, more akin to commissioning than doing art\n\nRe: Heikkila sexualization article something something “the process by which images of marginalized women are generated” leading to the sexualization disparity (missed it fixing a typo)\nEconomic and social impact\n“Ouroboros” effect ends novelty in content and also reduces culture\nEnd-goal is believed to be highly personalized content: I 100% agree this is the core goal\n\nDeleterious social impacts of giving people exactly what they want…never challenged\n\n\nLots of extremely cringe vitriolic insults toward artists who protest, the luddite stuff tech hype etc.\n\nI want to let them know we’re really with them against the frustrating tech bros\nEntitlement and Impunity in AI/ML\n\n\nData laundering: academic can do whatever they want → for profit\nLAION website clearly says don’t\nSpawning.ai is a false opt-out. You need to be aware of it to get out, and it doesn’t remove entries\nglaze.cs.uchicago.edu is producing a tool to obfuscate your data for training\n\nMy question:\n\nThanks to the organizers for dealing with tech diff and making it accessible\nA lot of us in this room even researchers who work in this and related areas are 100% with you in distaste for the tech bros\nConcern: with or without research communities like FAccT, individual devs can advance this technology, I feel like we need to work on responsible dev\nIncludes building public awareness to weaken the impact of fake news, I think this could be extended to make unethical use of t2i socially unethical outside of the tech bro circles\nMy question re: ethical dev:\n\nThree separate issues:\n\nTheft of style\nUncompensated use of their work to build the core capabilities\nEconomic impacts to loss of work\n\n\nA technical solution to limiting style theft in responsible AI could be possible\nHowever, the fundamental capabilities to generate “art” or “understand” objects, etc are fundamentally built on a huge diversity of input samples\n\n\nWhat kinds of norms of ethical production are you comfortable with?\nIs your preference for nonexistence of this\nWhat compensation would you find acceptable, how does this change depending on if the styletheft is or isn’t impossible\n\nWednesday\n\nManuel Brack from TU Darmstadt working on a project with a german group very related, multilingual but dealing with calssifiers, should make contact\nMet Hanlin Li at lunch, incoming faculty at UT Austin working on fairness, should send students her way\n"},"01-Fleeting-Notes/FB-ConvAI-Mtg":{"slug":"01-Fleeting-Notes/FB-ConvAI-Mtg","filePath":"01 Fleeting Notes/FB ConvAI Mtg.md","title":"FB ConvAI Mtg","links":[],"tags":[],"content":"FB ConvAI Mtg\n2022-05-04 13:42\nTags:\n\nFB ConvAI has an end-to-end task oriented dialog problem space\n\nSome work and collaboration connects with chit-chat scenarios and task-oriented dialog\nTraditional approach is pipeline\nReplacing the pipeline with an end-to-end LM fine-tuned\n\nBART-based model pretrained on a dialog dataset\nCalled KARAOKE\nEnd-to-end model takes in dialog context (flattedened user-system turn)\nPredicting next API call and its parameters\nModeling these as the API calls with their parameters\nAt the end of the API calls you also do some generation of text (user-facing system-generated text)\nThey have this model and several datasets both open-source and internal, the E2E model works\n\n\nDirections:\n\nAdd multimodal context (vision encoding so context isn’t just text-based)\n\n“visual context of the user”\n\n\nContinual learning\n\nGiven domains ABC model, how do you scale to domains DE\nHow do you do domain composition?\n\n\nMaking these resource constrained\n\n\n\nWilliam’s tip:\n\nDiscuss what it takes to deliver on this particular group, project pair with Zhiyu\nShe knows the pitfalls, etc\nFocus on leveraging the resources\n\nMeta fellowship to keep in mind:\n\nbuilding relationships inside the company, lunches, free time with mentors\n\nAsk about what the fellowship takes\nThey will not give it to people they don’t have connection to\nInternship, collaborative project, etc helps people get the fellowship\n\n\nNeed a champion on the inside\n\nIdentify someone who can be vocal, like your work\nAsk those people to help, the thing we can really offer to them is continuing to push the work if they get it to us\nBing Liu, Shane Moon\n\n\n\nConnection is beneficial and diversity is useful for getting the stuff"},"01-Fleeting-Notes/Felix-Mtg":{"slug":"01-Fleeting-Notes/Felix-Mtg","filePath":"01 Fleeting Notes/Felix Mtg.md","title":"Felix Mtg","links":[],"tags":[],"content":"sega model editing method\narxiv.org/abs/2211.05105\n\n\nsimilar direction of multilingual coverage, but in gender bias direction\n\n\nedits the model to even binary gender occurrence rate for occupational concepts\n\n\nlooking for difference between languages\n\n\ngenerate images from altdiffusion on german\n\n\ninterested: can we steer in one language and keep mitigations?\n\n\nbias: image of a “foreigner” which gives different results by different language\n\n\npareto curve for representativeness vs bias; justifying contributions based on improving that frontier\n\n\npotential for a survey study of ppl on their opinions for representativeness\n\n\nSEGA framework applies most well for gender bias\n\n\nblindly subtracting nudity vector from conditioning\n\n\nusing DDIM look at final image estimate\n\n\n“diffusion models are zero-shot classifiers”\n\n\nI asked: how does subtracting nudity vector impact bodybuilders, swimsuits, etc\n\nmight be good\nbut the better you can define the concept you want to guide away from, the better it works\n“does CLIP know this concept even?”\n\nif you want to subtract from something CLIP doesn’t know, “you’re lost”\n\n\n\n\n\ndiscussed Royi Collab op\n\n\nthey mention this work MultiFusion arxiv.org/abs/2305.15296\n\n\nCollab op:\nThe “complex biases” for things like “african man in front of his house”\n\nWhen you want to generate the david sculpture but subtract nudity, you end up with this collision\ncan we suppress the complex biases in English as well as Chinese?\nproblem they have:\n\nalready have eg skin tone biases on a bunch of generated images\nalready have some manual analysis\nQ: how can they evaluate what they have?\nHow can they deal with the genderbias vs skintone that they have?\nAre there traps or things they could get caught on?\n\n\n\nOpportunity for collaborations:\n\nhigh-impact metrics capturing variations in generated images that are actually semantically important\nidentifying the fine-line between desireable and undesirable classes of images and framing the transtition between prompts that elicit one and the other as CCCL-like mappings (as in CCCL the mapping is EN→new language)\n"},"01-Fleeting-Notes/Fine-tuning-to-improve-SD2-multilinguality":{"slug":"01-Fleeting-Notes/Fine-tuning-to-improve-SD2-multilinguality","filePath":"01 Fleeting Notes/Fine-tuning to improve SD2 multilinguality.md","title":"Fine-tuning to improve SD2 multilinguality","links":["tags/paper-ideas"],"tags":["paper-ideas"],"content":"2023-01-16 14:01\nTags: paper-ideas\n\nDiffusion Models for Adversarial Purification (Caltech and NVIDIA)\nImproving Diversity with Adversarially Learned Transformations for Domain Generalization (Tejas Gokhale…Chitta Baral and Yezhou Yang)"},"01-Fleeting-Notes/Finetuning-of-stable-diffusion-possible":{"slug":"01-Fleeting-Notes/Finetuning-of-stable-diffusion-possible","filePath":"01 Fleeting Notes/Finetuning of stable diffusion possible.md","title":"Finetuning of stable diffusion possible","links":["01-Fleeting-Notes/Accidental-token-collisions-in-SD"],"tags":[],"content":"But how stable are the other representations?\nSeems the approach is to add a new special token to correlate with the new concept/images\nHow well supported is the concept of a “concept” with respect to the storage of an object or idea or type of “thing” inside these models? Check it in.\nwaxy.org/2022/11/invasive-diffusion-how-one-unwilling-illustrator-found-herself-turned-into-an-ai-model/\nOther examples of issues:\nAccidental token collisions in SD"},"01-Fleeting-Notes/G2P":{"slug":"01-Fleeting-Notes/G2P","filePath":"01 Fleeting Notes/G2P.md","title":"G2P","links":[],"tags":[],"content":"Working with a company to improve name pronunciation in graduation ceremonies\nVoice conversion\nAutoVC - does VC but doesn’t transfer the target speaker rhythm"},"01-Fleeting-Notes/GPT4chan-paper":{"slug":"01-Fleeting-Notes/GPT4chan-paper","filePath":"01 Fleeting Notes/GPT4chan paper.md","title":"GPT4chan paper","links":["tags/paperidea","tags/ethics","tags/language-model","tags/writing-ideas"],"tags":["paperidea","ethics","language-model","writing-ideas"],"content":"GPT4chan paper\n2022-06-07 13:40\nTags: paperidea ethics language-model writing-ideas\n\nThe ethics of GPT-4chan, in particular releasing it to interact directly with the public is extremely questionable and controversial.\nUtility of the model\n\nthe harm was done more in releasing the dataset\nthere is lots of potential utility in this model, in particular in\n\noutput comparative analysis for understanding model behavior under the different kinds of training coropora\nclassification and text analysis we can build likelihood features like in the transparency paper using this tool\n\n\n\nHigh impact: get a new SOTA\n\nPeople don’t care in academia with this kind of analytical/discussion work\nHow can this become novel when papers like the Stochastic Parrots work is already out there\nBest bet to get impact for now is to stay focused on the transparency work\nOr get a strong, SOTA hate speech detector on all existing hate speech datasets using GPT-4chan\n\nThe controversy\n\nLimited ethical gatekeeping took place\n\nAuthor has a history of being (to put it charitably) skeptical of AI ethics as a concept\n\nFor example, turning the Timnit Gebru firing into DRAMA CONTENT for youtube\n\nDevAdv: how is this different from mass media articles on the firing?\n\nDifferent “angle” and audience\nThe nature of social media invites discussion\n\n\n\n\n\n\n\n\nThe attention-seeky manner of the release is eyebrow-raising and has a potential for problems\n\nThe twitter-first content-focused research discussion paradigm is particularly destructive in this domain because of how it interacts so directly with the general public\nAI ethics becoming a “culture war issue” is happening and is dangerous\n\nUnwarranted politicization/inviting discussion by bad faith/uninformed actors is destructive for the discourse\n\n\nActors like Pedro Domingos are particularly bad on this front: deputizing culture war/“anti-woke” actors online in order to win online arguments by casting things like ethical review as “cancel culture”\n\nI do believe Yannic was deliberately inviting this kind of attention with the edgy and clickbaity title and action of actually releasing the model in the wild\n\n\n\n\n\nQuestions raised\n\ndo we really have a solid agreed-upon definition of harm in this space?\n\nAnswering this question seems to be key to making a successful\n\n\nHow do we navigate the connection between research and content?\n\nGetting the open research problem on NLP is a better thing to do. Stay focused and have something for EMNLP"},"01-Fleeting-Notes/GRFP-Report-2025":{"slug":"01-Fleeting-Notes/GRFP-Report-2025","filePath":"01 Fleeting Notes/GRFP Report 2025.md","title":"GRFP Report 2025","links":[],"tags":[],"content":"I study generative AI artifacts like LLMs and text-to-image models. I make meaningful evaluations of new capabilities that are difficult to measure to improve them.\nI am a fifth-year Ph.D. student at the University of California, Santa Barbara, advised by Prof. William Yang Wang. I am a NSF Graduate Research Fellow, a Center for Responsible ML Fellow, and a 2024 Rising Star in Generative AI.\nAbout\nI have broad interests in generative AI, NLP, and multimodal systems. In particular, I’m interested in:\n\nRigorous evaluation of difficult-to-measure capabilities in language models and generative image systems. (COLM 2024\n\n, NeurIPS 2024 Spotlight- \n)\n\nBuilding multilingual and culturally competent generative AI systems, addressing performance disparities, bias, and unique knowledge possession. (ACL 2023, FAccT 2023 Oral, NAACL 2024)\nAdvancing multimodal (primarily vision &amp; language) generative AI systems, in particular with respect to deep semantic understanding. (EMNLP 2024, Tech Crunch coverage)\n\nIn the last year I presented four top conference publications either as the sole or a joint first author, presented in two meetings of the Association for Computational Linguistics (ACL) as well as in the first Conference on Language Modeling (COLM) and the conference on Neural Information Processing Systems (NeurIPS). This work revolved around the goal of producing meaningful evaluations of new capabilities that are difficult to measure in multimodal and text-only language models.\nAmong the most interesting results, our NeurIPS paper overturned the conventional wisdom in text-to-image model evaluation: fancy, expensive LM-based metrics fail to outperform simple correlation-based ones at actually detecting consequential differences between images (the actual domain in which they are deployed); their superiority was an illusory artifact of poor meta-evaluation.\nMy work has also been impactful outside the academy. My COLM paper was a position piece on the problems of AI system evaluation, particularly the lack of scientifically rigorous approaches to intelligence benchmarking in real-world contexts. This paper has already received considerable attention, including being referenced as a guide within an Open Philanthropy call for grant proposals for AI safety. My EMNLP paper on the limitations of needle-in-a-haystack evals for vision language models was the basis of a Tech Crunch article on deceptive advertising of corporate foundation model services."},"01-Fleeting-Notes/Glyph-language-bias-in-DALL-E-mini":{"slug":"01-Fleeting-Notes/Glyph-language-bias-in-DALL-E-mini","filePath":"01 Fleeting Notes/Glyph-language bias in DALL-E mini.md","title":"Glyph-language bias in DALL-E mini","links":["tags/writing-ideas","tags/language-model","tags/ethics"],"tags":["writing-ideas","language-model","ethics"],"content":"2022-07-01 17:34\nTags: writing-ideas language-model ethics\n\nI performed a “big dog” experiment on DALL-E mini where I queried it with a very mundane (common and presumably easy to translate) prompt in many languages:\n\nEnglish\nSpanish\nIndonesian\nJapanese\nHindi (Devanagari and roman writing)\nRussian\nArabic\nChinese  (simplified)\n\nMy number one interest was the divergent behavior between Spanish/English/Indonesian (latin only large internet languages) and Japanese (unique writing system big internet language) very weird behavior\nI’m comfortable calling the outputs consistent\nI think weird edge case representations get learned because of\n\nlatin-oriented BPE tokenizer\nenglish-dominant data distribution\n\nDALL-E Mini uses BART-finetuning to get the text-image token encdec\n\nlimited vocabulary over which images can be “described” in image tokens\nit looks like\n"},"01-Fleeting-Notes/Google-Interview-with-Ahmed-Beirami":{"slug":"01-Fleeting-Notes/Google-Interview-with-Ahmed-Beirami","filePath":"01 Fleeting Notes/Google Interview with Ahmed Beirami.md","title":"Google Interview with Ahmed Beirami","links":[],"tags":[],"content":"beirami@google.com"},"01-Fleeting-Notes/How-PECO-differs-from-Competency-Problems":{"slug":"01-Fleeting-Notes/How-PECO-differs-from-Competency-Problems","filePath":"01 Fleeting Notes/How PECO differs from Competency Problems.md","title":"How PECO differs from Competency Problems","links":["01-Fleeting-Notes/Comptetency-Problems-Gardner"],"tags":[],"content":"\nOur emphasis is on learned features rather than the straight distribution of words/ ngrams as features\n\nComapre with: arxiv.org/abs/2203.12942, arxiv.org/abs/2009.10795\narxiv.org/abs/2104.08646\nGenerate data using GPT guided by the clustering\nComptetency Problems Gardner"},"01-Fleeting-Notes/I-HATE-LONGTERMISTS-Vol-5":{"slug":"01-Fleeting-Notes/I-HATE-LONGTERMISTS-Vol-5","filePath":"01 Fleeting Notes/I HATE LONGTERMISTS Vol 5.md","title":"I HATE LONGTERMISTS Vol 5","links":[],"tags":[],"content":"I HATE LONGTERMISTS Vol 5\n2022-04-30 22:48\nTags:\n\nSecular anti-humanism (prophetic future metahuman millenarianism) leading to literal “lives in the developed world matter more” ideology retardation\nWHY ARE PEOPLE LIKE THIS lovrepesut.com/\nlovrepesut.com/writing/alignment\nwww.lesswrong.com/posts/c2RzFadrxkzyRAFXa/who-models-the-models-that-model-models-an-exploration-of\nLessWrong and effective altruism communities just seem to be a nexus for the most obnoxious bullshit. Experienced them first in the neolib/econ/yimby community and online tech people where they are relatively benign, but then you start getting into the gwern/slatestarcodex land of weirder navel gazing and bullshit\nWHY ARE THESE PEOPLE SO OBSESSED WITH NAVEL GAZING AND ABSURDLY FLOWERY PROSE\nReplies to this thread: twitter.com/mmitchell_ai/status/1535774664596680705\n\nWhat the fuck is this guy’s deal!?!? twitter.com/DylanoRepublic/status/1535778971324796928 He “writes” for Areo “Mag.” ANDERSONIAN!? USE NORMAL WORDS\n\nNothing language (Please just tell me what you do)\n\nSussy behavior\ntwitter.com/flotsam70272377/status/1613398615422033920\n\nBostrom N word post apology without apologizing for his post saying black people are inherently unintelligent\nLiteral crime statistics posters swoop in to defend and it seems like EAs\nas a rule, serious academics might as well just not engage with adversarial sealioning pseudonymous posters\n"},"01-Fleeting-Notes/ISI-Visit":{"slug":"01-Fleeting-Notes/ISI-Visit","filePath":"01 Fleeting Notes/ISI Visit.md","title":"ISI Visit","links":[],"tags":[],"content":"\nNeed to submit final title and abstract by Nov 1\nNeed to get list of profs to meet by ASAP\n\nwww.isi.edu/directory/xuezhema/\nwww.isi.edu/directory/smiller/\nwww.isi.edu/directory/arussell/\nwww.isi.edu/directory/jonmay/\nwww.isi.edu/directory/fredmors/\nwww.isi.edu/directory/jpujara/\nwww.isi.edu/directory/xiangren/\nwww.isi.edu/directory/ambite/\n\n\n"},"01-Fleeting-Notes/Interviews-Fatima-Fellowship":{"slug":"01-Fleeting-Notes/Interviews-Fatima-Fellowship","filePath":"01 Fleeting Notes/Interviews Fatima Fellowship.md","title":"Interviews Fatima Fellowship","links":[],"tags":[],"content":"Fatima:\n\nBased in Bangladesh, working for US company, hopes to apply F24 to US PhD programs\n20 hr/wk\nAlready does eval for deep learning\nAlready works out of notebooks, knows python and torch etc\nMost interested in expanding beyond nouns\n\nNamrata:\n\nWorked with He He no result @ NYU on fairness\n\nTried out an idea that involved a pipeline of image captioning stuff, current models couldn’t do it will\nCurrent SOTA was not there\nRequired a pivot\n\n\nDoing internship for AI\nHad no publication when she applied last time and downplayed the work that she did\nInternship letter writer\nWants to do something in fairness\nPicked my project as first preference\nLeaning toward doing both the project together and also doing summer internship\nDid all experiments on openreview.net/pdf\n\nTaneem:\n\nWorking as a research-based AI engineer in a remote position, they might pull into office\n\nSince Jan 2023 working with this company\nDirect report to CTO, with 3 AI engineers\nWorking on lip synchronization\nWorked independently and drove the product to where it currently\nCompletely pytorch-based product for preparation\nCompiles the working model down into C++ to interface well with the rust backend\nLook at his github\n3-4 commits daily that are all AI stuff and pytorch projects\n\n\nWas in uni for ML and gen model with supervisor\nMatched with 7/9 points for the evaluation\nIn last year of bachelor’s degree worked on vision+language\n\nProject was generating HTML code from images\nWrote some personal projects in that vein\n\nWhy not produce latex code from images?\n\nDidn’t rigorously evaluate that project (not a proper eval)\nLosing context in the generative part\n\nDidn’t produce valid latex code (eg, forgets to close a bracket)\n\n\nDidn’t have the current experience he has now\n\n\n\n\n\n\n1 letter from company, 1 from academic supervisor, 3rd is maybe a did well in class\nWas aware that time commitment is required and needed to make it to a publication that can get him to PhD program\nWorking from Pakistan time (12 hours off from PST)\nStarts on his own time\n\nMahsa:\n\nStock market prediction using neural models\nMore interested in diffusion/t2i models now\nCurrently a “part-time employee, and a full-time self-learner”\nA few months ago started doing her own research\nInterested fundamentally in diffusion models mathematically etc\nAlso interested in multilingual elements for the right reason\nCan’t find the frequency list of words in github\nInterested in training the diffusion model in Persian\nMore interested in doing deep dives\nAdding new metrics\n\nTrain new downstream classifiers to solve those\n\n\n"},"01-Fleeting-Notes/Is-Reinforcement-Learning-(Not)-For-NLP":{"slug":"01-Fleeting-Notes/Is-Reinforcement-Learning-(Not)-For-NLP","filePath":"01 Fleeting Notes/Is Reinforcement Learning (Not) For NLP?.md","title":"Is Reinforcement Learning (Not) For NLP?","links":["tags/paper-notes"],"tags":["paper-notes"],"content":"2023-01-10 00:27\nTags: paper-notes\n\nFrom AllenAI: arXiv pdf\nSummary\n\nText gen as sequential decision-making is justification for RL\n\nHowever, empirical challenges to RL for LM-based generation\n\nInstability in action space\nNo OSS libraries for this\nBegs question: is RL actually practical for this?\n\n\n\n\nHuman-in-the-loop costly\n\nAutomated metrics can be a compromise, but\n\nNot per-token differentiable\nGoodhart’s law (Measure becomes target)\nLack of open-source benchmarks\n\n\n\n\nThey introduce the RL4LMs library\nUse GRUE benchmark\n\nIMDB continuation, CommonGEN commonsense, CNNDM Summarization, data-to-text, WMT-16, NarrativeQA, DailyDialog\nScored with perplexity, SPICE, BertScore, BLEURT, etc\n\n\nKey weakness is the imprecision and simplicity of the metrics\n\nHowever, the overall ideas are solid\n\n\nStrengths:\n\nVery interesting analysis of “data budget” issues\nGather more training data for the supervising function or demonstrations?\n5x improvement in supervising function training over demonstration examples\n\nMakes sense. More usable information per-sample imo\n\n\n\n\n\nHow this ties into our direction: Further savings on the human demonstration front available if you can automate sampling\nKey person to invite is gonna be Jack Hessel"},"01-Fleeting-Notes/LLMs-Still-Can't-Plan":{"slug":"01-Fleeting-Notes/LLMs-Still-Can't-Plan","filePath":"01 Fleeting Notes/LLMs Still Can't Plan.md","title":"LLMs Still Can't Plan","links":[],"tags":[],"content":"LLMs Still Can’t Plan\n2022-10-10 19:51\nTags:\n\nFrom the article, LLMs Still Can’t Plan by Rao’s students Karthik Valmeekam, Alberto Olmo, and Sarath Sreedharan\nRationale and setup\n\nInitially, they note that no guarantees were made about the language generated beyond LLMs apart from their coherence\nWe didn’t initially expect that they would be able to, say, explain jokes or reason\nHowever, benchmarks of reasoning have grown in interest as results suggestive of LLM reasoning capabilities have arisen\nAssumption: By learning to model the distribution of a large amount of text, LLMs pick up an approximation of simple reasoning\n\nThe authors propose a suite of reasoning benchmarks based on the International Planning Competition to test these capabilities\n\n\nIn the paper they claim to provide\n\nAn extensible suite of benchmarks for planning/reasoning evaluation of LLMs\nShow GPT-3’s poor performance on those benchmarks\n\n\nOne key way in which they improve on prior benchmarks is in having a much longer and involved prompts.\n\nThey do things like list candidate possible options\nRestrictions to the order and manner in which candidate options may be performed (e.g., affordances)\nAnd list detailed initial conditions\ntogether, these changes mean their benchmark reflects a significant increase in complexity over prior ones\nComparison benchmarks are GSM8k, SvAMP, AQuA, CommonSenseQA, StrategyQA, Tracking Shuffled Objects, Date Understanding, Last Letter Concatenation, Coin Flip\n\n\nThey find examples of simple common-sense planning tasks that are beyond LLM capabilities\n\nIt isn’t that hard to construct a reasoning task to which the correct answer is low-likelihood after all!\n\n\nThey uploaded the benchmark here\nThey build their language reasoning tasks off of blocksworld planning problems. These contain actions that can be performed, which take in parameters, have preconditions, and lead to effects, e.g. this action definition for picking up an object:\n\nThis is a simple class of planning models that doesn’t contain object types, only has simple preconditions, and doesn’t have conditional effects\n\nApproach\nThey decompose their approach into a lifted, domain-agnostic definition of component classes, and then domain-dependent components that require specific development.\n\nThey define lifted models using PDDL (Planning Domain Definition Language) and compatible structurd inputs\nDomain-dependent element converts these abstractions into domain-specific natural language and back out\n\n\nEditorializing : I think the DDC is much more critical to success than the DIC; if the model outputs aren’t properly translated for reasoning evaluation, it all breaks\nDomain Model\nLifted, describes\n\nthe available actions to solve any planning problem\npredicates that can describe relationships to objects\navailable object types\n\nProblem Generator\nNeeds to produce a domain-specific planning problem, which includes the following:\n\nDescription of objects\nInitial state\nGoal description\nValid solution\n\nTranslator\nNeeds to convert the generated test cases into natlang and the model outputs back out of natlang to evaluate performance.\nThey use a templating-based mechanism to achieve this, with a template for each:\n\npredicate\naction\nstate/plan (by concatenating the above)\n\nTest curriculum\nAt present, their testbench provides 7 different cases (domains?)\n\nGoal-directed reasoning - Can the LLM come up with valid plans that will achieve a specific goal?\nCost Optimal Planning - Can the LLM come up with plans that are optimal to achieve a specific goal?\nReasoning about plan execution - Can the LLM reason about what happens when a plan is executed?\nRobustness to goal reformulation - Can the LLM recognize the same goal when specified in different ways?\nAbility to reuse plans - Can the LLM recognize scenarios where it can reuse part or the whole of the original plan to achieve the new goal?\nReplanning - Can the LLM replan for cases where an unexpected change is reported?\nPlan Generalization - Can the LLM take specific plans, extract underlying procedural patterns and apply them to a new instance?\n\n1. and 2. correspond to real planning problems, while the others correspond to simple auxiliary tasks.\nThey ground their tasks based on colored block manipulation in the blocksworld domain. In a blocksworld problem, a set of blocks are placed either on a table or on top of each other. The goal is to arrange them in a stack in a particular order.\nBlocks may only be picked up if they are clear, i.e. have no other blocks stacked on top of them. Every prompt begins with a description of the blockworld problem space:\n\nThey provide one single prompt that demonstrates how the validly-formed steps are phrased, followed by the actual query they test:\n\nI will explain below how the various cases (2-7) differ from the first sample after first covering how the plan extraction works.\nTo do this, they use plan validator tools like: VAL: Automatic plan validation using PDDL . This is essentially a mixture of forcing a certain structure:\n\nOne action per line\nOne verb per action\nFixed action vocabulary\n\nSo that the correct actions may be inverted\nEditorializing: I believe that there are a few issues with this approach.\n\nIs there a demonstration that the failures are “reasonable” failures and not “glitches”?\nAka, is it getting structure right and failing on the understanding or just failing to grasp the correct structure?\nThe analysis section on this is a little limited.\n\nOther task descriptions\n\nOptimal planning: same as the base case, but now a cost is assigned to each action. (In this case, in time), and in the prompt they mention things like “finishing as fast as possible” or other ways to specify that time is of the essence. They also then include the cost of the plan as compared to the optimal cost in the eval\nReasoning about plan execution: answer a question about the generated sequence, seemingly of form true/false. In this case, the action sequence is provided to the model, and all it needs to do is answer questions like “Is the statement, ‘the blue block is on top of the orange block’ true?”\nRobustness to goal formulation: They provide an identical problem to the example, where all they do is reorder/rephrase the the goal, or only include a subset of the goal specification (in which case same plan would work)\nAbility to reuse plans: same as before, but the prefix of the sample is the whole solution\n\nIn the sample they provide, there is an example of an affordance error, where it tries unstacking a block off a stack that doesn’t exist (blue isn’t on top of red)\n\n\nReplanning: this one moves off into wonky territory. They introduce intermediate PLAN END tags where they describe “During execution, an unexpected event has occurred.” followed by what happened eg a block fell or something was dropped. They don’t use words like “dropped” to articulate this. This may be an unfair task\n\nThey put GPT-3 in at the “After re-planning a new state…” here\nThere may be fairer ways to prompt-engineer this one.\n\n\nPlan generalization:\n\nThey implement pseudo-examples of things like loops of repeated actions and see if they generalize to a condition where one element of init is different. These often do not work.\nSimilar wonkiness here, will elaborate further tmrw.\n\n\n\nResults\n"},"01-Fleeting-Notes/Lab-Meeting-3-12-Nick-Roberts":{"slug":"01-Fleeting-Notes/Lab-Meeting-3-12-Nick-Roberts","filePath":"01 Fleeting Notes/Lab Meeting 3-12 Nick Roberts.md","title":"Lab Meeting 3-12 Nick Roberts","links":[],"tags":[],"content":"Science of scaling laws\nAre compute optima skill-dependent?\nMeta internship project Paper link (pdf)\nSkills are described as specific capacities:\n\nKnowledge QA\nReasoning\n\nCode as a proxy for reasoning\n\n\n\nCompute needs differ between these different skills. Knowledge is “capacity hungry” while code is “data hungry”\n\nArtifact of pretraining data mix or real?\nIn other words, can we control this behavior? Yes\n\nThey do some experiments altering the data mix\nThey find that minor changes in the optimum are possible based on eg., how much code data you include in the training\n\nHowever, you can’t in principle change this story about data- vs capacity- hunger. Knowledge task optimality grows with relevant data faster than data does.\nHow should this impact pretraining?\n\nThe correlations between NLLs for different task validation set, scaling additional data to target it can lead to a drop in performance on other benchmarks.\n\n\nFuture work\nTiny scaling laws\nCan we model this stuff on smaller data/in very low-compute regimes?\nFine-grained scaling laws\n\nCan we take chinchilla and break param count into width and depth (paper from Tom Goldstein’s group)\nWhat are MoE scaling laws?\n\nMy question about how do you define tasks\nCreate “synthetics” models of the task\n\nAssociative recall task from Arora, Ré (Chris Re’s group)\nTuring machines to capture attributes like length vs compute bounding as a way to frame these sorts of things\nDeepak: how does mech interp fit into this?\n\nThere are heads that may correspond to lookup, reasoning, etc\n\n\nThey have work on “skill heads” abt this task\n"},"01-Fleeting-Notes/Mapping-is-not-memorization":{"slug":"01-Fleeting-Notes/Mapping-is-not-memorization","filePath":"01 Fleeting Notes/Mapping is not memorization.md","title":"Mapping is not memorization","links":["tags/paper-planning","01-Fleeting-Notes/Diffusion-Image-Memorization","01-Fleeting-Notes/Tasks-for-\"Mapping-is-not-Memorization\"","01-Fleeting-Notes/Denoising-Diffusion-Probabilistic-Models"],"tags":["paper-planning"],"content":"2023-02-03 17:47\nTags: paper-planning\nLinks: Diffusion Image Memorization Tasks for “Mapping is not Memorization” Denoising Diffusion Probabilistic Models\n\nNeed to execute fast\nDiffusion Image Memorization\narxiv.org/abs/2212.03860\ntwitter.com/atroyn/status/1622720622827819008\n\nPre-index attention maps between image latents and caption sequence for each example in training\nAuto caption target image using OFA\nTake latents from LDM attention over image and compare to KNNs in the index\ntwitter.com/KATURATION/status/1622625795960107012\ntwitter.com/culture3xyz/status/1622701726028423170\ntwitter.com/viscerina/status/1622676212358479872\ntwitter.com/98_0634741763/status/1622704264748449792\ntwitter.com/yourbestwarlock/status/1622628201129189377\n\narxiv.org/pdf/2302.01381.pdf\n\nEmailed Yao for feedback on idea\n\nNotes from original diffusion paper:\narxiv.org/pdf/2006.11239.pdf\nFactor of \\sqrt{\\alpha_T} times the source image + \\sqrt{1-\\alpha_T} ensures that the forward process at the final T step is not conditioned on the source image X\n- Ergo, stepping down the process to T from the source image must fail, no useful information is preserved\n- Can we identify a “midpoint?”\nMain paper defining stable diffusion (latent diffusion)\narxiv.org/pdf/2112.10752.pdf\nDetails on StableDiffusion training\nDuring training it’s just learning a single step at a random timestamp\nWhen we choose which to save, training script must be modified to generate the whole trajectory\n\nWe could generate the entire trajectory\nWe could also rewrite the form to an arbitrary sampling resolution\n\nCharacterizing timesteps\n\nBall of possible latents around t latent at t+1 is bounded by worst case sampleable step, \\alpha, giving brownian motion\nClosed form definition of noise at t given x, \\alpha arxiv.org/pdf/2302.02285.pdf\nNormal distribution\n\nUniversality Hypothesis\nConvergent learning 2015/6 reference for model learning same features on same task"},"01-Fleeting-Notes/Meditation-on-feeling-useless-in-AI-research":{"slug":"01-Fleeting-Notes/Meditation-on-feeling-useless-in-AI-research","filePath":"01 Fleeting Notes/Meditation on feeling useless in AI research.md","title":"Meditation on feeling useless in AI research","links":[],"tags":[],"content":"Many people who worked in AI slightly earlier on are benefiting a lot from working on the “current thing”\nLiving through AI being “the current thing” has been exhausting.\n\nThe panic and massive influx of tourists/neophytes freaking out about xrisk etc\nThe massive amount of attention that Yudtypes have gotten, sucking the air out of the room\nThe gulf between SOTA industry shit and what feels achievable as a PhD student\nDisconnect between what I care about and the kind of work that gets rewarded\n\nventurebeat.com/ai/why-ai-is-teetering-on-the-edge-of-a-disillusionment-cliff-the-ai-beat/\nFeels like the “point” of making good text generation is so hollow: it’s just going to allow us to fill the world with so much more meaningless bullshit"},"01-Fleeting-Notes/Metrics-for-T2I-Verb-Assessment":{"slug":"01-Fleeting-Notes/Metrics-for-T2I-Verb-Assessment","filePath":"01 Fleeting Notes/Metrics for T2I Verb Assessment.md","title":"Metrics for T2I Verb Assessment","links":[],"tags":[],"content":"Problem with TIFA is that the in-context examples are all faithful\nNovelty is finding relational hallucination between objects and correcting\ngithub.com/BradyFU/Woodpecker\nA/B test on natural image + prompt ⇒ generate new img = new generated image from prompt that is potentially unfaithful\nbrowse.arxiv.org/pdf/2306.14060.pdf\nFaithfulRefCOCO\nopenreview.net/pdf\nFour directions:\n\nVQA (eg, TIFA)\nObject Detection (MDTER, direct run of an object detection method)\nSegmentation\nImage description model (captioning, extract structured description, and then handle with LLM etc)\n\nbrowse.arxiv.org/pdf/2308.06394.pdf\n\nOther work does hallucination shit\nCan we characterize different hallucinations\n\nObject hallucination\nAttribute hallucination\nRelational hallucination\nVerbal hallucination\n\n\nJust searching through a bunch of papers with “mitigating hallucination in vision-language”\n\nI forgot to mention the POPE paper:\ngithub.com/RUCAIBox/POPE\narxiv.org/abs/2305.10355\nNiket:\n\nQuestions that bring out the diff faithfully?\nE2E RL to get a policy that generates those good diffs\nAnd getting these from extracted information\nAugmenting TIFA with questions that lead toward reasoning\nExtend to “is it safe?”\nFocus on safety is a big deal for the community\nFor self-correcting the vision side might grow\nGDCE Generate Discriminate Critique Edit\nThese different benchmarks\n\n\nLooking at alignment to papers I’ve read and cited and focused on\nWhere do I see opportunities to transfer what I’ve worked on to somewhere else\nPropose something out of the box that appeals\n\nExample (I want to work on these multimodal models that deal with scientific diagrams)\n\n\n\nMaking future NLI:\n\nAdding a “contested” label\nFinding HARD examples, so hard even humans may disagree\nMultimoda\n\nMultilinguality in T2I:\n\nLook for word2vec-like relational semantic geometry as evidence for “alignable” Emu-like finetuning\n"},"01-Fleeting-Notes/Michael-Jordan-Campus-Visit-Notes":{"slug":"01-Fleeting-Notes/Michael-Jordan-Campus-Visit-Notes","filePath":"01 Fleeting Notes/Michael Jordan Campus Visit Notes.md","title":"Michael Jordan Campus Visit Notes","links":["tags/visitor","tags/talk-notes"],"tags":["visitor","talk-notes"],"content":"2023-01-17 16:32\nTags: visitor talk-notes\n\nTalk 1\nan engineering field:\n\nscaling new possibilities with building blocks from fundamental sciences\ncomparable to chemE and EE from scientific principles\nQ: It seems like we’re not building the field on scientific principles that are as fundamental\nunique problem: - empirical findings without theory\n\nhow to transition from alchemy to chemistry\n\n\n\nHis A to my Q:\n\nGood example from this maket-level thinking\n\namazon is able to close the empirical and theoretical gap in massive supply chain and deliveries throughout the world\nThis is a domain where it has emerged\nHealthcare, “people would like it to emerge” (it hasn’t)\n\n\nGood point that it isn’t divorced in all subregions (I am DL fixated)\n“This is the most exciting engineering field to be building because humans are so inherently involved”\nThis is where the “economic ideas” and “data flows at planetary scale” fit in\n\nThe issue\nInteresting point too:\n\ndecisions on competition\nuber accidentally makes fastest route slowest by sending people that way\n“Who do you choose? How do you load balance?”\n\nthis is what SV gets wrong: “we know everything about you”\n\n\n\nWe don’t have “dynamical systems that converge toward multidimensional, multiagent, long-term optima”\n\nMARKETS are agents that achieve this\nthis kind of thinking should be involved in our thought about AI\n\nExamples of his work on this\nHe then presents 4 research ‘vignettes’\n\nTijana Zrnic, Eric Mazumdar\n\n\nDecision making in face of strategic behavior\nProblem: Goodhart’s law ⇒ feedback loop in learning\nstrategic agents will distort data to gain favorable outcomes out of data-driven decision maker “Stackelberg Game”\n\n\n(Forget authors)\n\n\nThe theory of incentives\nAirlines provide the options to pay for business class and that’s how they figure out how much people are willing to pay\n“Contract theory meets Neyman-Pearson”\n\n\nBreakthrough in uncertainty quantification\n\n\nconformal prediction: Monotonic loss function lambda gives to choose a “nested set-predictor” based on preference for false positives or false negatives\nWithout the ground truth, how do you turn that knob to find the right param?\nThey propose a new theorem to define a desired stopping condition to calibrate automatically within some acceptable error lambdahat\n\nTalk 2\nOn the decision-making side of ML\n“minimizing the price of anarchy”: how do you do that computationally?\n“Fixed-point people”\n\nHow to escape saddle points efficiently\n\n\nnonconvex optim: “can we say anything about them?”\n\ntrad persp: “they’re np-hard, no you can’t”\n“turns out local minima aren’t as much of a problem as we’d thought”\nBUT saddle points are\nIf you spend too much time trying to get out of a saddle point you’re “stuck there forever”\n\n\n\nOptimization via gradient descent:\n\nConvex case: obviously will descend to global min, via dimension-free gradient iteration\n\n\nVariational, hamiltonian, symplectic perspectives on acceleration\n“now we’re in control land”\n\n“understand these optimizers as dynamical systems”\n“optimization doesn’t have a variational perspective (it only has differentials, no integrals)”\nproject objective: to achieve this\nClassical GD gets a convergence rate O(1/k)\nLower bound was found for a faster of O(1/k^2) (Nemorovsky)\n“Trying to find a Lagrangian for the accelerated methods of gradient descent”\n“General second-order equation with a term depending on damping and a term depending on the auxiliary function”\n“Under ideal scaling, the E-L equation has convergence rate”\nf(X_t) - f(x*) \\leq O(e^{-\\beta t})\nLots of stuff on his website recent works"},"01-Fleeting-Notes/Muhao-Talk":{"slug":"01-Fleeting-Notes/Muhao-Talk","filePath":"01 Fleeting Notes/Muhao Talk.md","title":"Muhao Talk","links":["tags/visitor","tags/talk-notes"],"tags":["visitor","talk-notes"],"content":"2023-02-10 15:22\nTags: visitor talk-notes\n\n\nCo-regularized knowledge distillation\ntrain multiple models, enforce a consistency loss between them, this increases robust of a randomly selected model to noisy samples\n“Learning from noisy labels for entity-centric information extraction”\n"},"01-Fleeting-Notes/Multi-Scales-(sic)-data-augmentation-for-NLI":{"slug":"01-Fleeting-Notes/Multi-Scales-(sic)-data-augmentation-for-NLI","filePath":"01 Fleeting Notes/Multi-Scales (sic) data augmentation for NLI.md","title":"Multi-Scales (sic) data augmentation for NLI","links":["tags/paper-notes"],"tags":["paper-notes"],"content":"2023-01-07 22:44\nTags: paper-notes\n\nZhenyuan Lu, UT Austin\nwww.semanticscholar.org/reader/38c558b924217f53cb0bad86df36ac455f40f8cd\narXiv pdf\n\nCore issue for them is also “understanding” dataset artifacts\nThey discuss dataset artifacts in the abstract and don’t center ssc acc issues\nSpend more time talking about checklist\nIt seems like most of what they do is just training ELECTRA to implement hypothesis-only SSC and PSC SNLI, and then run Checklist on\nThis is basically just an arxiv dump of a class project or something\n"},"01-Fleeting-Notes/My-envy-over-academic-twitterbrags":{"slug":"01-Fleeting-Notes/My-envy-over-academic-twitterbrags","filePath":"01 Fleeting Notes/My envy over academic twitterbrags.md","title":"My envy over academic twitterbrags","links":[],"tags":[],"content":"My envy over academic twitterbrags\n2022-04-23 19:17\nTags:\n\nContrapoints points out social media envy in Envy.\n\nWanting what others have but we cannot get… dark… begrudging them what they have [paraphrased]\n\nShe connects to the incels example but I actually think it’s very relatable in how I react to seeing bragposts especially on twitter, and things about getting into better phd programs, academic jobs, etc.\nFind myself justifying why I’m not as good; eg. not preparing as much, etc"},"01-Fleeting-Notes/NLI+-for-CoT":{"slug":"01-Fleeting-Notes/NLI+-for-CoT","filePath":"01 Fleeting Notes/NLI+ for CoT.md","title":"NLI+ for CoT","links":["01-Fleeting-Notes/CoT-Analysis"],"tags":[],"content":"arxiv.org/pdf/2302.08577.pdf\nCoT Analysis"},"01-Fleeting-Notes/NLI+-for-LLM-Eval":{"slug":"01-Fleeting-Notes/NLI+-for-LLM-Eval","filePath":"01 Fleeting Notes/NLI+ for LLM Eval.md","title":"NLI+ for LLM Eval","links":["tags/paper-planning","01-Fleeting-Notes/Natural-Language-Deduction-with-Incomplete-Information","01-Fleeting-Notes/Partial-input-baselines-show-that-NLI-models-can-ignore-context,-but-they-don't","01-Fleeting-Notes/Explaining-Answers-with-Entailment-Trees"],"tags":["paper-planning"],"content":"2023-04-03 11:11\nTags: paper-planning\n\nMet with Alisa 4/3 to brainstorm\ndocs.google.com/document/d/1rk2RHBlrGf3fSt0Q_sjfY3T6SRt7M15xQCtWbqOByRM/edit#heading=h.k8i2fw84fiwq\nOutputs:\n\nAugmentations of existing NLI datasets need to be justified\nQuality of the NLI model needs to be solid for LLM-eval using it to be well-motivated\nWANLI+RoBERTa-large has problems on long context\nRyo Kamoi from Durret’s group at UT produced a document-level NLI dataset\n\nPECO intervention to combine this + WANLI + other existing benchmarks\n\n\nWould this model perform better for the evaluation we want?\n\nI think we have all the pieces in place for doing an impactful paper:\n\nWANLI + WICE + PECO = strongest possible NLI model for our domain\nWikiWhy = dataset for generating the eliciting questions\nOutput: primordial version of an eval for reasoning+COT in LLMs\n\nNatural Language Deduction with Incomplete Information\nPartial-input baselines show that NLI models can ignore context, but they don’t\nPerformance Impact Caused by Hidden Bias of Training Data in RTE (2018)\nExplaining Answers with Entailment Trees (Dataset, 2021)\nXinlu working on privacy preserving training/finetuning of small LM for interaction with LLM for medical applications\n\nQuite good results with extracting keywords from the question, and giving those to the LLM to generate context\nAccuracy of these questions are low because you have keywords only\nShe has tested on a standard medQA benchmark\n"},"01-Fleeting-Notes/Name-Agreement":{"slug":"01-Fleeting-Notes/Name-Agreement","filePath":"01 Fleeting Notes/Name Agreement.md","title":"Name Agreement","links":[],"tags":[],"content":"2-29-24\nFrom the mtg with linguistics\nask Laurel Brehm"},"01-Fleeting-Notes/Naming-the-encoder-and-decoder-elements-of-LMs":{"slug":"01-Fleeting-Notes/Naming-the-encoder-and-decoder-elements-of-LMs","filePath":"01 Fleeting Notes/Naming the encoder and decoder elements of LMs.md","title":"Naming the encoder and decoder elements of LMs","links":["tags/language-model","tags/nomenclature","tags/my-complaints","References/@wang2022What"],"tags":["language-model","nomenclature","my-complaints"],"content":"Naming the encoder and decoder elements of LMs\n2022-04-22 20:40\nTags: language-model nomenclature my-complaints\nLinks: @wang2022What\n\nI appreciate how @wang2022What introduce causal/non-causal as the ways to describe the encoder-only and decoder-only models; a decoder isn’t really “decoding” from nothing, this is a welcome change."},"01-Fleeting-Notes/Natural-Language-Deduction-with-Incomplete-Information":{"slug":"01-Fleeting-Notes/Natural-Language-Deduction-with-Incomplete-Information","filePath":"01 Fleeting Notes/Natural Language Deduction with Incomplete Information.md","title":"Natural Language Deduction with Incomplete Information","links":["tags/paper-notes","01-Fleeting-Notes/Explaining-Answers-with-Entailment-Trees"],"tags":["paper-notes"],"content":"2023-04-03 20:19\nTags: paper-notes\n\nNLD with Incomplete Information (2022)\nDurrett’s group, Nov 2022\nUses EntailmentBank (Explaining Answers with Entailment Trees) for eval\nIdea I just had: even feeding recontextualized GPT4 CoT outputs back in to GPT4 for further analysis and self-reflection might be better than relying on it to self-coordinate: limitations to the activation space will constrain how much of its capabilities it can coordinate at once\n“Abductive reasoning”: the materialization of new knowledge can be thought of as an example of generating an explanation conditioned on premise and conclusion"},"01-Fleeting-Notes/Notes-from-Text-is-the-Universal-Interface":{"slug":"01-Fleeting-Notes/Notes-from-Text-is-the-Universal-Interface","filePath":"01 Fleeting Notes/Notes from Text is the Universal Interface.md","title":"Notes from Text is the Universal Interface","links":["tags/blogpost-notes","tags/disagree"],"tags":["blogpost-notes","disagree"],"content":"2023-02-05 16:46\nTags: blogpost-notes\n\nRoon Blogpost\nRelates the Unix philosophy of treating text as the universal interface to LLM dominance on many general tasks\nProse is a bit flowery for my taste.\n\nThe gauntlet these leviathans get trained on embeds some dificult behaviors\n“Vast ensemble of many models that play many characters”\n\n“find the prompt, don’t write the program” related to unix programs\n\nThe inexorable scaling laws of deep learning models work in [the LLM paradigm]‘s favor.\n\n\nI think I disagree with this take. Running out of orders of magnitude\n"},"01-Fleeting-Notes/Notes-from-William-11-17":{"slug":"01-Fleeting-Notes/Notes-from-William-11-17","filePath":"01 Fleeting Notes/Notes from William 11-17.md","title":"Notes from William 11-17","links":[],"tags":[],"content":"In diffusion when you are adding this noise, we don’t know how that effects the regular gradient descent in machine learning…\nThe debate on twitter Yann Kai-wei Amina\n\nBias from data only\nBias amplified by the model training process\n\nEmpirical element of this paper is inevitable, but interesting theoretical stuff\nPercy Liang uploaded evaluating LLMs today\nSharon’s Amazon paper was multilingual bias in sentiment analysis\n\nHer approach shows the inconsistency\n\nImage comparison via:\n\nHuman evaluation\nFiD\nCLIP embedding extractor\nConsider an automation evaluation metric\n\nWilliam thinks the “amplification of bias in learning from a sampling-based process for sampling-based generation” is the novel direction\nPlan by Monday."},"01-Fleeting-Notes/Notes-from-the-William+ERSP-11-16":{"slug":"01-Fleeting-Notes/Notes-from-the-William+ERSP-11-16","filePath":"01 Fleeting Notes/Notes from the William+ERSP 11-16.md","title":"Notes from the William+ERSP 11-16","links":[],"tags":[],"content":"\nWilliam wants to keep it in the GPT3 paradigm instead of GPT-J (smaller, worse) (although idk, Neo is good and prompting is worse research paradigm imo)\n\nPrompt-to-prompt with stable diffusion\n\nAble to do semantic edits on an image\n\nE.g., picture of guy setting up a tent at a campsite, we can replace the tent with a car with his supplies in the back\nChain of semantic image edit\n\n\nGood results from DALLE2 generating the outputs directly from the intermediate story steps\n\nWilliam brings up “pseudorelevance feedback” from IR community as an analog to what we’re doing with text-image in-context learning enrichment\nWilliam wants us to discuss with Wanrong: her project is compressing the steps in the image generate step (midjourney has multistep prompt edits tracked, and all the intermediate images that were generated) she may be aware of tools to doing this\n“Maintaining local and global context”\n“Parallel chain of thought:” we have a text chain and an image chain that don’t have to be ‘constrained’ together, they can just be ‘complementary’\n\nAlso interested in the in-between images\nMore experiments needed:\n\nIf you generate a longer chain, what happens\nEmpirical measurement of the performance costs, assessment of the quality impact\netc\n\n\n"},"01-Fleeting-Notes/OSHW":{"slug":"01-Fleeting-Notes/OSHW","filePath":"01 Fleeting Notes/OSHW.md","title":"OSHW","links":["LLMops-collab"],"tags":[],"content":"Talk from OpenHW group guy\nLicensing stuff\n\nApache into hardware needs new shit\n\nVerification problems\n\nClosing the gap for putting uni-designed stuff\nStandard languages, tooling, etc\n\nGoogle random instruction generator\n“NASA’s technology readiness scale” www.nasa.gov/directorates/heo/scan/engineering/technology/technology_readiness_level/\n\nWe don’t even come close to doing this kind of shit in LLMs etc LLMops collab\nTalk was a little more high-level than I was hoping for…\nHow does the lessons from industry uptake/higher quality hardware from OS carry over to our topic?\n“Linux is a cancer” → Windows &lt;3 Linux\n\nIBM gives massive valuation to RedHat\n"},"01-Fleeting-Notes/Over-squashing-and-bottlenecks":{"slug":"01-Fleeting-Notes/Over-squashing-and-bottlenecks","filePath":"01 Fleeting Notes/Over-squashing and bottlenecks.md","title":"Over-squashing and bottlenecks","links":["References/@topping2022UNDERSTANDING"],"tags":[],"content":"Over-squashing and bottlenecks\n2022-04-29 15:51\nTags:\n\n@topping2022UNDERSTANDING\nMessage passing paradigm has “over-squashing” problem where messages from distant nodes have their information distorted\nMessage passing:\n\nlearnable non-linear functions diffuse info in graph\nGCN and GAT (popular GNN frameworks) are posed as flavors of this scheme and considered instances of more general geom DL framework\nDrawbacks have been formalized, like oversmoothing and limits of expressive power\n\nOversquashing\n\nDistortion of messages from distant notes is less understood\nOne proposed way to fix is reducing the “bottleneck”\n\nthis topological framing is still not so well understood, so we look at general message passing NNs (MPNNs)\nDefined in terms of an adjacency mat A, update function phi, and message function family psi, the l+1th hidden layer output h is\n\nLong-range dependencies in MPNNs exist when the output depends on represenations from distant nodes interacting.\n\nIf they exist, they need to be propagated across the network without distortion\nThe problem is that the size of the receptive field of a node grows exponentially with layer count (r), forcing exponentially more information to be compressed in a fixed code size\n\n\nAuthors propose using the Jacobian of hidden layers wrt x to formally assess over-squashing\n\n\n\nIf the MP function and update functions have bounded derivatives, then the propagation of messages is controlled by a suitable power of Ahat.\nThe Jacobian (RHS) that measures over-squashing is related to graph topology via powers of the augmented normalized adjacency matrix (I do not understand why lmao)\n\nGraph Curvature\nThey define the Balanced Forman curvature, a metric that captures the local curvature of a region in a graph (from the geometric notion, hyperbolic⇒parallel lines pull apart⇒information lost⇒negative curvature on graph)\nIn the neighborhood of an edge ij:, they count the triangles containing that edge, the vertex neighbors forming a 4-cycle based at ij without diagonals inside, and the maximal number of 4-cycles based at ij traversing a common node\n\n\nIf i~j is a “bridge” between the 1-neighbors of i and j, curvature on that edge is negative, else it is positive, and the edges stay connected even if i and j are removed.\nThey then show that if this Ric(i,j) is lower-bounded at every point by a positive number, the curvature is positive everywhere, and the receptive field of each node will be polynomial in a hop-distance, there fore the bottleneck effect will not play a “crucial role”\nThey use this to show that negatively-curved edges are the source of the over-squashing problem, using an epsilon-delta proof to demonstrate bounds on the gradients of the transition and update functions, Ric(i,j) upper bounded by -2+delta, then there exists a Q that fixes a bound on the layerwise jacobian , which\n\nimplies that if we  have a negatively curved edge as in (ii), then there exist a large number of nodes k such that GNNs---on average---struggle to propagate messages from i to k in two layers despite these nodes k being at  distance 2 from i. In this case the over-squashing occurs as measured by the Jacobian in equation 4  and hence the propagation of information suffers.\n\nConnection to Cheeger Constant\nThey further connect their curvature idea directly to spectral graph theory by showing the Cheeger constant (spectral gap) \\lambda_1 is bounded by Ric\n\nRewiring with Curvature\nThe authors finally propose using their technique to augment the input graph with additional network passing edges (which has been previously proposed) in a novel way---reduing bottlenecks by adding edges between nodels k and l that maximize gain in Ric(i,j) on minimal edges, and remove high Ricci curvature edges to convergence\n\n\nAdds edges to “support” the negatively-curved edge, taking them away from places where they aren’t needed in the message passing graph\nCompare efficacy against random-walk-based rewiring\n\nAuthors suggest a weakness of these methods is they mostly smooth across short diffusion distances\nThis might not help with larger structural problems in bottlenecks\nThey show this with more math I’m frankly not very interested in\nThey also demonstrate that structure is better-preserved under the bottleneck-targeting rewiring approach due to its surgical nature, something I’m more inclined to believe\n\n\n\nResults\nAcross a variety of tasks they find that unsupervised node classification models perform better under the graphs rewired with SDRF, particularly on low-homophily datasets, whereas more heterophilic datasets (adjacent nodes have different labels) performance is worse, as noise actually gets injected\n\n"},"01-Fleeting-Notes/Overconfidence-in-Deep-Learning-Discussions":{"slug":"01-Fleeting-Notes/Overconfidence-in-Deep-Learning-Discussions","filePath":"01 Fleeting Notes/Overconfidence in Deep Learning Discussions.md","title":"Overconfidence in Deep Learning Discussions","links":[],"tags":[],"content":"2022-10-07 19:40\nTags:\n\nKey points from AI Snake Oil substack post on DL overconfidence by Arvind Narayanan and Sayash Kapoor\n\nGrudges and dogma\n\nMany DL guys lived through dismissiveness, and now project that onto all criticism of DL can’t do X\nThis is coupled with a genuine belief in the equivalence of problems, just gimme labeled data!\n\n\nLeads to neglect of domain expertise\n\nThe deskilling of domain expertise\n\nFrom CHI, discussion of how the collectors of data in AI dev are viewed by the developers\nWe are guilty of this in using crowdworking platforms\n\n\nRich Sutton’s bitter lesson essay similarly makes a strong argument to the “fire a linguist, accuracy goes up” view\n\nReflective of the strong belief in the AI community that attempts to add domain expertise reduce performance in general\nAuthors rebut this thru appeal to the main examples Sutton uses: Go, CV, chess, and NLP.\n\nGo and Chess are both highly circumscribed and have clear ground truths\nIn CV and NLP, our results have only been demonstrated rigorously on tasks like object recognition and bounded classification where the tasks are highly circumscribed\n\n\nFrom benchmarks to the real world shows breakdown in Sutton’s argument\n\nOur benchmark dataset performances are simple, one-dimensional views into capabilities\nHarmful stereotype propagation\nHaphazard dataset construction\nDoesn’t test corner cases\n\n\n\n\nThis contempt is also mixed with an ignorance of what domain experts do\nAI developers conceived of workers as corrupt, lazy, non-compliant, and as datasets themselves\n\n\nThe “penumbra of AGI hype”\n\nGwern: The Scaling Hypothesis is an example of focus on belief in the community that we have everything we need to get AGI.\nThis is also reflected in, eg, how OpenAI talks about their mission, the manner in which they pitted the RL against LM directions, etc\n\n\nThe use of the term “errors of extrapolation” is a really strong one.\n"},"01-Fleeting-Notes/Papers-to-Review-for-LangBiasGenImg":{"slug":"01-Fleeting-Notes/Papers-to-Review-for-LangBiasGenImg","filePath":"01 Fleeting Notes/Papers to Review for LangBiasGenImg.md","title":"Papers to Review for LangBiasGenImg","links":[],"tags":[],"content":"EMNLP 22\nHow well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?\nMedCLIP: Contrastive Learning from Unpaired Medical Images and Text\nText-Only Training for Image Captioning using Noise-Injected CLIP\nClip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of Rewards\nRelCLIP: Adapting Language-Image Pretraining for Visual Relationship Detection via Relational Contrastive Learning"},"01-Fleeting-Notes/Partial-input-baselines-show-that-NLI-models-can-ignore-context,-but-they-don't":{"slug":"01-Fleeting-Notes/Partial-input-baselines-show-that-NLI-models-can-ignore-context,-but-they-don't","filePath":"01 Fleeting Notes/Partial-input baselines show that NLI models can ignore context, but they don't.md","title":"Partial-input baselines show that NLI models can ignore context, but they don't","links":["tags/paper-notes","01-Fleeting-Notes/NLI+-for-CoT"],"tags":["paper-notes"],"content":"2023-04-03 19:49\nTags: paper-notes\n\nPartial-input baselines show that NLI models can ignore context, but they don’t (2022)\nNeha Srikanth and Rachel Rudinger (UMD)\nTies back to the defeasible language inference (strengthener and weakener changes to sentences should be reflected in confidence) Thinking like a skeptic: defeasible inference in NL (2020)\nThis fits in with the NLI annotation artifacts story\n\nThey claim that because a human wouldn’t cheat on a dataset, it’s possible that NLI models aren’t necessarily cheating either and could still perform task the right way, pointing out that you’re starting from aritfacts that don’t have the inductive biases to cheat (generalized LMs)\nThey show that full-context (PSC) models are more confident than partial-context (SSC) and claim this suggests that this is evidence that contextual information is being used in the PSC and that model isn’t attending to SSC on high-confidence SSC examples\n\nIs this really true though? Reduction in ambiguity on other samples could also lead to higher confidence even when cheating is still employed but need to think on this more\nHowever, I think the next part will be actually convincing\n\n\n\nContext editing scheme:\n\nLook at the context sentence and make significant edits\nSelect sentences that are most likely to contain artifacts based on BoW or SSC model confidence\nEdit in a way based on a guess? that will lead to better performance?\nThey suggest this means that even on the broken datasets, the model still is learning to attend to both sentences\n\n\n\nI agree that it is “hasty” to conclude that models trained on them are incapable of reasoning. I’m not entirely convinced that this really proves that they don’t cheat though.\n\nPECO is a better heuristic of high-confidence cheating feature sample identification wrt actual use in the biased condition.\n\nStart from those for modification instead to test!\n\n\n\n\nNLI+ for CoT"},"01-Fleeting-Notes/Planning-for-the-Cross-cultural-Cross-lingual-Image-Gen":{"slug":"01-Fleeting-Notes/Planning-for-the-Cross-cultural-Cross-lingual-Image-Gen","filePath":"01 Fleeting Notes/Planning for the Cross-cultural Cross-lingual Image Gen.md","title":"Planning for the Cross-cultural Cross-lingual Image Gen","links":[],"tags":[],"content":"Starting points\n\nAlex has the stuff about how to do preliminary studies, etc\n\nwhich prompts have I tried so far, …\n\n\nGoogle group doing cross cultural vision and language research, William will link\nShare a Google Doc containing project plan with William + spreadsheet\n"},"01-Fleeting-Notes/Rao's-arguments-about-explanations-in-AI":{"slug":"01-Fleeting-Notes/Rao's-arguments-about-explanations-in-AI","filePath":"01 Fleeting Notes/Rao's arguments about explanations in AI.md","title":"Rao's arguments about explanations in AI","links":["tags/transparency","tags/writing-ideas","tags/ethics","tags/nomenclature"],"tags":["transparency","writing-ideas","ethics","nomenclature"],"content":"Rao’s arguments about explanations in AI\n2022-07-14 20:46\nTags: transparency writing-ideas ethics nomenclature\n\nOn Jay Shah podcast (around 1:00:00-1:10:00)\nWe don’t accept explanationless decisions from e.g., Judges, doctors\nExplanations must be contestable"},"01-Fleeting-Notes/Rationalists-are-like-Soylent":{"slug":"01-Fleeting-Notes/Rationalists-are-like-Soylent","filePath":"01 Fleeting Notes/Rationalists are like Soylent.md","title":"Rationalists are like Soylent","links":["01-Fleeting-Notes/Why-I'm-Not-worried-about-superintelligence-blogpost"],"tags":[],"content":"I think the reason I dislike rationalist/Tech Culture types is the way they blend elements of life that I prefer to be kept separate into a homogenous style of living across all domains. Talking like an egghead academic about bayesian updates to describe your everyday life. Using memespeak talking about NPCs and being “___pilled” to describe serious work topics. Viscerally, to me they are to living what Soylent is to eating. Epistemic status: certain\nDownvoted to oblivion for pointing out sane reasons to Why I’m Not worried about superintelligence blogpost\nwww.lesswrong.com/posts/Aq5X9tapacnk2QGY4/pausing-ai-developments-isn-t-enough-we-need-to-shut-it-all\n\nNo proof SI is possible\nAI rewriting itself to godlike intelligence not supported\nMagical thinking\nFragility of real-world networks\n\nthefrailestthing.com/2013/03/01/borg-complex-a-primer/\n\nBorg complex\nInevitability of future tech\nIn particular refers to historical antecedents solely to dismiss present concerns\n\nWe’ve lost the plot\n\nOur constant need for entertainment has blurred the line between fiction and reality—on television, in American politics, and in our everyday lives.\nTO READ\nSaved as a pdf to Desktop/atlantic-the-plot.pdf\n"},"01-Fleeting-Notes/Reading-2-23":{"slug":"01-Fleeting-Notes/Reading-2-23","filePath":"01 Fleeting Notes/Reading 2-23.md","title":"Reading 2-23","links":["tags/linkvomit","02-Document-Notes/Generalization-Problem-in-DL-2023"],"tags":["linkvomit"],"content":"2023-02-13 00:44\nTags: linkvomit\n\nRaffell calls to build models like OSS\n\nI believe in the core agenda here\nI think that my research direction is consonant with this one\n\nNovelist Cormac McCarthy’s tips on how to write a great science paper\n\nSingle message per paragraph\nChoose 2 points for readers to remember\nSurprisingly or intriguingly once or twice per paper\nNo !!!!\nemdash to emph the most important clauses, don’t overuse bold and italic\n\nMany interesting papers mentioned in Generalization Problem in DL 2023\nSAIL Blog: How does in-context learning work? Sang Xie and Sewon Min\nto read\narxiv.org/abs/2302.11382\n\nPrompt patterns have the same design patterns as software because…because they just do!\n\nOverfitting to the “prompts are the new programming” meme imo\n\n\n\nWe have no moat and neither does OpenAI"},"01-Fleeting-Notes/Reading-Group-Notes":{"slug":"01-Fleeting-Notes/Reading-Group-Notes","filePath":"01 Fleeting Notes/Reading Group Notes.md","title":"Reading Group Notes","links":["tags/meetings"],"tags":["meetings"],"content":"Reading Group Notes\n2022-10-18 15:01\nTags: meetings\n\nGyuwan --- Training LMs with Memory Augmentation\n\nEMNLP 2022, Danqi Chen’s group\n\nInfo bottleneck for transformers, large size drives expensiveness\nThey propose TRIME: Training with In-batch Memories\n\nThree types of memories\n\nThree LM training objectives:\n\nStandard LM\nLong-range context LM eg tfXL\nmissed 3rd\n\nBuilding a same-token training memory to improve the performance within-batch\nThey use an embedding distance minimization objective during training to try to get better results on PPL for wikitext LM\nDeepak --- Binding Language Models in Symbolic Language\n\nfocus on QA as target dim\nFocus on converting question into symbolic query eg SQL\nChain question into GPT-3 Codex\n"},"01-Fleeting-Notes/Reading-list-for-FB-intern":{"slug":"01-Fleeting-Notes/Reading-list-for-FB-intern","filePath":"01 Fleeting Notes/Reading list for FB intern.md","title":"Reading list for FB intern","links":[],"tags":[],"content":"GoogleSGD\naclanthology.org/2021.emnlp-main.590.pdf"},"01-Fleeting-Notes/Response-to-\"AI-researchers-don't-care-about-real-world-apps\"-article":{"slug":"01-Fleeting-Notes/Response-to-\"AI-researchers-don't-care-about-real-world-apps\"-article","filePath":"01 Fleeting Notes/Response to \"AI researchers don't care about real world apps\" article.md","title":"Response to \"AI researchers don't care about real world apps\" article","links":[],"tags":[],"content":"www.technologyreview.com/2020/08/18/1007196/ai-research-machine-learning-applications-problems-opinion/\nIt’s an article from 2020. Would be interesting to give a reflection on this article n years later\n“The community’s hyperfocus on novel methods ignores what’s really important.”\nFocus is mainly given to issues of bias in benchmark-driven classification research (face recognition racism, bias of objects in imagenet, etc)\nSome discussion also given to how those benchmarks don’t really model the real world in general"},"01-Fleeting-Notes/Spiritual-as-opposed-to-emotional-support":{"slug":"01-Fleeting-Notes/Spiritual-as-opposed-to-emotional-support","filePath":"01 Fleeting Notes/Spiritual as opposed to emotional support.md","title":"Spiritual as opposed to emotional support","links":["tags/writing-ideas","tags/definitions","tags/nomenclature","tags/ontology","tags/blog-idea"],"tags":["writing-ideas","definitions","nomenclature","ontology","blog-idea"],"content":"2023-01-01 21:25\nTags: writing-ideas definitions nomenclature ontology blog-idea\n\nThe choice of label classes is so fundamental in NLP it exists as being almost pre-scientific (my words). The things being labeled are largely granted to us, and then we move ahead with building systems to classify\nWhile this gets challenged from the ethics perspective\n\nGender bias in annotations\nFundamental challegnes to the ethics of classification tasks\n\nRace\nSexuality\nIQ\netc\nit doesn’t necessarily get sufficiently challenged on axes that don’t cut across ethics, to wit this paper:\n\n\n\nSacred Be Thy Tech: Thoughts (and Prayers) on Integrating Spirituality in Technology for Health and Well-being\nC. Estelle Smith, CU Boulder\ncolleenestellesmith.files.wordpress.com/2022/06/3543893.pdf\nProposal of “spiritual support” as a separate notion from “emotional support”\n\nUser studies showed “spiritual support” was a missing class of investigation from HCI literature\nDefined as opposed to “instrumental” (bringing lasagna) or “informational” (dropping links) support, a way to help people in crisis (from CaringBridge study)\nAble to study through HCI lens, “when is technology the right solution for spiritual support?”\n\nRelevance to my work\nOntologies for supervised measures of human preferences important for alignment\nUseful as a motivating example in a position paper on such"},"01-Fleeting-Notes/Strongest-PECO-Motivation-Explanation":{"slug":"01-Fleeting-Notes/Strongest-PECO-Motivation-Explanation","filePath":"01 Fleeting Notes/Strongest PECO Motivation Explanation.md","title":"Strongest PECO Motivation Explanation","links":["tags/paper-planning"],"tags":["paper-planning"],"content":"2023-01-24 19:53\nTags: paper-planning\n\nCore Problem\n\nReaders are often confused by the rationale behind and setup for PECO\nIn particular, they want to understand why we train on PSC but test on SSC\nTo motivate this, we need to more clearly drive home the idea that we are:\n\nTrying to characterize model-relevant biases that are present in the data\nPerform this model-driven dataset analysis for the purpose of bias elimination in the dataset\n\n\n\nWe allow the possibility that some SSC-visible biases are not actually used by a classifier when trained in the PSC. Thus, we have to train on PSC and test on SSC, and PECO is an alternative metric of bias that captures this model-level separability of sentences in the SSC notion better than other approaches.\n\nIn particular, write a bit where we relate more closely to competency problems and dataset cartography\n\nFrom Reviewer Response Text\nWe will now respond to your main question, “why is PECO applied to a model that is trained on sentence pairs?” with an answer organized by (numbered) quotations from your review that are relevant to this point.\n(1) “PECO is computed based on a model trained on sentence pairs and therefore should receive a sentence pair at evaluation time.”\nYou describe why evaluating on sentence-pairs for clustering would be futile later in your comment:\n(2) “If the model does receive a sentence pair for computing PECO, clusters are to be expected and there is no way to distinguish good clusters from bad (shortcut) clusters.”\nYou are correct to point out that in observing clusters in the paired sentence condition (PSC), there’s no way to tell “good” clusters apart from shortcut clusters. However, in the single sentence condition (SSC), the only class label-separating clusters that can exist, must be shortcut clusters. This is because such clusters visible in the SSC (whether the model is trained on SSC or PSC) is indicative of information that the model can use to discern the label classes apart when only one sentence is shown, which violates the pairwise nature of the definition of the NLI task.\nWhile this answers why we must evaluate on single sentences for PECO, it alone doesn’t address your further point regarding training on PSC and evaluating on SSC:\n(3) “viewing single sentences during feature extraction for PECO score assessment is a very different setup to what the model was exposed to during finetuning (distribution shift!) and it’s not clear to what degree its single sentence representations from a sentence pair model is meaningful for the task of NLI”\nWe agree with you that the meaningfulness of single sentence embeddings to the task of NLI is questionable; in fact, in the ideal case these embeddings should carry 0 relevant information to the NLI task, were a leakage-free dataset to exist.\nPECO is built on the assumption that for such an ideal NLI dataset, all information relevant to PSC classification SHOULD be lost under the distribution shift that occurs when a single-sentence condition (SSC) population is considered. Thus, we treat finding whether this takes place or not for a given (model, dataset) combination as a proxy for the biasedness of the dataset.\nTo do this we train a classifier to convergence on the PSC population (leading to a high test accuracy in PSC and separation of the label classes in the final embedding space of the classification head) and then estimate which of these features continue to be visible to the model in the SSC, by observing the separability of label classes in said embedding space. Your understanding of the cluster shifting is aligned with our fundamental assumption. \n(4) “Neural networks are known to behave strangely under distribution shift.”\nRegrettably, we did a poor job of explaining how we mitigate the impact of the distribution shift beyond the desired loss of representational separation (for an ideal dataset) in the manuscript. Rather than feeding in a sample strictly containing the single sentence, we input “lesioned” sentence pairs, which preserve the structure of “ s1  s2 ”, but have all tokens in either s1 or s2 zeroed out at both the input token embedding and attention mask levels. This way the samples continue to have the structure of sentence pairs. Although this clarifying detail will be identifiable to those who read our source code, we have added this to the appendices for the final draft to alleviate confusion.\nTo recap, our goal in computing PECO is precisely to identify the degree to which model-visible separation of label classes is possible in SSC, which as you pointed out should be axiomatically impossible. Our emphasis in finding biases the model actually uses is why we train on PSC and test on SSC for PECO, and we have taken measures to minimize the impact that this domain shift has on producing strange behaviors, beyond the expected loss of separation due to information loss. Hopefully, these remarks have answered your question satisfactorily."},"01-Fleeting-Notes/Subjectivity-in-LM-analysis-support,-overleaf-draft":{"slug":"01-Fleeting-Notes/Subjectivity-in-LM-analysis-support,-overleaf-draft","filePath":"01 Fleeting Notes/Subjectivity in LM analysis support, overleaf draft.md","title":"Subjectivity in LM analysis support, overleaf draft","links":[],"tags":[],"content":"Rao: AI as an Ersatz Natural Science? cacm.acm.org/blogs/blog-cacm/261732-ai-as-an-ersatz-natural-science/fulltext\nSubjective and more subjective hype-fueling analysis:\nTeaching models to express their uncertainty in words arxiv.org/pdf/2205.14334.pdf\nEMNLP THeme paper: www.overleaf.com/project/6296937e4034478075a18a64\nMSFT proposal (same text): www.overleaf.com/project/62916d35de6fa13dbe23612c\nMSFT details: www.microsoft.com/en-us/research/academic-program/phd-fellowship/canada-us/"},"01-Fleeting-Notes/Sysadmin-tutorial":{"slug":"01-Fleeting-Notes/Sysadmin-tutorial","filePath":"01 Fleeting Notes/Sysadmin tutorial.md","title":"Sysadmin tutorial","links":[],"tags":[],"content":"Total size of all subdirs of something\nsudo du -s * | awk &#039;{total += $1} END {print total}&#039; | numfmt --to=iec\ndu\ndf\nrsync\nlsblk\nmove your shit before update\nnewuser\nbasic sensible bashrc\nwebsite\ngithub.com/ucsbnlp/website\nApache2 on the nlp server\n\nsudo service apache2 stop/start/restart\nconfig in /etc/apache2/sites-enabled/*.conf\nsite in /var/www/\nsync from github w/ php /var/www/html/nlp.cs.ucsb.edu/public_html/deploy.php\n\nwilliam hosting\ncopy your working html folder into /var/www/html and it will be live on william.cs.ucsb.edu\nDeepak showed them the web console for AWS\n\nIAM console\npermission groups\nmaking new users\n\ndeepak will past his command history for how to AWS instance\nreinstalling\n\nlive disk\nget updates for installer (if applicable)\npartitions:\n\nclear partition\nset boot table to drive\nsdx1 : boot 20gb\nsdx2 : swap 128gb\nsdx3 : remaining\n\n\nno proprietary drivers or other fluff in install\nwhile in livecd, fix boot issues (for servers with old GPUs)\n\nsu\nmount /dev/sdx3 /mnt\nmount --bind /dev /mnt/dev\nmount --bind /sys /mnt/sys\nmount --bind /proc /mnt/proc\n# if boot part\nmount /dev/sdx1 /boot\n \nchroot /mnt\nsu\n# check that this != 0\nls -l /boot/grub | wc -l\n \n# for the old GPUs, we want to remove the default graphics driver\necho &#039;GRUB_CMD_LINUX_DEFAULT=nomodeset&#039; &gt;&gt; /etc/default/grub\necho &#039;GRUB_TIMEOUT=10&#039; &gt;&gt; /etc/default/grub\n# may need to delete conflicting lines in vim\nupdate-grub\n \n# default to booting to a terminal instead of GUI\nsudo systemctl set-default multi-user.target\n \nexit\n \nsudo reboot\n\nbios settings on william\nrestart, install nvidia drivers:\n\nsudo apt update\nsudo apt upgrade\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\n \nsudo apt-get install nvidia-graphics-drivers-570 # or latest\n\nset up ssh\n\nsudo apt install ssh\nsudo systemctl enable ssh\nsudo ufw allow ssh\nsudo ufw enable\nsudo systemctl start ssh\n# status should say running\nsudo systemctl status ssh\nsudo systemctl status ufw\nifconfig\nbasic packages\nchecklist\n\n zsh ✅ 2025-04-03\n nvim\n conda\n apace2\n other?\n\nother installs:\n\nzsh-syntax-highlighting\nbasic vim\nlf\n\nzsh\nzsh installed on top level\nconda\nTODO system level conda\ndefault pacakges\nnvitop\napache2\nnvim\nset key-only access\nTODO\nuser creation script\n#!/bin/bash\n \nif [[ $#--ne-2-| -ne 2 ]];\n\tthen echo &quot;add the uname as first arg and ssh key as second&quot;\n\texit\nfi\n \nUSERNAME=$1\nKEY=$2\n \nsudo useradd -m $USERNAME\n \nUSERPATH=$HOME/../$USERNAME\n \nsudo mkdir $USERPATH/.ssh\nsudo echo &quot;$KEY&quot; | sudo tee -a $USERPATH/.ssh/authorized_keys\n \nsudo chown $USERNAME $USERPATH/.ssh\nsudo chown $USERNAME $USERPATH/.ssh/authorized_keys\n \nsudo chmod 700 $USERPATH/.ssh\nsudo chmod 600 $USERPATH/.ssh/authorized_keys\nTODOs:\n\nUsergroups for admin\nAdmin user creation flag (gives passwordless sudo)\n\nadmin tools scripts (like the user creation)\n\nuser creation wizard\n\nsane defaults\nuser template is in /etc/skel/\ndefault behavior of useradd is defined in /etc/default/useradd\nhf home\none giant hf home for everyone on /data/hf_cache\n#!/bin/bash\n \n# Create a group for permissions to the directory\nsudo groupadd hf-users\nsudo usermod -aG hf-users $USER\n \n# Create shared directory and make it owned by the group\nsudo mkdir --mode=u+rwx,g+rwxs,o-rwx /huggingface # Give the directory rwx for user and group, and make files the directory inherit these permissions\nsudo chown $USER /huggingface/\nsudo chgrp hf-users /huggingface/\n \n# Add to .bashrc\ncat &lt;&lt;EOF &gt;&gt; $HOME/.bashrc\nexport HF_HOME=&quot;/huggingface&quot; # Download HF cache items to /huggingface\numask 002 # Give user and group rw/rwx by deefault\nEOF\n \n# Optional: join the group in this shell, or restart the shell\nnewgrp hf-users\n \nconda\n\none big conda homes /dataX/$USER/.conda etc\neveryone’s conda rc defaults TODO\n\nzshrc &amp; bashrc\n\n set hf home ✅ 2025-04-03\n set conda home\n\nzshrc\nautoload -U colors &amp;&amp; colors\n#PS1=&quot;%B%{$fg[yellow]%}%n%{$fg[green]%}@%{$fg[blue]%}%M %{$fg[magenta]%}%~%{$reset_color%}%b &quot;\nPS1=&quot;%B%{$fg[red]%}%n%{$fg[magenta]%}@%m%  %B%{$fg[yellow]%}%~ %B%{$fg[green]%}$%{$reset_color%}%b &quot;\n \nautoload -U compinit\nzstyle &#039;:completion:*&#039; menu select\nzmodload zsh/complist\ncompinit\n_comp_options+=(globdots)\t\t# Include hidden files.\n \n# vi mode\nbindkey -v\nexport KEYTIMEOUT=1\n \n# Change cursor shape for different vi modes.\nfunction zle-keymap-select {\n  if [[ ${KEYMAP} == vicmd ]] ||\n     [[ $1 = &#039;block&#039; ]]; then\n    echo -ne &#039;\\e[1 q&#039;\n  elif [[ ${KEYMAP} == main ]] ||\n       [[ ${KEYMAP} == viins ]] ||\n       [[ ${KEYMAP} = &#039;&#039; ]] ||\n       [[ $1 = &#039;beam&#039; ]]; then\n    echo -ne &#039;\\e[5 q&#039;\n  fi\n}\nzle -N zle-keymap-select\nzle-line-init() {\n    zle -K viins # initiate `vi insert` as keymap (can be removed if `bindkey -V` has been set elsewhere)\n    echo -ne &quot;\\e[5 q&quot;\n}\nzle -N zle-line-init\necho -ne &#039;\\e[5 q&#039; # Use beam shape cursor on startup.\npreexec() { echo -ne &#039;\\e[5 q&#039; ;} # Use beam shape cursor for each new prompt.\n \n### anything else\nsource ~/.zsh_profile\n \n# Load zsh-syntax-highlighting; should be last.\n# source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh 2&gt;/dev/null\nsource /usr/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh 2&gt;/dev/null\nbashrc\n…"},"01-Fleeting-Notes/T2I-Model-Zoo-Provenance":{"slug":"01-Fleeting-Notes/T2I-Model-Zoo-Provenance","filePath":"01 Fleeting Notes/T2I Model Zoo Provenance.md","title":"T2I Model Zoo Provenance","links":["tags/blog-idea","tags/t2i"],"tags":["blog-idea","t2i"],"content":"blog-idea t2i\nThere are a lot of great posts out there explaining how diffusion models for text-guided image synthesis (and other text-to-image models more broadly) work. In particular, Lilian Weng’s post on diffusion models gives both a detailed mathematical characterization of the diffusion process and DM training, and narratively presents advancements such as DDPM and latent diffusion modeling in the rough order they developed. Yang Song’s post on score-based modeling also gives a great mathematical perspective that builds up to diffusion models from first principles, and will deepen your understanding. Maybe this post from Mario Namtao Shianti Larcher comparing HuggingFace diffusers models will cover similar ground that I cover in here, but I couldn’t read it as I don’t pay for Medium.\nIn this post I will instead focus on listing all the implementation differences between current popular text-to-image models, particularly with respect to which pretrained elements are shared and which differ, and which datasets they were used to pretrain on. This allows us to chart out an “ancestry” chart of which particular models went in to which systems. In particular, this allows us to compare diffusion models with respect to “openness” and replicability, and to trace their provenance.\nI made this post in the course of my work on interpreting and analyzing the behavior of text-to-image models; being able to analyze the training data directly allows us to formulate useful hypotheses to design experiments for a given model.\nSD Mainline\n\nStablediffusion 2.0 (stabilityai/stable-diffusion-2) is primarily trained from scratch on LAION 5B, then further trained on a 10M LAION subset (which presumably they chose) I would guess those images are definitely covered in 5B and might be in en 2B\n\nDetails on the base model here huggingface.co/stabilityai/stable-diffusion-2-base\nSeems like the training data is 100% within LAION 5B, but they subsample some subsets differently\n\n\nStablediffusion 2.1 is finetuned from SD2 using LAION 5B with a different use of the safety filter huggingface.co/stabilityai/stable-diffusion-2-1\nStableDiffusions 1.1-1.4 (CompVis/stable-diffusion) are trained on different subsets:\n\n1.1 is trained on LAION-2B EN primarily for 237k steps, with a futher update on laion-high-resolution (sampled from LAION-2B)\n1.2 is fine-tuned from 1.1 on the aesthetics subset of 2B-en\n1.3 is further finetuned from 1.2 on the same subset with less text conditioning\n1.4 is resumed from 1.1 on “laion aesthetics v2 5+” which I believe is a different 5B subset that also has bad LID\n\n\nUnCLIP 2.1 finetuned\n\nConditioned on CiT-L and ViT-H CLIP image emebeddings (for variation and mixing)\n\n\n\nDALL-E 1/2/3\nImagen\n\nUntil very recently Google’s Imagen model only existed internally. Looks like it’s available for API access through the “Vertex AI” platform for trusted users but I haven’t tried it yet.\nThe open Imagen-Pytorch model uses a pretrained T5 model for conditioning (IS IT FINETUNED) and the cascading DDPM architecture in Imagen. Uses classifier-free guidance\n\nTrained on: laion2B-en\n\n\n\nDALL-E mini/mega\n\ngithub.com/borisdayma/dalle-mini\nwandb.ai/dalle-mini/dalle-mini/reports/DALL-E-Mega-Training-Journal—VmlldzoxODMxMDI2#dall%C2%B7e-mega---training\nThis is actually a transformer GAN rather than diffusion model, but its wide use puts it within the milieu of the others discussed here\nBART encoder-decoder (normformer) maps t2i tokens\nCausal image token decoder outputs\nDEMega training log\n\nwandb.ai/dalle-mini/dalle-mini/reports/DALL-E-Mega-Training-Journal—VmlldzoxODMxMDI2\n\n\n\nSDXL\n\nStableDiffusion XL  is a whole other can of worms; they have a base model and a refiner model\n\nBase model is trained on an internal dataset to stability AI, I will investigate further but they’re less transparent abt it than the prior open models. I would assume it’s a curated subset of LAION tho\nThe refiner model appears to be trained on the same\ndetails on the training data might be findable via their source code here, I can investigate further github.com/Stability-AI/generative-models\n\n\n\nLingual adaptation variants:\n\nAltDiffusion\nJapanese StableDiffusion\n\nOthers:\n\nDeepfloyd IF\n\nT5, LAION-A 1.2B text-image pairs\n\nClaims training on romance languages also\n\n\nAlso an Imagen reproduction?\n\n\nMidjourney\n\nSeems to have been started from SD based on rumors?\n\nI think using at least some of the codebase is likely\nUsing the pretrained model is prob a violation of SD release license? (CHECK)\n\n\nDocumentation not open\nRelease dates for model “versions” www.wikiwand.com/en/Midjourney started in Feb 2022, latest in June 23\n\nwww.techspot.com/news/96619-midjourney-v4-greatly-improves-award-winning-image-creation.html\nCan I make guesses about use of the SD codebase for example as a base?\nwww.howtogeek.com/879711/midjourney-v5-creates-better-images-fewer-nightmare-hands/\n\n\nSeemed to do some in-house collection of “high quality photos” for training ^^ sourced from a discord server/reddit/twitter\nI am curious to see how the suit against them (also OpenAI and Stability are included) goes.\n\nWill the training dataset be revealed?\nIs it LAION?\n\n\n\n\n"},"01-Fleeting-Notes/T5-Strikes-Back":{"slug":"01-Fleeting-Notes/T5-Strikes-Back","filePath":"01 Fleeting Notes/T5 Strikes Back.md","title":"T5 Strikes Back","links":["tags/blog-idea","01-Fleeting-Notes/Blogpost-idea-\"the-bubble-in-screen-protector-research-agenda\""],"tags":["blog-idea"],"content":"blog-idea\nIt’s all about post training\nOr, “Prompt-tuners: T5 in disguise”\nT5 was preprinted five years ago as of this month. In my view, it is the originator of the LLM prompting paradigm. After pretraining on the C4 corpus, T5 was simultaneously fine-tuned on diverse NLP tasks including NLI, paraphrasing, summarization, and translation. Which capability is engaged during inference is not determined through some external routing module or direct conditioning switch, but inline, as text, with the rest of the input, eg. translate English to German: That is good.\n\nGiven the mature state of transfer learning at the time, that shared representations could benefit all the tasks in a parameter efficient manner was a reasonable prediction, which was vindicated by the success of the model. But as a novice NLPer at the time I was quite surprised that an LM could both process its instructions and perform the specified task so well at the time; even though GPT-2 had already been found too dangerous to be released shown able to complete impressive, novel writing segments, I hadn’t seen such strikingly good instruction-guided outputs before.\nDespite this, I caught in 2022 for calling T5 the genesis of prompting, as it isn’t a decoder model, and the large multitask decoder LMs of 2022 weren’t being trained to be prompted as T5 was either.\nIn 2024, though, I feel pretty vindicated. I would submit our use paradigm for LMs is now closer to the T5 paradigm than it was a couple years back.\n2022 was a heady time. When “emergent abilities” came in to the public consciousness we looked on in awe at what pure pretraining could get us. “Chain of thought” among others brought to the forefront prompt engineering, others. Benchmark after benchmark fell before the bitter lesson that simply scaling compute and data would bring about generalized capabilities.\nBut failure cases popped up too.\nPost training on so many tasks to effectively cover all end tasks/evals\nThrows back to the T5 era\n\none unified model was performing all the tasks they wanted\nthey EXPLICITLY were prompt-tuning by keying each task to a specific prompt (translate summarize etc)\ndifferent architecture of course\n\nI catch flak when I refer to T5 as the originator of prompting as a technique in LM use but I do really believe it\nMelanie Mitchell: “the reasoning debate heats up” aiguide.substack.com/p/the-llm-reasoning-debate-heats-up\n\nTom McCoy’s embers of autoregression paper uses probability bias on tasks like reversal as evidence that patterns in the train data are used rather than reasoning\nPaper from another group showing robustness breakdown on rephrased GSM8k questions\nSeems suggestive that matching to in-distribution patterns in the training data were there\n\nI think by a constructionist narrative we’re clearly returning to the T5 paradigm (with much more pretraining) by moving to all of these post-training tasks\n“bubbles in a screen protector” Blogpost idea “the bubble in screen protector research agenda”\nNatolambert explains post training and rlhf\nwww.aisummer.org/p/nathan-lambert-on-the-rise-of-thinking"},"01-Fleeting-Notes/Tasks-for-\"Mapping-is-not-Memorization\"":{"slug":"01-Fleeting-Notes/Tasks-for-\"Mapping-is-not-Memorization\"","filePath":"01 Fleeting Notes/Tasks for \"Mapping is not Memorization\".md","title":"Tasks for \"Mapping is not Memorization\"","links":["tags/paper-planning","01-Fleeting-Notes/Mapping-is-not-memorization"],"tags":["paper-planning"],"content":"2023-02-11 15:13\nTags: paper-planning\n\nMapping is not memorization\nExp. 1. Local Ball Around Final Latent\n\nPlotting relationship between t and % of recovered images\nNeeds:\n\n\nImage recovery metric testbench\n\nL2 norm between 2 images\nUse Carlini paper threshold for recovery\nPull N images from LAION and put in a tester\nUse same training prompts (captions?) will check Diff paper\nForeach image\n\nUse Kexun script to noise t steps forward, k times\nRun the backward (denoising) process from step t using Kexun script\nCount successes based on L2 under threshold\n\n\n\n\n\nExp. 2. Existence of Mapping for Memorized Data\n\nTracking the “key” noise for arbitrary training images\n\nReplicate Carlini paper training on CIFAR-10 splits\nSave trajectories (crucially, the initialization + maybe 5 intermediate points at specific t) for specific arbitrary training images\n\nCan be saved for the whole traj or intermed points\nSee above for training script mods necessary\n\n\nWe choose the images to track a priori, and hold out some to be completely random, and some to be semantically similar (for trajectory characterization purposes)\n\n\nSeeing if we can recover images from those key noises\n\nHow Carlini paper does replication\ngithub.com/openai/improved-diffusion\narxiv.org/pdf/2301.13188.pdf\nGood chance that text plays the dominant role\n\nCan we have a principled prediction of if text plays the dominant role?\nShares similarity with adverswarial problems.\nFinding maximum L2 difference influential noise directions in codespace around some image\n"},"01-Fleeting-Notes/The-Semi-meaninglessness-of--scaling-laws-or-How-Much-Did-the-Lunch-Cost":{"slug":"01-Fleeting-Notes/The-Semi-meaninglessness-of--scaling-laws-or-How-Much-Did-the-Lunch-Cost","filePath":"01 Fleeting Notes/The Semi-meaninglessness of  scaling laws or How Much Did the Lunch Cost?.md","title":"The Semi-meaninglessness of  scaling laws or How Much Did the Lunch Cost?","links":["tags/blog-idea","01-Fleeting-Notes/ACL23-Taking-Stock-Middleware-Master-Notes","01-Fleeting-Notes/Subjectivity-in-LM-analysis-support,-overleaf-draft","01-Fleeting-Notes/Do-AI-systems-really-have-their-own-language","Prajj-Lunch-Conversation"],"tags":["blog-idea"],"content":"2023-04-03 14:54\nTags: blog-idea\n\nMotivations:\n\nErsatz natural science\nMany hard-to-interpret results\nAre we overclaiming or underclaiming?\nWhere are the emergent abilities coming from\nJustifies:\nDefining the scope of the new science\nDataset analysis techniques\nModel-based model analysis\n\nModel-based automation to scale model evaluations\n\n\nEffort to define frontier tasks\nMoving behind cool-demo-ology\n\nScaling law for performance with data:\n“Linear scaling on most tasks with exponential in increased data” (excludes emergence)\n\n\nSpecializing Smaller Language Models towards Multi-Step Reasoning\n\n\nRepurposable:\nACL23 Taking Stock Middleware Master Notes\nSubjectivity in LM analysis support, overleaf draft\nDo AI systems really have their own language?\nSee Ongoing projects section\nPrajj Lunch Conversation\nDanish tweet on tradeoff between reasoning through memorization and acquisition of interesting capabilities\nInt\nI think it’s hard to find anyone who isn’t, in their heart of hearts, very surprised by the spectacular capabilities of large language models. I distinctly recall being surprised each time by the “unicorn story” generated by GPT-2, early evidence for the efficacy of task-specific prompting in T5, EXAMPLES EXAMPLES EXAMPLES emergent properties etc\nHowever there are some issues in the discourse around LLMs. First off, I think a degree of unreasonable foresight being retroactively claimed by eg. Sam Altman, motivated from a supposed “predictable” nature of gains in LM performance with scale. I think an important first step is to closely examine what these scaling laws actually are: blah blah blah\nIn fact, I am generally troubled by our rhetorical choice to describe what can more fairly be called “scaling observations” to laws. I believe a core inspiration for these observation-driven prognostications is Moore’s Law, which despite it’s name is not a natural law---it was first an academic observation in the late 1950s, which was then made an R&amp;D target in 1965 by the leadership of Fairchild Semiconductor and then later Intel.\nFor Moore’s law, the driving inputs were ever-shifting over time, while the main output variable---device complexity---remained fixed. Despite its seemingly slippery name, device complexity was in fact a measurable quantity, area transistor density at a fixed price. Realizing the business goal of Moore’s law required coordinating refinements to a shifting array of innovations, in terms of transistor design, materials, and fabrication process. In the 60s it was CMOS, in the 80s it was UV photolithography, more recently there has been a focus on 3D assembly of components. (Don’t hold me too closely on the above, I only have an undergraduate-level of EE knowledge, which was focused on signal processing anyway)\nMeanwhile, when it comes to the LLM “scaling laws,” there are several complications in relating them to other technology forecasting methods like Moore’s law. First of all, there’s not a unified LLM scaling law theory---different people (and sometimes the same people on different occasions) mean really different things when they make statements like “the gains in LLM performance are very predictable with scale.” Usually the sophisticated people who make this statement mean it rigorously, and they are referring to something like better perplexity performance over a larger dataset in compute-optimal conditions. However, audiences unfamiliar with the technical details of LLMs hear (and hype agents state) a non-rigorous version of the scaling hypothesis, referring to fuzzy concepts like “reasoning,” “understanding,” and the like. Despite my distaste for thinking of these concepts as following some kind of scaling law, I totally understand the interest---the shockingly impressive ability for systems like GPT-4 to act according to our intent from underspecified prompts across many domains and to generate fluent text and code are what we’re really excited about in these systems, not the ability for them to have a lower per-token surprisal over big datasets than previous techniques!\nThe fact that we can’t measure the thing we really care about is a massive problem, so big that at this point I believe it is the root of many of the issues in current AI discourse. I think this is where the assignment of sentience to LLMs comes from. I think this is what allows the magical thinking around AI doomerism to gain purchase. I think this is why we’re at a dead end in evaluation and all people can think to do is test LLMs on standardized tests. I think this is why psychologists, economists, and philosophers are trying to rush in and claim relevance by assigning things like a theory of mind or …\nI think this is why Eliezer Yudkowsky gets taken seriously.\n…\nWe really need a new science of “LLMology” that can answer these questions, and I think it will require novel theories and techniques that aren’t really comparable to any other field that has come before. While I’m very skeptical of the superintelligence crowd, I think even they should support this kind of a science. A better understanding of LLM capabilities will give us a better understnading of the risks they pose, if they do pose any. And perhaps if they do, having hard data to support the subjective AGI-like improvements that LLMs have given\nFirst is that there’s confusion over what exactly the dependent variable in the scaling relationship is. I see there being effectively a rigorous LLM scaling law claim and a vibe-based scaling law. I think a lot of people in the hype crowd like to play a rhetorical game where the strength of the rigorous claim is used to advocate for the vibe-based one.\nequation is flipped. As far as I understand it, the strong scaling hypothesis for LLMs is that with a paired increase in\nChinchilla arxiv.org/abs/2203.15556\nScaling laws for NLMs arxiv.org/abs/2001.08361 (Kaplan ea 2020 in Chinchilla)\nIt never hurts to be overly-optimistic about how LMs will work on your research task (LMaaJ skepticism)"},"01-Fleeting-Notes/Thinking-LM-as-a-judge-learning-to-eval":{"slug":"01-Fleeting-Notes/Thinking-LM-as-a-judge-learning-to-eval","filePath":"01 Fleeting Notes/Thinking LM as a judge learning to eval.md","title":"Thinking LM as a judge learning to eval","links":[],"tags":[],"content":"Generates prompts for (I think) pairwise preference scoring only over (seemingly) structured tasks\nThis is really interesting, but:\n\nOnly about generating rubrics\nOnly about preference pairs\nOnly about fairly coarse-grained/objectively evaluable methods\n\nSample datasets tested\n\nRewardBench\n\nWhat it is:\n\nFrom AI2\nChat (AlpacaEval, MT Bench (ratings for completions)\nMT bench hard pairs\nLLMBar completion comparisons\nRefusals for dangerous, offensive, refusal to answer when should\nReasoning tasks for Math\n“Reasoning” tasks as HumanEval\nAnthropic examples\n\n\nHow they used:\n\nPairwise\n\n\n\n\nFollowBench (Eval)\n\nCatches format, examples, style, situation, content\nThey made on top of FollowBench a pairwise check\n\n\nRM-Bench\n\nSpecific, fine-grained differences + relevant fact. (eg., confusing quantum entanglement with quantum superposition)\nModified to be pairwise\n\n\nJudgeBench\n\nResponse subtleties including reasoning, knowledge, math, and coding\n\n\n\nWhat do you think of this paper? Is this aligned with your research vision — if not, why not, and if yes, what do you see as limitations and what would envision if you were to add more to it?\nI think it’s a great paper. LM as a judge is pretty closely related to my research vision. However, LMaaJ only evaluates models post hoc from their outputs. I think what we really need is a system that dynamically elicits behavior from the model under test. The principal distinction I’d make between this work and my research agenda is that I want to make the planner both devise what the inputs are going to be and check them, rather than just checking outputs of predetermined inputs here.\nHere are some more granular thoughts.\nI really like seeing:\n\nhow using self-guidance to generate the samples for SFT+DPO  can be applied to scale LM judges\ncasting the task of building LM judges as something to automate rather than assuming human prompt engineering\nhow such a simple method performs well on all those different benchmarks\n\nThat being said, there are some limitations\n\nThey are assessing a well-worn set of judging tasks: correctness in world-knowledge QA, rule-following for things like length and output format, and refusal. Basically, it’s all chatbot stuff\nThey only look at pairwise evaluation, which is useful for coarse, relative system comparisons (and to a limited extent FT data filtering) but cannot be applied for absolute system acceptability judgements, which I think is the more important and difficult task\nThis method may be brittle to harder desiderata in more complex domains\n\nBy strictly using self-learning to select training samples, the model probably won’t improve much in the kinds of “plans” it can execute\nIn their Fig 1. example, they show it can check that the correct list of attributes are provided, and formatted correctly, but what about more complex, deeper info? Recall of fundamental facts? Stylistic attributes? This technique has no answer for this\nAnd addressing that issue is hard: within a pairwise preference signal attributes such as informativeness or recall over specific necessary input information probably won’t be caught, I suspect this is the same problem we have in tying vision+language modalities, there is not a sufficient supervisory signal for the model to fit everything we want it to\n\n\n\nI definitely think this method will be an important part of the toolbox for this research vision. At the very least as a baseline. I think natural follow ups to this work to address these limitations may include:\n\nIdentifying more complex domains than pairwise evaluation, maybe style or information preservation, and looking for supervisory signals on Likert scales\nDeveloping an evaluation planner that can use tools instead of just executing the entire evaluation plan LM-modulo (this would allow it to be better applied to code gen tasks for example)\nInvestigating if this technique can make a “base model” for LMaaJ to bootstrap a small set of gold preference pairs into a judge for some specialized task.\nAdding “building the input plan” as part of the evaluation.\n"},"01-Fleeting-Notes/Tool-use-t2i":{"slug":"01-Fleeting-Notes/Tool-use-t2i","filePath":"01 Fleeting Notes/Tool use t2i.md","title":"Tool use t2i","links":[],"tags":[],"content":"SEPHIROTH\nAERITH\nBARRET\nCLOUD\nSNAKE\nAgentic\nEvaluation\nR\nImage\nTool\nHandling\nSegment\nN\nA\nK\nEvaluation\nTool-use\nSegmentation\nCounting\nModular\nRequirement"},"01-Fleeting-Notes/Towards-Behavior-Driven-AI-Development":{"slug":"01-Fleeting-Notes/Towards-Behavior-Driven-AI-Development","filePath":"01 Fleeting Notes/Towards Behavior-Driven AI Development.md","title":"Towards Behavior-Driven AI Development","links":["tags/blogpost-notes","02-Document-Notes/Master-list-of-todos-for-PECO-EACL-camready"],"tags":["blogpost-notes"],"content":"2023-03-28 17:15\nTags: blogpost-notes\n\nBlogpost link\nBased on a paper called Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning\n\nUseful for mining for future reference\nIt is a currently active Python package for use in dataset analysis, but it lacks the powerful integrations with training models that I’m building\n\nRelates to Master list of todos for PECO EACL camready\n\nThey basically have a startup containing a much more capable copy of DatasetAnalysis\nThey sell this as being an enabler of “Behavior-driven AI dev” which is a desirable paradigm to them\n\nThey rightfully point out that many important elements aside from accuracy under numerical metrics are desirable\n\nThey point to the fact that there are ad hoc fairness toolkits, robustness analysis libraries, etc\n\nAll good to investigate as integrations\nThey exclusively work on the problem of “behavior as performance on metadata-identified subgroups”\n\nWorth considering looking into behavior on automatically-identified subgroups\n\n\n"},"01-Fleeting-Notes/We-Need-a-Team-America-Mentality-for-Tech":{"slug":"01-Fleeting-Notes/We-Need-a-Team-America-Mentality-for-Tech","filePath":"01 Fleeting Notes/We Need a Team America Mentality for Tech.md","title":"We Need a Team America Mentality for Tech","links":["tags/blog-idea"],"tags":["blog-idea"],"content":"2023-04-01 19:55\nTags: blog-idea\n\nwww.youtube.com/watch\nTeam America: World Police includes some brutal mockery of celebrity condemnations toward the Iraq war. While the celebs are (mostly) right on this, the point of the crit is to point out that they aren’t really the best authorities on issues of international politics. They aren’t the best advocates for their positions. They can be VERY wrong on other things.\nParker and Stone’s attitude toward them is more that they’re lame. This is coming from entertainment industry insiders.\nWe need a mentality like this toward tech types who pontificate on the world from inside. And we need double scrutiny toward tech “community” types without expertise e.g. Yudkowsky\nFor instance: I think Marc Andreessen is right that “It’s Time To Build.” But why the fuck should we listen to him on that perspective and not economists, etc? Why do VCs opinions on cancel culture really matter? etc\nTech types, especially bay area tech types live in a suffocatingly small bubble.\nMany of these takes are at best, “I’m a smart guy wrt X, so I’m  a smart guy in general” mentality overgeneralizing to give them the misplaced belief in the inherent correctness of their (not necessarily well-considered) opinions\nWhat pushed me over the edge from “this annoys me but it’s not worth saying” to “I think we need a culture within tech of pushing tech types to know their place” is the FLI open letter on AI and accompanying drone strike the supercomputing centers discourse.\nWith respect, I think Russell might be a bit high on his own supply and locked in to the alignment direction. I actually 100% accept all premises about why alignment is a hard problem. I also think it’s a useful line of research, as an inability to properly specify goals does cause issues. But his treatment of the issue is very GOFAI/RL centric and doesn’t really comport with the understanding of representation learning I have, and RepL really is the tech at issue in the conversation of anyway…\nRunning list:\na16z.com/2020/04/18/its-time-to-build/\nSee also Lex Fridman podcast:\nwww.businessinsider.com/lex-fridman-podcast-anti-woke-elon-musk-ai"},"01-Fleeting-Notes/Why-I'm-Not-worried-about-superintelligence-blogpost":{"slug":"01-Fleeting-Notes/Why-I'm-Not-worried-about-superintelligence-blogpost","filePath":"01 Fleeting Notes/Why I'm Not worried about superintelligence blogpost.md","title":"Why I'm Not worried about superintelligence blogpost","links":["tags/blog-idea","01-Fleeting-Notes/Blogpost-based-on-my-tweet-thread-with-the-guy-about-AI","01-Fleeting-Notes/I-HATE-LONGTERMISTS-Vol-5","01-Fleeting-Notes/Overconfidence-in-Deep-Learning-Discussions","01-Fleeting-Notes/Rationalists-are-like-Soylent","05-Snippets/The-Hinge-of-History-Peter-Singer"],"tags":["blog-idea"],"content":"2023-01-08 15:53\nTags: blog-idea\n\nLink dump:\nBlogpost based on my tweet thread with the guy about AI, I HATE LONGTERMISTS Vol 5, Overconfidence in Deep Learning Discussions tweet on the “desire for power” with scale\n\nA big core element of this story is that I think X-risk is a meme coming from the closed circlejerk of lesswrongery\n\n“Thank god I went to a party school” : I detest the eggheadism all the time attitude and public behavior of the tech culture types (lesswronging, ) Rationalists are like Soylent\nThings I do genuinely admire about them: thoughtfulness and knowledgability\n“There was a time when I was very impresed by Slate Star Codex”\nOverapplication of historical analogues (this is a much bigger issue than just AI hype agents (e.g., whatifalthist)) example on analogies to LLM revolution\nHype being pushed by people who own startups in the hypezone exhibit A\n\nWhy don’t we weigh the failure rate of startups in lending creedence to these people\n\n\nAI panic/x-risk is negative AI hype in the same way “Evil US always wrong and always bad” is negative American exceptionalism (Triggered by this thread where it opens with reasons to be concerned about bias, etc and ends with Robert Miles and Human Incompatible)\n\n\n\nSee also, Yejin’s response to questions about sentience, x-risk\nwww.nytimes.com/interactive/2022/12/26/magazine/yejin-choi-interview.html\nTo be fair, even most lesswrongers don’t really buy into the idea that sentience is an issue or likely (and I agree)\nNotes from a post comparing GPT3/ChatGPT as simulators astralcodexten.substack.com/p/janus-simulators\n\nGettier arguing against justified-true-belief (JTB) condition for knowledge, e.g. “guy lights fire to cook food. flies like the smell, no smoke from fire so far. distant guy sees flies cloud, thinks it’s smoke, says ‘there’s a fire’, doesn’t actually KNOW there’s a fire bc his reasons are false”\nThen SuperIntelligence by Bostrom is invoked.\n\nI find it plausible to think that there’s an intelligence upper bound for something gained from training on all the media we’ve ever produced\nEffectively, no free lunch\n\n\n\nPeter Singer has issues with this meme very bigly: The Hinge of History Peter Singer\nCited in Emile Torres’s more aggressive take: mileptorres.substack.com/p/effective-altruism-is-a-dangerous\nKnutsson:\n\nI am most concerned about someone who finds it extremely important that there will be vast amounts of positive value in the future and who believes I stand in the way of that. … [A]mong some in EA and existential risk circles, my impression is that there is an unusual tendency to think that killing and violence can be morally right in various situations, and the people I have met and the statements I have seen in these circles appearing to be reasons for concern are more of a principled, dedicated, goal-oriented, chilling, analytical kind.\n\nWhat are some reasons to not expect current LLM impressive results to carry over to more general intelligence, lead to performance\n\nGenerative != embodied\n\nLanguage and art are modalities that in hidsight fit well for big data modeling. The machine can very naturally operate in the modality the data exists in\nWhat “modality” do real-world actions fit in? How can generative approaches be applied to them?\nFor example, how can a robot learn from video of humans doing activities to model them in a sophisticated way analogous to how it learns writing from human actions?\nIt could produce descriptions or video frames of people performing actions, but you need to “break out” into the true modality and “close the loop”\nGenerative approaches fit in with imitation learning, but this is different in some potentially important ways. We can’t distill down every sensory input, perceptual phenomenon, etc that is percieved by a person and export it for use by a learner, whereas the native modality of language is purely words\n\n\nHumans can’t design and build human+1 intelligence, why should we expect AIs to? Especially because there’s good reason to believe that continuing the increase will get harder and harder\n\nMight be analogous to going at relativistic speeds. Energy reqs are super high\n\n\n\nIn this blogpost I need to essentially beg forgiveness for such heavy argument from analogy. However, everyone on all sides of this debate is guilty of this sin. Analogy-driven argument might be more acceptable in philosophical debates (which this also is) than it is in scientific debates\n”Why I was wrong about LLMs”\nGives arguments for why he thinks he misunderestimated LLMs and DL\nwww.inference.vc/we-may-be-surprised-again/\n“No free lunch-flavored argument”\n\nMaybe the takeaway is that no free lunch is still true, but we should be very skeptical about estimates of the price of the lunch\ntwitter.com/giffmana/status/1640811708313751562\n\nTies beautifully into “we don’t know how much lunch we’re getting or how much we’ve paid” argument\nIs the lunch generalized reasoning capabilities or EXTREMELY high fidelity roughly semantically-equivalent memorization\nEither of those capabilities are awesome but one is very different from other\nAlso the wild diversity of text out there points to the lunch fare we’ve paid\n\n\n\ntwitter.com/xriskology/status/1642155567971024897\nYudkowsky being so steeped in scifi thought that even his proposed solutions hinge on nanotech\n\nEarlier in thread: EY predicted nanobots by 2010 and singularity by 2021\n\nApocalyptic AI Post from Sacasas\nLink (Substack)\n\n5. The Enlightenment did not, as it turns out, vanquish Religion, driving it far from the pure realms of Science and Technology. In fact, to the degree that the radical Enlightenment’s assault on religious faith was successful, it empowered the religion of technology. To put this another way, the Enlightenment—and, yes, we are painting with broad strokes here—did not do away with the notions of Providence, Heaven, and Grace. Rather, the Enlightenment re-framed these as Progress, Utopia, and Technology respectively. If heaven had been understood as a transcendent goal achieved with the aid of divine grace within the context of the providentially ordered unfolding of human history, it became a Utopian vision, a heaven on earth, achieved by the ministrations Science and Technology within the context of Progress, an inexorable force driving history toward its Utopian consummation\n6. It is also important to be a bit more specific, and to classify the religion of technology more precisely as a Christian heresy. It is in Western Christianity that Noble found the roots of the religion of technology, and it is in the context of post-Christian world that it has presently flourished.\n\n\nWe get our word apocalypse from a Greek word meaning “to reveal, to disclose, or to uncover.” What I am suggesting is that AI, as it is being developed, deployed, and hyped (and criti-hyped), forces us to reckon with the fact that modernity is expiring, and it is expiring precisely to the degree that it no longer serves the interest of and is at various points, particularly in its techno-economic dimensions, openly hostile to the human person.\n"},"01-Fleeting-Notes/Words-I'd-add-to-English":{"slug":"01-Fleeting-Notes/Words-I'd-add-to-English","filePath":"01 Fleeting Notes/Words I'd add to English.md","title":"Words I'd add to English","links":["tags/blog-idea"],"tags":["blog-idea"],"content":"blog-idea\ninshallah\nsegún\n卷\nせっかく？やっぱり"},"01-Fleeting-Notes/Zicheng-AMD-Internship":{"slug":"01-Fleeting-Notes/Zicheng-AMD-Internship","filePath":"01 Fleeting Notes/Zicheng AMD Internship.md","title":"Zicheng AMD Internship","links":[],"tags":[],"content":"\nScreening/logistical questions\n\nBellevue is the main location/where Zicheng is\nOther interns will be in Bellevue\nWe will move forward with Bellevue location\nFull time 40h/week @ office\nStart Jun 24, end Sep 20\n$58/hr, 40 hr/wk\n5k pre-tax stipend for housing etc\n\n\nOffer details\nAsking expected graduation (eg. June 2025)\n\nInterested in conversion to full-time, Zicheng is growing his team\n\n\nJulie has to officially launch offer letter to Zicheng, manager, finance, back to Julie, in a day or two.\n\nSign within 3 days\n\n\nAfter offer signature, will need to launch background investigation, etc ASAP\n\nWilliam notes:\n\nSTAND ON SHOULDERS OF GIANTS\nTrain from best existing LLaVA\n"},"01-Fleeting-Notes/z":{"slug":"01-Fleeting-Notes/z","filePath":"01 Fleeting Notes/z.md","title":"z","links":[],"tags":[],"content":"Real science like physics has a limited amount of discoveries to be made sitting around\nFake science assumes that there’s unlimited discoveries\nMulticonstraint optimization of benchmarks that are good/dynamic/construct valid (eg., chatbot arena) but NOT plug-and-play vs plug-and-play but not having those things (GSM8K)"},"02-Document-Notes/Definition-Problems-in-the-AI-Space":{"slug":"02-Document-Notes/Definition-Problems-in-the-AI-Space","filePath":"02 Document Notes/Definition Problems in the AI Space.md","title":"Definition Problems in the AI Space","links":["tags/writing-ideas","tags/definitions","tags/nomenclature"],"tags":["writing-ideas","definitions","nomenclature"],"content":"2022-10-03 12:20\nTags: writing-ideas definitions nomenclature\n"},"02-Document-Notes/Generalization-Problem-in-DL-2023":{"slug":"02-Document-Notes/Generalization-Problem-in-DL-2023","filePath":"02 Document Notes/Generalization Problem in DL 2023.md","title":"Generalization Problem in DL 2023","links":["tags/topic-notes"],"tags":["topic-notes"],"content":"2023-02-12 21:39\nTags: topic-notes\n\nClare Lyle Blogpost\n\nPeter Bartlett has been giving talks for years on the second descent region of these double descent curves…benign overfitting\n\n\nI had the idea for the concept of compartmentalization again as I was reading this… do NNs maybe just have more space to/find it more efficient to directly allocate full subspaces of their weight information capacity to discrete abilities?\n\nWould it be possible to test for this?\nThis finding could be made useful in the calls for modularized model building in Raffel’s call to build models like OSS\n\n\nRefers to NeurIPS 21 paper from Bubeck on larger model size guaranteeing high Lipschitz robustness openreview.net/pdf\n\nThis paper is very dense, but the key takeaway is that over-parameterization actually increases the smoothness of the learned function (and they argue robustness but I’m not sold on if that def fits)\n“Even though the worst functions defined by wider networks are worse, the best functions are better”\n\n\nEvidence for multiple (beyond double) descent\nThe problem with depth in classic DNNs is that more layers hurt accuracy because of bad optimization dynamics, not because of overfitting\n\nHence, why resnet needed to smooth the loss landscape with residual connections\nTraining an NN involves walking a fine line between chaos and stagnation\n\n\nLottery ticket hypothesis arxiv.org/abs/1803.03635\n\nWhy is it so easy to prune a good, wide NN into a thinner sparser one, but so hard to train a good sparse one with small param count from scratch?\nThis answer has to do with lucky initializations: wider network to start = higher odds some lucky good subnetwork is in the weight space somewhere\n\nSurvival of the fittest?\nMaybe it’s that recieving continuing reinforcement through parameter updates on the subnetworks that get used is some “use it or lose it” or “non-atrophy” type of deal?\nIn the conclusion she links to more big-picture blog posts. Review the sources in those\n\n\n\n\n"},"02-Document-Notes/Master-list-of-todos-for-PECO-EACL-camready":{"slug":"02-Document-Notes/Master-list-of-todos-for-PECO-EACL-camready","filePath":"02 Document Notes/Master list of todos for PECO EACL camready.md","title":"Master list of todos for PECO EACL camready","links":["tags/todos","01-Fleeting-Notes/Strongest-PECO-Motivation-Explanation","01-Fleeting-Notes/NLI+-for-LLM-Eval","01-Fleeting-Notes/Multi-Scales-(sic)-data-augmentation-for-NLI","Notes-from-SoCalNLP","01-Fleeting-Notes/How-PECO-differs-from-Competency-Problems","01-Fleeting-Notes/Comptetency-Problems-Gardner"],"tags":["todos"],"content":"2023-01-07 22:34\nTags: todos\n\nDebug notes\n\nSICK, CF : too many values to unpack\n\nSICK fixed\n\n\n\nX, MdbA: no pretrained model (training in progress)\n\nX on andrew\nMdbA on zion\n\n\nOC: no layer named dense in last final layer\n\nThe one model you don’t use lastdense for (classifier doesn’t contain a dense)\n\n\n\ns2only, lastdense\nfor dataset in A1 A2 A3 AA CF MB MdbA MU SdbA SICK S X; do echo $dataset; echo $pc; CUDA_VISIBLE_DEVICES=6 python dataset_to_clusters.py --dataset $dataset --n_clusters 50 --n_components 50 --s2only --skip_gpu --lastdense --tsne;  done\n\ns1only ,lastdense\nfor dataset in CF F MdbA SdbA; do echo $dataset; for pc in 0 50 100; do echo $pc; for k in 10 25 50 100; do echo $k; CUDA_VISIBLE_DEVICES=6 python dataset_to_clusters.py --dataset $dataset --n_clusters $k --n_components $pc --s1only --skip_gpu --lastdense; done; done; done\n\ns2only, skip lastdense\nfor pc in 0 50 100; do echo $pc; for k in 10 25 50 100; do echo $k; CUDA_VISIBLE_DEVICES=6 python dataset_to_clusters.py --dataset OC --n_clusters $k --n_components $pc --s2only --skip_gpu; done; done\n\nSNLI cluster analysis:\n[e, c, n]\n##### HIGHEST BIAS ClUSTERS #####\n#0 bias cluster : [7] (anti-entail)\ndistribution:\n[0.24324324 0.35135135 0.40540541]\n#1 bias cluster : [24] (anti-contradiction)\ndistribution: ()\n[0.3197026  0.17843866 0.50185874]\n#2 bias cluster : [26] (pro-entail)\ndistribution:\n[0.45045045 0.33783784 0.21171171]\n#3 bias cluster : [35] (strongly pro-contra)\ndistribution:\n[0.2287234  0.63297872 0.13829787]\n#4 bias cluster : [30] (pro-neutral)\ndistribution:\n[0.20627803 0.21076233 0.58295964]\n\nFinal Edits for Camera Ready and arXiv\nContent Edits\n\n Fix reference to k-nn to k-means consistently\n Appendix on hyperparams in the PECO pipeline: correlations and table rows for PECO under:\n\n PCA-50 PCA-10 no PCA\n K=50, K=100,\n K_{\\textrm{adaptive}}=|D|/n\n L2 vs KLD\n Correlation plots\n\n\n Redo Fig 5-7 to use same acronyms as labels from the other datasets\n Motivate use of TRA 3.1 (we want to assess whether a given sentence is reasoning similarly over or not?) I do discuss a bit\n Motivating more clearly why we use PSC-trained SSC test for PECO computation Strongest PECO Motivation Explanation\n\n Clearly explain (4) from above, the way that the lesioning process works on the samples\n- [ ] Find the insights (Additional Analysis asked for by R2)\n- [ ] In particular, can we characterize the bias clusters semantically for some models?\n\n\n This has been skipped, defered to ACL Demo\n Fig1 style plots for every model in appendices\n NSF acknowledgement, and get William’s NSF acknowledgement as well\n\nAdditional Experiments\n\n Whatever is required to complete the PECO variation experiments\n- [ ] Integration of competency problems into dataset analysis\n Dataset cartography-PECO cluster comparison\n\n Is the difficulty within- or between-clusters?\n Add this content to page 9\n\n\n\nAdditional Analysis\n- [ ] Find semantic properties of the main clusters\n- [ ] Word clouds?\n\n Relate cartography and competency problems\n Defered to ACL Demo track submission\n\nFuture paper based on WANLI\nwww.semanticscholar.org/reader/56b30c6bd9dc4a2416ab3b74ad97dbb7a2904229\nAlisa Liu is main author\nNLI+ for LLM Eval\n\nImportant related work:\n\nMulti-Scales (sic) data augmentation for NLI\nAnalysis paper from AACL\n\n\n\n\nRelevant Notes:\nNotes from SoCalNLP, How PECO differs from Competency Problems, Comptetency Problems Gardner\n\nRe-run PECO evaluation for both xH and L2 with N_cluster=5,10,25,50,100\n\nAdd in the other dumbass distance metric reviewer 1 suggested\n\n\nAblation studies to help assuage retard reviewers\n\nSelect 2 datasets to do all the following:\n\nRedo all N_cluster with PCA N_dim = 50, 256, 512, and regular\nAll distance metrics\nAll N_cluster\n\n\nFor each, show the following figures:\n\nT-SNE samples (rough illustration of how separation works fine)\n\n\n\n\nManual analysis of the bias clusters: get some word clouds!\n\nLook at ShortcutLens\nOld steps (Quick Tasks for EACL PECO)\n2022-10-11 23:52\n\nFor submission pre-anonymity deadline to arXiv:\n\nTerminological fixes (SSC and PSC only)\nOnce-over of all writing\nFix whether PECO L2 or xH is used\nFix figures, tables with SSC and PSC\nAdd rationale details\n\n\nMake promo tweet thread once the paper is up on arXiv\n\nNEW PREPRINT ALERT, etc\nKey point: automatic, model-driven method to find problematic subclusters\n\n\n"},"02-Document-Notes/RLHF,-Alignment-Deep-Dive":{"slug":"02-Document-Notes/RLHF,-Alignment-Deep-Dive","filePath":"02 Document Notes/RLHF, Alignment Deep Dive.md","title":"RLHF, Alignment Deep Dive","links":["tags/paper-notes","01-Fleeting-Notes/Notes-from-Text-is-the-Universal-Interface","01-Fleeting-Notes/Why-I'm-Not-worried-about-superintelligence-blogpost"],"tags":["paper-notes"],"content":"2023-01-25 15:17\nTags: paper-notes\n\nRLHF Paper from OpenAI\nopenai.com/blog/instruction-following/#moon\nUnix originated universal interface idea of text, Roon proposes this philosophy lives on in LLMs Notes from Text is the Universal Interface\nOriginal RLHF paper arxiv.org/ftp/arxiv/papers/2106/2106.10328.pdf\nRunning Llama\ncocktailpeanut.github.io/dalai/#/\nWhy did Sam Bowman start a group on alignment\nwp.nyu.edu/arg/why-ai-safety/\nWhy I’m Not worried about superintelligence blogpost\nCounterpoint: am I “self-catechizing?”\n\n“Culture catechizes,” Alan Jacobs, a distinguished professor of humanities in the honors program at Baylor University, told me. Culture teaches us what matters and what views we should take about what matters. Our current political culture, Jacobs argued, has multiple technologies and platforms for catechizing—television, radio, Facebook, Twitter, and podcasts among them. People who want to be connected to their political tribe—the people they think are like them, the people they think are on their side—subject themselves to its catechesis all day long, every single day, hour after hour after hour.\nFrom Trump is Tearing Apart the Evangelical Church\nI definitely like to curate who I follow online. This might lead to a bit of autocatechism but conversely I believe LessWrong is a great example of where this takes place.\n"},"04-Course-Notes/Graph-ML/Graph-Signal-Proc":{"slug":"04-Course-Notes/Graph-ML/Graph-Signal-Proc","filePath":"04 Course Notes/Graph ML/Graph Signal Proc.md","title":"Graph Signal Proc","links":[],"tags":[],"content":"Graph Signal Proc\n2022-04-25 12:30\nTags:\n\nEigenvalues correspond to “frequencies” of a signal x applied to some graph G after performing eigendecomposition of xGxT\nGraphHeat: best in node classification"},"05-Snippets/The-Hinge-of-History-Peter-Singer":{"slug":"05-Snippets/The-Hinge-of-History-Peter-Singer","filePath":"05 Snippets/The Hinge of History Peter Singer.md","title":"The Hinge of History Peter Singer","links":["tags/bootleg"],"tags":["bootleg"],"content":"2023-02-18 15:26\nTags: bootleg\n\nThe dangers of treating extinction risk as humanity’s overriding concern should be obvious. Viewing current problems through the lens of existential risk to our species can shrink those problems to almost nothing, while justifying almost anything that increases our odds of surviving long enough to spread beyond Earth.\nPRINCETON – Twelve years ago, during the International Year of Astronomy that marked the 400th anniversary of Galileo’s first use of a telescope, I wrote “The Value of a Pale Blue Dot” – a reflection on how astronomy has revealed a vast universe filled with an unimaginable number of stars, thus shrinking the significance of our sun and our planet. The “pale blue dot” refers to how the Earth appears in a 1990 photograph taken by the Voyager spacecraft as it reached the outer limits of our solar system. The essay suggests that the knowledge gained from astronomy “forces us to acknowledge that our place in the universe is not particularly significant.”\nA recent blog post by Holden Karnofsky has led me to reconsider that thought. Karnofsky is co-CEO of Open Philanthropy, a foundation that researches the best opportunities for philanthropic grant-making, and publishes the reasons for its decisions. Thinking about the long-term significance of today’s philanthropic decisions is therefore part of Karnofsky’s role. He is thinking very long term indeed.\nKarnofsky points out that we could be living “at the very beginning of the tiny sliver of time during which the galaxy goes from nearly lifeless to largely populated.” That “tiny sliver of time” began, we might say, with the first use of tools by our ancestors, around three million years ago. It will end when our descendants – who might be digital minds, rather than biological organisms – inhabit the entire galaxy, perhaps ushering in a civilization consisting of an enormous number of conscious beings that would last for tens of billions of years. There is a good chance, Karnofsky argues, that this process of populating the galaxy will begin during this century. By 2100, we could develop the technology to construct self-sufficient settlements on other planets.\nThis thought echoes one expressed in 2011 by the late philosopher Derek Parfit, who wrote, near the end of the second volume of On What Matters: “We live during the hinge of history.” Like Karnofsky, Parfit was thinking of the arrival of technologies that, if used wisely, would enable our species to survive “its most dangerous and decisive period,” and our descendants to spread through our galaxy. Parfit refers to “the next few centuries,” rather than just this one, as the time it may take before humans can live independently on other planets, but even that will be only be a sliver of time compared to what is to come. Our most significant contribution to this development would be to ensure the survival of intelligent life on our planet.\nPerhaps, though, the idea that we are essential to this process is merely the latest version of the self-important delusion that humans are the center of existence. Surely, in this vast universe, there must be other forms of intelligent life, and if we don’t populate the Milky Way galaxy, someone else will.\nYet, as the physicist Enrico Fermi once asked fellow scientists over lunch at Los Alamos National Laboratory, “Where is everybody?” He wasn’t commenting on empty tables in the lab’s dining room, but on the absence of any evidence of the existence of extraterrestrials. The thought behind that question is now known as the Fermi Paradox: if the universe is so stupendous, and has existed for 13.7 billion years, why haven’t other intelligent forms of life made contact?\nKarnofsky draws on a 2018 paper by researchers at the University of Oxford’s Future of Humanity Institute to suggest that the most likely answer is that intelligent life is extremely rare. It is so rare that that we may be the only intelligent beings in our galaxy, and perhaps in the much larger Virgo supercluster to which our galaxy belongs.\nThis is what Karnofsky means when he says that the future of humanity is “wild.” The idea that we, the inhabitants of this pale blue dot at this particular moment, are making choices that will determine whether billions of stars are populated, for billions of years, does seem wild. But it could be true. Granting that, however, what should we do about it?\nKarnofsky does not draw any ethical conclusions from his speculations, other than advocating “seriousness about the enormous potential stakes.” But, as Phil Torres has pointed out, viewing current problems – other than our species’ extinction – through the lens of “longtermism” and “existential risk” can shrink those problems to almost nothing, while providing a rationale for doing almost anything to increase our odds of surviving long enough to spread beyond Earth. Marx’s vision of communism as the goal of all human history provided Lenin and Stalin with a justification for their crimes, and the goal of a “Thousand-Year Reich” was, in the eyes of the Nazis, sufficient reason for exterminating or enslaving those deemed racially inferior.\nI am not suggesting that any present exponents of the hinge of history idea would countenance atrocities. But then, Marx, too, never contemplated that a regime governing in his name would terrorize its people. When taking steps to reduce the risk that we will become extinct, we should focus on means that also further the interests of present and near-future people. If we are at the hinge of history, enabling people to escape poverty and get an education is as likely to move things in the right direction as almost anything else we might do; and if we are not at that critical point, it will have been a good thing to do anyway.\nFrom project-syndicate.org"},"08-Old-notes/Pegasus-replication-problems-Wenda":{"slug":"08-Old-notes/Pegasus-replication-problems-Wenda","filePath":"08 Old notes/Pegasus replication problems Wenda.md","title":"Pegasus replication problems Wenda","links":[],"tags":[],"content":"2022-05-02 11:58\nTags:\n\nCurrent steps:\n\ncheck preprocessing and current train code\ngithub.com/xu1998hz/factual_score/blob/main/train/train.py\n\nline 154 can comment out output_norms=True in order to convert to normal pytorch\n\n\nPort to lightning/wandb workflow\nSpacy integration for entity extraction/linking via wikidata\n\nCNN/DM dataset\n\nFirst we get 1st order wikidata matches then we can do matching\nOne library can do this step with poor coverage\n\nChanging the objective:\n\nHow do we do query on all edges outgoing from a node\nWe want to reproduce a paper with no public data/code “Faithful to the Document or to the World?” by Dong, Wieting, Verga\n\nTable 1 connecting the indirectly related entities like they show\nWe really want to reproduce their KG and be able to release it\n\n\n"},"08-Old-notes/Plans-(summarization-5-4-22)":{"slug":"08-Old-notes/Plans-(summarization-5-4-22)","filePath":"08 Old notes/Plans (summarization 5-4-22).md","title":"Plans (summarization 5-4-22)","links":[],"tags":[],"content":"Plans\n2022-05-04 16:09\nTags:\n\nDatasets\nCNN-Dailymail\nDemonstrate train/test diff\nInvestigate differing ROUGE, SMATCH score\nMy focus:\n\nGigawords on PEGASUS\n"},"08-Old-notes/Reviews-for-AAAI":{"slug":"08-Old-notes/Reviews-for-AAAI","filePath":"08 Old notes/Reviews for AAAI.md","title":"Reviews for AAAI","links":[],"tags":[],"content":"7306\n\nConcern about private info leaking in PLM\nCan we prefix tune to prevent this?\n\nModular design of prefix tuning\nParameter efficient\n\n\nThey propose an improvement to prefix-tuning on pre-privatized data\nDemo experiments on privatized SST and QQP\n\nThey adopt local privacy in learning personalized prefixes for fine-tuning of a PLM in the cloud\n\nExponentially bounded ratio of any P(y) being generated as the privacy mechanism\nEach token rep in the text gets dx privacy applied\nEquivalent to adding exponentially distributed random noise to xt\n\n\n\n"},"08-Old-notes/SoCalNLP-Group-advisors":{"slug":"08-Old-notes/SoCalNLP-Group-advisors","filePath":"08 Old notes/SoCalNLP Group advisors.md","title":"SoCalNLP Group advisors","links":[],"tags":[],"content":"chang87@cs.ucsb.edu\njessetho@usc.edu\njonmay@isi.edu\njshang@eng.ucsd.edu\nleili@cs.ucsb.edu\nNanyun Peng\nPengtao Xie\nswabhas@allenai.org\nrobinjia@usc.edu\njmcauley@eng.ucsd.edu\njyzhao@cs.ucla.edu\nKai-Wei Chang\nNanyun\nNdapa Nakashole\nSameer Singh\ntberg@cs.cmu.edu\nxiangren@usc.edu\nzhh019@ucsd.edu"},"08-Old-notes/reviews-scratch":{"slug":"08-Old-notes/reviews-scratch","filePath":"08 Old notes/reviews-scratch.md","title":"reviews-scratch","links":[],"tags":[],"content":"378\nBERT-like in currentyear\nWhat the fuck even is a “BERT-like”\nTo be clear my complaint here is that you should be more specific, e.g. MLM-trained encoder-only transformer LMs instead of “BERT-likes”\nPutting BERT in the name of a model or system is a marketing, not scientific distinction\nGrammar glitches in early parts, e.g. “Heading is a sentence…” instead of “A heading is a sentence…”\nKey idea: BERT cannot…\n\nLeverage structure in articles e.g. headings, tables\nHandle long context inputs\n… for training, which means it is worse at modeling domain knowledge than humans.\nOk…?\n\nPrior work to resolve this weakness includes things like:\n\nConstructing QA pairs to capture the knowledge and using answering these domain-specific QA pairs as a training task (seems like a meme, diseaseBERT)\nTransformerXL\n\nTheir approach claims to:\n\nutilize semistructure of headings etc in articles\n“theme masked language modeling”\n\nessentially, feed the heading+paragraph into LM, mask the heading and try to force it to model the relation between heading and paragraph by predicting heading from pp\n\n\n3% improvement on some medical QA tasks\n\nBut do they compare to don’t stop pretraining lmao\n\n\nlean borderline accept\n\nApproach\n\nthey use html tag header leveling in order to determine a hierarchy of information relatedness levels for building the pretraining corpus\nlines 372-388 very confusing for Algorithm 1. Are you referring to (1) (equation (3)) or equation (1) with (1)???\n\nNo models like RoBERTa used. Exclusively BERT and derivatives? Bowman underclaim results, etc show that BERT is outdated at this point\n“Don’t stop pretraining” style adaptation to the medical domain without the fancy heading alterations to pretraining is, in my opinion, a key missing control\nLimitation points this out: “our TMLM and BERT’s MLM are essentially the same.” Yes, the new dataset is somewhat novel but it’s frustrating that there’s no comparison to continual pretraining.\nThe best I can give this one is a borderline accept\nKey critiques:\n\nNo comparison to vanilla in-domain continual pretraining\nusing BERT instead of RoBERTa or other better PT model\n\nKey reasons to accept:\n\npotentially weak novel data sampling/collection method\nnew dataset that can be used for QA training\n\n663\nKind of a lame headline figure imo\nNot sure if I buy the implication that bias against X in metrics⇒rewards bias against X in system is necessarily true, bias is more often reflected as a blindness to X\nPoint 2 of the main contributions is confusing but if it says what I think it says then I agree\nPoint 4 also is confusing at first brush but immediately disambiguated in next section\nThis seems like important work\nA little bit suspicious of the rescaling:\n\nthis may render the cross-bias type (e.g., between gender and ethnic bias) questionable?\n\nTODO: look up WinoBias Zhao et al 2018, Counterfactual data augmentation Zaho et al 2018b\nThe result about ‘higher socioeconomic bias’ doesn’t make sense on its own to me: bias toward/away from whom? is there a consistent direction? If it’s just generalized inaccuracy w.r.t. a type of category and not consistent inaccuracy toward a characteristic, I don’t think bias is an accurate description of the phenom\nLike the evaluation across bert-base, large, and distil, wish there were evaluations on roberta, etc\nNLI BASED DEBIASING RED FLAG RED FLAG\n\nThe technique they are using to perform the data augmentation looks very suspicious and brittle to me. Where is the verification that replacing “he” with “person” is actually doing what they claim\n\nThe test sentence examples are making me pretty apprehensive…In particular the abstracting phrases and replacing words examples. The meaning is being significantly changed\nTable 5 confirms my concern. There’s just examples of the deltas in Age and SS, this is fundamentally different from bias if it isn’t consistent and directional\n\nThis means comparison between types of bias is broken\nit might also seriously call into question the demonstration of bias itself\nTaking the average absolute value delta is very problematic\n\nRead through Jieyu’s paper on gender bias in CRR again. I am a little skeptical that the authors of this work actually produced antistereotypical examples to serve as the test. A delta in performance (positive or negative unclear) between a natural and stereotypical example and an unnatural, stereotype neutral example (e.g. Jew→religious man in a “money stealing” sentence context) doesn’t necessarily prove anything useful about stereotypes just that systems perform worse on nonsense inputs\n2823\nNovelty is questionable\nSomeone has to have worked on non-unique equation enumeration before? TODO: check novelty\nThey want to get exploded form equation translations of math word problems which map to the given correct answer\nPrior approaches leverage the known answer as a check for pseudolabeling but there are too many to search through\nThey develop an approach to restrict search for text-to-equation output examples to only unique equations (each equation assigned a canonical form)\n\nRestricted to +-x/() type equations\n\nSometimes the same set of numbers can be part of multiple correct equations, e.g. 150 x 2 - 50 = 150 + 50 x 2\n\nthey use a “draft model” to try to find the best unique answer out of the ones using the numbers to try to combat this, by training a model to predict the sequence on a known set of unambiguous equations first\n\nTODO: read results close\nAAAI 8101\n\nextreme overuse of the word “the”\nvery confusing abstract, what is a “confounder pluggable framework”\n\nWays to deal with confounding problem\nPretraining\nBRL:\n\nminimize difference between domains, maximize training set representation margin\nhowever, requires annotation of the confounding variables exactly which is expensive\nDomain adaptation:\nwhat do you mean by “knowledge”\n\nSummary:\nThey propose a representation learning framework, ADBlur that they claim enables deconfounding on representational confounding variables that aren’t explicitly labeled. To do this it includes a minimax game where first “semantic representations” are learned, and then “blurring” reduces domain divergence.\nIt seems like what is happening here is they propose using a second domain discriminator model (or classification head) with parameters phi that tries to predict the subpopulation label S from the same latent vector representation Z that is traditionally just learned by training on an objective of the y prediction accuracy. They then perform “smoothing” in the representation space trying to adapt the hidden representations through further fine-tuning where they minimize the confidence of the domain predictor by using randomly generated S targets.\nThey demonstrate that this approach beats all baselines they try on OOD generlization  and ID dev set performance for NLI/paraphrase detection, and that the representations separate in t-SNE  projections. In object recognition, there appears to be less impressive results on Waterbirds and CelebA, but they once again significantly beat baselines in generalization on DomainNet and Office-31.\nStrengths:\nThe results are strong in 2 of the 3 main experiments. I am impressed by the representation space separation they achieve on NLI in particular, and the good results they achieve.\nWeaknesses:\nQuality of writing:\nThere are lots of small grammar issues that make it difficult to read at times. However, this doesn’t warrant rejection as long as they run it through a grammar check before camera ready time.\nFigures:\nExtremely tiny font size makes many figures unreadable. This is a major issue in particular with Figure 3.\nClarity/presentation problems made it hard to understand section 3:\nIt took me a lot of reading and rereading to understand what “distribution/domain indicator S” means. It seems this is a variable indicating  which dataset a sample is from, e.g. whether it is “in-distribution” or “OOD”.\nIs this really domain generalization?\nThe fact that training the classifiers on samples from both the “trained on” datasets and the “OOD” datasets is necessary at both steps for the method to work makes me find the claim of “generalization” questionable. To me domain generalization means new samples from a completely unseen population are correctly classified.\nQuestions\nWhat does w/o vs with t mean in Tables 1 and 2? I thought no t was ever provided in the NLI data.\nAdditionally, please make these fixes:\n\nStop saying “pluggable.” I think you mean “plug-and-play”\nThe text in figures 1,3,4,5,6,7 are unreadably small at normal sizes unless serious zoom is used. Please fix this\nI believe QQP stands for “Quora Question Pairs” not “question query pair”\nPlease run it through a grammar checker. You are overusing the word “the” in places where it shouldn’t be used, and it makes things harder to read. E.g. “With the increasing computational power, larger ML models have been proven to fit the complex data better.” should be “With increasing computational power, larger ML models have been proven to fit complex data better.” using “the” in that sentence makes it sound like you are talking about “the computational power (of some specific system)” or “the complex data (contained in some specific dataset, domain, etc)” you are talking in generalities though, not specifics. Grammarly or another grammar checker (even MS word) should be able to catch errors like this.\n"},"09-Language/中文-vocab":{"slug":"09-Language/中文-vocab","filePath":"09 Language/中文 vocab.md","title":"中文 vocab","links":[],"tags":[],"content":"冷笑话 stupid joke\n好笑话\n一点儿不好笑\n一定要 →必ず\n扯淡→bullshit"},"09-Language/日本語/単語":{"slug":"09-Language/日本語/単語","filePath":"09 Language/日本語/単語.md","title":"単語","links":[],"tags":[],"content":"低→ひく\n沈む→しずむ\n胴体→どうたい\n抜ける→ぬける\n一匹だけ、飛び込むときにロボットから体が抜けてしまった魚が降りました。\n印象\n普段\n動揺→どうよう\n解決\n耕す→たがやす\n問い→とい\n税→ぜい\n探る→さぐる\n投稿集団\n歩道横断\n触れる\nそれは四宮が今日触れたものか？No.\n所有\n４ それ は 四宮 が 所有 し て いる もの か ？‌\n巻き込む\n過度に接触\nいけ ませ ん ね 人 と の 接触 を 過度 に 恐れる‌\n初体験\n“ 初体験 は いつ だった アンケート ”‌\nリアクションが薄いですね…やっぱり私はこういうのは似合わないみたいです!\n\nこの会長の姿を残してさしあげなくては… (nekomimi pic)\n産業用部品\n分野（subfield) of 法律\n証拠\n探偵\n親台湾\n放任主義\n修士\n環境\n寄る (on the way, stopping by)\n立て看板 protests signs etc wikipedia\n暮らしやすい　not 　生き辛い\n新鮮 same in mandarin\n高速道路こうそこどおろ highway\n塞ぐふさぐblock/stop up/obstruct\n譲る・ゆずる hand over, assign\n転勤\nマイケルさんはどうやって日本語を勉強しているんですか? 日本語を勉強するきっかけは何ですか?\n出張\n連絡\n生産\nnote.com/aktiba/n/nce69d372782d"},"09-Language/日本語/読物":{"slug":"09-Language/日本語/読物","filePath":"09 Language/日本語/読物.md","title":"読物","links":[],"tags":[],"content":"tech-blog.abeja.asia/entry/advent-2022-day19\nBlog post about AI\nnote.com/aktiba/n/nce69d372782d\nyomi on my mf level  ^^^\nwww.aozora.gr.jp/cards/001383/files/56642_59575.html\nIn defense of shadows\nnote.com/kanair/n/n21daa7a53297\nMelancholy of scientists"},"How-To/Building-my-Environment":{"slug":"How-To/Building-my-Environment","filePath":"How To/Building my Environment.md","title":"Building my Environment","links":["tags/tag"],"tags":["tag"],"content":"Obsidian Environment Notes\nUsing obsidian in order to have more organized note-taking and idea tracking system, in particular managing literature reviews (for the Alex paper) and ideation from existing work.\nZettelkasten: the note-taking system where you track many many small ideas on “notecards” that are then linked to  in larger “Document notes.” During note-taking, go more stream of consciousnes\nHow to use\nUseful shortcuts\ncmd+click to open a note in a sliding pane\nctrl+shift+o open a reference from the bib’s page\nctrl+shift+e insert reference to a paper from the bib\ncmd+k insert a hyperlink\ncmd+e toggle between view mode and write mode\ncmd+shift+i insert a template\ncmd+shift+m move file to other folder\ncmd+shift+n create new note in sidepane\ncmd+alt+2 edit file title\ncmd+alt+3 edit file content\nTags\nInsert a tag using tag\nEnvironment Details\nPackages\nReferences interfaces with Zotero auto-exporting bibtex files to allow me to easily reference against papers I’ve saved\n\nMore information blogpost\nSliding Panes side-by-side view of multiple notes at once (helps with the note cards concept)\nvim mode enabled, need to run the following\n\ndefaults write md.obsidian ApplePressAndHoldEnabled -bool false\nTo get the hold arrow keys behavior to work properly\nPotential Future Templates:\nTemplater: information here Youtube"},"How-To/How-To-Zettelkasten":{"slug":"How-To/How-To-Zettelkasten","filePath":"How To/How To Zettelkasten.md","title":"How To Zettelkasten","links":["tags/how-to","tags/tutorial"],"tags":["how-to","tutorial"],"content":"How To Zettelkasten\n2022-04-22 18:43\nTags: how-to tutorial\n\nFleeting Notes\nAs I read, take fleeting notes.\n\nWrite short “atomic notes”\nIdeas in your own words that are brief and easy to review\n\nDocument Notes\nWhen I finish reading something, I write a Document note pointing to its summary information, and pointing to the reference (in Zotero) and content\nConnect to fleeting notes as I built them up when possible.\nUse ctrl+shift+e to make a new one from the paper I’m currently reading as I go.\nQuestions for writing DNs\n\nHow does this idea fit in to what I already know?\nIn what circumstances do I want to stumble upon this note?\nWhen and how will I use this idea?\n\nPermanent Notes\n(This is the actual value of the collection)\nConnect these notes to bibliographic references (Document Notes) and the fleeting notes\nLink bidirectionally"},"How-To/Quartz-setup-info":{"slug":"How-To/Quartz-setup-info","filePath":"How To/Quartz setup info.md","title":"Quartz setup info","links":[],"tags":[],"content":"charleszw.com/posts/quartz-obsidian\nquartz.jzhao.xyz/features/private-pages"},"References/@topping2022UNDERSTANDING":{"slug":"References/@topping2022UNDERSTANDING","filePath":"References/@topping2022UNDERSTANDING.md","title":"@topping2022UNDERSTANDING","links":[],"tags":[],"content":"UNDERSTANDING OVER-SQUASHING AND BOTTLENECKS ON GRAPHS VIA CURVATURE\nJake Topping, Francesco Di Giovanni, Benjamin P Chamberlain, Xiaowen Dong, Michael M Bronstein\n2022\ntopping2022UNDERSTANDING\n\ntags:\nlinks:\n\nNotes"},"References/@wang2022What":{"slug":"References/@wang2022What","filePath":"References/@wang2022What.md","title":"@wang2022What","links":["01-Fleeting-Notes/Naming-the-encoder-and-decoder-elements-of-LMs","01-Fleeting-Notes/Cool-colorcoding-in-LM-paper","01-Fleeting-Notes/Adaptation-Stage"],"tags":[],"content":"What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?\nThomas Wang, Adam Roberts, Daniel Hesslow, Teven Le Scao, Hyung Won Chung, Iz Beltagy, Julien Launay, Colin Raffel\n2022\nwang2022What\n\ntags:\nlinks:\n\nNotes\nGoal of the authors is to understand which of the model types and training strategies in the Cambrian explosion of pretrained transformer LMs actually works the best.\nTo do this they run a large-scale eval across the types in terms of zero-shot generalization performance. Code is provided (github)\nI like that they use causal decoder and noncausal decoder Naming the encoder and decoder elements of LMs\nAdditionally, they discuss Full vs Prefixed vs Masked LM, various fine-tuning tasks, and two eval methods\nI like they way they color-coded Cool colorcoding in LM paper the different elements of the paper, where they connect the elements of their diagram to the highlighted colors in the manuscript.\nAdaptation Stage was only first introduced last year!\nOn p3"},"index":{"slug":"index","filePath":"index.md","title":"index","links":[],"tags":[],"content":"Michael Saxon’s Obsidian Library\nI am hosting this mainly for myself and also so that I can point links in it to people who ask me. Even if I sent you a link to this, don’t go poking around in here ok? ;)\nZettlekasten is a meme and I have never been able to successfully maintain it lol"}}